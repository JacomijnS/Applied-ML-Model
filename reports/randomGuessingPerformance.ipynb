{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057aba3f",
   "metadata": {},
   "source": [
    "### How to prove we are better than random guessing\n",
    "\n",
    "We have an interesting situation where we work with bounding boxes, resulting in a more difficult way to prove that we are better than random guessing. We will show multiple ways to prove that we are better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af98239",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c11277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from project_name.models.yoloModel import YOLOModel\n",
    "model = YOLOModel()\n",
    "model.load_model(\"../runs/obb/train6/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34474148",
   "metadata": {},
   "source": [
    "Let us now predict for every model and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766831e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1542_png.rf.62deacf7980320313580d67dee1ed8a6.jpg: 1024x832 (no detections), 39.3ms\n",
      "Speed: 3.7ms preprocess, 39.3ms inference, 17.3ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_978_png.rf.b1fa6e4655c393a3d4f408f32f9e721c.jpg: 1024x672 None36.4ms\n",
      "Speed: 4.3ms preprocess, 36.4ms inference, 85.7ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_155_png.rf.3b17ee4030dd0461fddfc0f3b5583153.jpg: 992x1024 (no detections), 35.8ms\n",
      "Speed: 3.9ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1773_png.rf.51512561cfc16438d9c13166f1b5457b.jpg: 1024x832 None10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_545_png.rf.8d73929cbb6032b4eb7f1f2a4d7588e7.jpg: 1024x736 (no detections), 41.4ms\n",
      "Speed: 4.7ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1421_png.rf.c0b0c1daaf1ebeba1ee030d1b730a07f.jpg: 832x1024 None38.8ms\n",
      "Speed: 3.2ms preprocess, 38.8ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2358_png.rf.84f9ec7307749d01f6f471fa0de652b7.jpg: 1024x736 (no detections), 8.0ms\n",
      "Speed: 3.6ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_300_png.rf.6ab2b8b5cbf58cd8a3383ea39ef25a72.jpg: 1024x832 (no detections), 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1719_png.rf.0f877f7a46aeb634c73b35aec23a719e.jpg: 864x1024 None40.2ms\n",
      "Speed: 4.9ms preprocess, 40.2ms inference, 2.7ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_230_png.rf.71ef1e82cb7249b449e08e1b0f4b6c9b.jpg: 1024x864 (no detections), 33.8ms\n",
      "Speed: 4.3ms preprocess, 33.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1496_png.rf.efbe691d5aeabbbc208713d4bfe48a2f.jpg: 1024x576 (no detections), 41.6ms\n",
      "Speed: 2.5ms preprocess, 41.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4230_png.rf.5d825ccb19e29b2676e3efaf8bcf065c.jpg: 1024x672 None10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_391_png.rf.11858d7bfa2cc8d7ab964bacf53f51c4.jpg: 1024x608 None38.0ms\n",
      "Speed: 2.5ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1136_png.rf.7fda8b722e043723ecb7747e64a4a23d.jpg: 1024x928 (no detections), 38.6ms\n",
      "Speed: 3.7ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_249_png.rf.0f8d53c1a26d4bc36d1f71a3a89dcebd.jpg: 1024x1024 (no detections), 10.8ms\n",
      "Speed: 6.0ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1712_png.rf.382b330b51f7f47764fd95d2b8366134.jpg: 1024x864 None8.6ms\n",
      "Speed: 3.9ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_321_png.rf.ecc0b07cea9e33452804e4feda7c7d6f.jpg: 832x1024 (no detections), 8.2ms\n",
      "Speed: 3.3ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_408_png.rf.6552b6bd70d78a47c52b5f1847b5ffd3.jpg: 1024x768 (no detections), 44.0ms\n",
      "Speed: 4.5ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_130_png.rf.4b9ab828064ca9b6e951e6b95689f4dd.jpg: 1024x864 (no detections), 8.9ms\n",
      "Speed: 5.6ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1793_png.rf.27e45bd8854ac26a87f4170628b848cd.jpg: 1024x832 None8.6ms\n",
      "Speed: 4.6ms preprocess, 8.6ms inference, 4.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7615_png.rf.304bc2c5cf0a941b6846f0e132be5c3d.jpg: 896x1024 None43.1ms\n",
      "Speed: 4.5ms preprocess, 43.1ms inference, 1.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_269_png.rf.6b72c9e7f876960575338223b496d52c.jpg: 1024x864 (no detections), 8.8ms\n",
      "Speed: 3.8ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_12_png.rf.a1b541915e55c7475ace99b211328e97.jpg: 1024x672 (no detections), 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_41_png.rf.59c058f73450f48dd765135e939aee6a.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.9ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_823_png.rf.7efd238ae14f03da48c57ce9bf8d771e.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 4.9ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1528_png.rf.4f919e17170960c2a7e3ed00c3550bd1.jpg: 1024x384 None34.6ms\n",
      "Speed: 1.7ms preprocess, 34.6ms inference, 3.3ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1096_png.rf.0201a3553b8b76991d514ced849de390.jpg: 1024x736 (no detections), 7.5ms\n",
      "Speed: 3.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1047_png.rf.6d8753139f1f13e21f64d385b3b78865.jpg: 864x1024 None7.9ms\n",
      "Speed: 3.8ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4678_png.rf.f0f6bcbfa2128ce420ed5d3809c20a58.jpg: 1024x512 (no detections), 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7_png.rf.4d60e88297d0349d04e0f8ea0189df34.jpg: 864x1024 (no detections), 7.9ms\n",
      "Speed: 4.5ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_899_png.rf.bc3b41fb512474962f558f0f53d5ebae.jpg: 864x1024 (no detections), 7.9ms\n",
      "Speed: 4.9ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_270_png.rf.1999fa635b0ffddd2ee908b5249452b5.jpg: 832x1024 (no detections), 8.2ms\n",
      "Speed: 4.4ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_63_png.rf.7c34eaff8da54160fa6e24bd8cc767a7.jpg: 1024x480 (no detections), 39.2ms\n",
      "Speed: 3.3ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_195_png.rf.078c6d17c523a8ace6be6124407cfdac.jpg: 1024x832 (no detections), 9.6ms\n",
      "Speed: 4.0ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1090_png.rf.de645f822a5e36175c5e988223f4eeb0.jpg: 1024x512 (no detections), 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_277_png.rf.6bec675762045dd3e65c3b265789d9d9.jpg: 1024x384 None9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1148_png.rf.dea6af8d1222d9f33b0d9b123b7d1579.jpg: 832x1024 (no detections), 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_199_png.rf.b38f5b057f75781bf591be85d974fa0b.jpg: 1024x1024 (no detections), 11.8ms\n",
      "Speed: 4.5ms preprocess, 11.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2862_png.rf.3c9b51a1440c76a95163e57308759430.jpg: 1024x864 None9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_226_png.rf.fa703c0ade306795e1bdc15cd9a756ff.jpg: 1024x1024 None11.2ms\n",
      "Speed: 4.0ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_326_png.rf.1a4c5f7889b7fd54e6bd0e1812431e56.jpg: 1024x640 (no detections), 34.5ms\n",
      "Speed: 2.7ms preprocess, 34.5ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_811_png.rf.754f721fa3c67e3b94dfbc54d4611a83.jpg: 416x1024 (no detections), 33.9ms\n",
      "Speed: 1.6ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_104_png.rf.86a9d1eeedeec79216455a5b9be63e17.jpg: 1024x576 (no detections), 8.5ms\n",
      "Speed: 2.1ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1000_png.rf.7eebc2918f75be5baf4c32a091ef963d.jpg: 1024x320 None35.7ms\n",
      "Speed: 1.2ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 320)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_301_png.rf.33c97596525e84921e5150191ce72202.jpg: 1024x864 (no detections), 7.5ms\n",
      "Speed: 5.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1173_png.rf.c4789dee95f6a55c09e3b523d2f71dde.jpg: 1024x576 (no detections), 7.5ms\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_475_png.rf.fa5ec3299479ea066939ff8d0af4cf13.jpg: 1024x832 (no detections), 8.9ms\n",
      "Speed: 3.3ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2193_png.rf.9f98385cf14495eb548024eeca646222.jpg: 1024x544 None34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_712_png.rf.4b96cd2cf2df5d5270aa3bd79e71299c.jpg: 1024x768 None7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_593_png.rf.e9849767ca988ba52ec46984697635ed.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 3.9ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7013_png.rf.306acba02f2efd1e3fa537ae88659c30.jpg: 864x1024 None8.5ms\n",
      "Speed: 3.7ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_803_png.rf.9f52036e63cf0dd6715a051fdd0523ec.jpg: 1024x416 (no detections), 33.6ms\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_979_png.rf.b94742342af786f4577502a93255029a.jpg: 1024x864 None7.3ms\n",
      "Speed: 4.1ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_53_png.rf.bdac91faa4e8950a4e7b01d4ec328c37.jpg: 1024x864 (no detections), 7.9ms\n",
      "Speed: 3.8ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3244_png.rf.195b93d43b6794dc57bb36564d208192.jpg: 1024x640 None7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1172_png.rf.1da7148474be8ef63728f3a3d870b0e5.jpg: 1024x960 (no detections), 34.5ms\n",
      "Speed: 4.2ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_195_png.rf.f10d144a7c86ab76285046a15305d65a.jpg: 672x1024 (no detections), 33.3ms\n",
      "Speed: 2.6ms preprocess, 33.3ms inference, 0.4ms postprocess per image at shape (1, 3, 672, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_42_png.rf.71bc29cdbf12ea454839c26f642db1fd.jpg: 832x1024 (no detections), 7.6ms\n",
      "Speed: 3.4ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_36_png.rf.62ca9fb224a30f6641b2e5bb87a89b2b.jpg: 832x1024 None7.1ms\n",
      "Speed: 3.3ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_888_png.rf.3d1e56f022463d81ebeb8574717e0619.jpg: 832x1024 (no detections), 7.2ms\n",
      "Speed: 3.6ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_441_png.rf.b14bb0935b574b3e3b9e5adf8f0e7f6b.jpg: 1024x768 None7.6ms\n",
      "Speed: 3.9ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1209_png.rf.3ce049ed968acea01b86ab912a605d0a.jpg: 1024x1024 None8.5ms\n",
      "Speed: 4.6ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_132_png.rf.6fc485cd30f7a7ac20825477ae74d49b.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 4.1ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_658_png.rf.5205c44bbc71fc2c3efe407d441519a5.jpg: 832x1024 None8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_198_png.rf.1319d1e6470b497f05ac13a9bb52e704.jpg: 1024x864 (no detections), 8.9ms\n",
      "Speed: 3.7ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_216_png.rf.0b423fd44fe23382c0f302560b3621aa.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.8ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_578_png.rf.8214cf7e14c6964d521feb47e2d0739a.jpg: 832x1024 (no detections), 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_108_png.rf.90f61f5cd524897a0f80427f56a392ba.jpg: 864x1024 (no detections), 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3613_png.rf.04279ec0c858ecc936ec0199d6e898a8.jpg: 1024x416 (no detections), 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_80_png.rf.c064670165c0e86584d7e56d8268ac07.jpg: 768x1024 (no detections), 34.8ms\n",
      "Speed: 2.9ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1667_png.rf.b92568dd097508f060cd2afd528f8e62.jpg: 1024x672 (no detections), 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_73_png.rf.d5a8af47f15d4d1eb631a42d4d6b6a6f.jpg: 1024x288 None39.5ms\n",
      "Speed: 1.3ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1223_png.rf.0a498c2e88c243ab32fbec80233b5e72.jpg: 1024x416 (no detections), 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7917_png.rf.70ee7ab7ae89188c2eb7549ccd790991.jpg: 928x1024 (no detections), 37.0ms\n",
      "Speed: 4.7ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_264_png.rf.386e1a0bf8e66735ae91a5bcfc01aed5.jpg: 1024x1024 (no detections), 10.0ms\n",
      "Speed: 3.9ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_598_png.rf.bce390518181b7112f52a7f68e01b987.jpg: 1024x544 (no detections), 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_409_png.rf.627057f41b97e8ba901e4924a9c18743.jpg: 832x1024 (no detections), 9.1ms\n",
      "Speed: 3.9ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1611_png.rf.0c40354a305a2eba353ebdf7f135866a.jpg: 1024x736 None8.7ms\n",
      "Speed: 2.6ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_314_png.rf.c26c252d1302ef5698071371d98689bf.jpg: 1024x864 (no detections), 8.6ms\n",
      "Speed: 3.7ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1776_png.rf.5937b77f49288051b1400ad65ef8dec7.jpg: 1024x608 None10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3247_png.rf.d1046712e475f502514a90fa78f97525.jpg: 1024x864 (no detections), 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_269_png.rf.223c627685f37552d6119a6af31c4821.jpg: 1024x864 (no detections), 9.5ms\n",
      "Speed: 3.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_306_png.rf.4c6dca0ca61755390c534915139b20f1.jpg: 1024x864 (no detections), 9.8ms\n",
      "Speed: 3.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_353_png.rf.ea40e7110fc7a9c90b87b2b7e8bf7c1e.jpg: 832x1024 (no detections), 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_396_png.rf.891d048d9125ba147174a6f7d74c57d4.jpg: 1024x864 None10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2128_png.rf.f8b6cd5da365cf54ad4c51ff43bcb9bf.jpg: 1024x832 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3709_png.rf.9e90ec7d2dfb35d01a1c105b3b2f79c9.jpg: 1024x832 None8.1ms\n",
      "Speed: 3.5ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_285_png.rf.ec8e67b4f493b56be2f41decdf280b62.jpg: 544x1024 (no detections), 37.1ms\n",
      "Speed: 2.6ms preprocess, 37.1ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1407_png.rf.0c6325cfef96b74c45b60545953f2408.jpg: 864x1024 None8.2ms\n",
      "Speed: 3.8ms preprocess, 8.2ms inference, 2.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_620_png.rf.ce4d242b874a9cd276e610097cdcca8b.jpg: 1024x608 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1900_png.rf.b5bcead0522f3d8b2bee79cc15a5477f.jpg: 1024x512 None10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2562_png.rf.2b1b0b7638fa30068783c6bb6287314d.jpg: 832x1024 (no detections), 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_496_png.rf.4805c81fce35ad473ba1b27e9c054ef8.jpg: 1024x512 (no detections), 7.9ms\n",
      "Speed: 1.9ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2894_png.rf.0a4052446539647c424af73438fb9a06.jpg: 1024x448 None37.8ms\n",
      "Speed: 2.1ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_213_png.rf.85241ed9c6ce96f4a18e85ec6482b246.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 4.6ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_788_png.rf.4099b0223a789948e4b727c46a6092a1.jpg: 1024x1024 None8.3ms\n",
      "Speed: 5.6ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_240_png.rf.60708ec8d8d242f30d399b095c77c7ce.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 3.8ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3593_png.rf.eb2fcd9dc83efe328d4797bd4fede777.jpg: 1024x544 None7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_819_png.rf.8ebb71ef2e3e83019dc323683c56af2b.jpg: 1024x832 None8.2ms\n",
      "Speed: 3.6ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_429_png.rf.7a3cdb472f4382251ece6195e7ae1e9c.jpg: 1024x1024 (no detections), 10.1ms\n",
      "Speed: 5.0ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1081_png.rf.fa746d423a8a31d9dbcf027ae78016ee.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1948_png.rf.5cee5ce80ba2f4f1d7786c8aa5bab7f7.jpg: 1024x384 None8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_655_png.rf.f5b259239c2ad2b74ddf445f88e9950d.jpg: 1024x768 (no detections), 9.2ms\n",
      "Speed: 2.8ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_94_png.rf.5eb2c8f111ad826bfeb20134ba4b6b4f.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.3ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1095_png.rf.528793dae32e5d8d6aca1d9bbc7a4511.jpg: 1024x1024 (no detections), 8.2ms\n",
      "Speed: 4.7ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_382_png.rf.051ac683451d7606ad307fdeddfb4899.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 3.1ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_629_png.rf.f6fd2950975f3a90e805f9c36ceff961.jpg: 1024x768 (no detections), 7.8ms\n",
      "Speed: 3.3ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3956_png.rf.4ce7f45835a4a12ebb4bc3a86661f2cd.jpg: 832x1024 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_295_png.rf.374489979467919cbf776559311c3364.jpg: 1024x1024 None10.0ms\n",
      "Speed: 4.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_61_png.rf.fe73991ac017c1c2fdb5f17cc431872e.jpg: 1024x1024 None8.5ms\n",
      "Speed: 4.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_629_png.rf.fea90f1a2944bd83330277d6fda80964.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 4.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_6448_png.rf.2e1b9a29642c01c30e72e1665c936339.jpg: 832x1024 None7.9ms\n",
      "Speed: 4.4ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_296_png.rf.21cdb7c1c82a8992ceda7a17f7e5512e.jpg: 1024x704 None35.1ms\n",
      "Speed: 3.0ms preprocess, 35.1ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_357_png.rf.502a511ed8bdcfa15f0a5fdadd29853e.jpg: 1024x832 (no detections), 7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1026_png.rf.e9dc3004de762ddd0f75d8f17fb5d0f6.jpg: 800x1024 (no detections), 35.1ms\n",
      "Speed: 3.0ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_8373_png.rf.e4c1577e54e74dc96a3989672dd54301.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.8ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_37_png.rf.3135ee0014e23b10985bb0773f2f65f9.jpg: 832x1024 (no detections), 8.2ms\n",
      "Speed: 3.6ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_58_png.rf.80a7b4275735ac207ca21321a12f834c.jpg: 1024x768 (no detections), 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1_png.rf.fa169dd72c05264f1fa1b4c2a34d1469.jpg: 1024x864 (no detections), 9.4ms\n",
      "Speed: 3.5ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1224_png.rf.7c20f6876b3efc39ea916cda7db4c00c.jpg: 1024x864 None7.6ms\n",
      "Speed: 3.4ms preprocess, 7.6ms inference, 3.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3789_png.rf.ecb45f4073420238817c80bb9dfb4eac.jpg: 864x1024 None8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 3.1ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1134_png.rf.d654c836fa7d0df0490cc25e4b8b841d.jpg: 864x1024 (no detections), 7.6ms\n",
      "Speed: 3.2ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_482_png.rf.bbf4f0951688af0ded3e5b01e37f0dc5.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 3.1ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_608_png.rf.0c6cc5699987e38bd48f0c177baa7d7e.jpg: 1024x960 (no detections), 7.7ms\n",
      "Speed: 4.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3513_png.rf.9bb8c4ef73a74c038d227eec0bea97db.jpg: 1024x352 None35.0ms\n",
      "Speed: 1.4ms preprocess, 35.0ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_694_png.rf.49d9623643bf19c7915f785f9727f497.jpg: 1024x832 None7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4160_png.rf.da4b4d52bb392c4587f10a38b8818fb5.jpg: 1024x512 (no detections), 7.6ms\n",
      "Speed: 1.8ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1147_png.rf.5081a993043bcb23358d3bea9981c9ab.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1992_png.rf.379b87658e6c985d51218b5383d5450b.jpg: 1024x544 None7.5ms\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_754_png.rf.f14f77b3341ceeb367026174400a48a9.jpg: 832x1024 (no detections), 7.5ms\n",
      "Speed: 4.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_604_png.rf.9087b8961228cd207e2d66f1dec266ef.jpg: 1024x864 None8.5ms\n",
      "Speed: 3.9ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1346_png.rf.a708d220c5342918bcb0aee7f80953d5.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.5ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_631_png.rf.557ce4882bce1244e45b277f144e1c17.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image3_138_png.rf.909d6ce0c02babadf555b7aa76a9dcea.jpg: 1024x992 None37.5ms\n",
      "Speed: 4.2ms preprocess, 37.5ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1722_png.rf.450ed72977e9af3f01fb362ea0f7d01e.jpg: 1024x864 None9.7ms\n",
      "Speed: 3.9ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_410_png.rf.08c2ab9f97d8e6f07b98cf875c53d097.jpg: 896x1024 (no detections), 10.5ms\n",
      "Speed: 6.3ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3101_png.rf.99c9bb3c4d074ab053621447b8d313ed.jpg: 1024x832 None7.9ms\n",
      "Speed: 3.3ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1061_png.rf.fbf0e5b8dba2be5aa26bd71df6622c36.jpg: 768x1024 (no detections), 7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_600_png.rf.da8ecb57a923d4e4d932a6c7fd8ed731.jpg: 1024x864 (no detections), 9.5ms\n",
      "Speed: 3.6ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image3_620_png.rf.5bda3651124325056a68ce9e18c8594e.jpg: 1024x864 None8.6ms\n",
      "Speed: 3.6ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1107_png.rf.806fab17616702fbc33f1485701759d7.jpg: 832x1024 (no detections), 9.6ms\n",
      "Speed: 3.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2027_png.rf.d64c9d07c29a2c6b7b76b6df9f8933e5.jpg: 1024x768 (no detections), 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_621_png.rf.836b9d0613f68f044a0a85fcfe998b98.jpg: 1024x800 None34.2ms\n",
      "Speed: 3.5ms preprocess, 34.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1309_png.rf.792e90812ae6932e3459f8df5b9167e9.jpg: 1024x864 (no detections), 9.0ms\n",
      "Speed: 3.7ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3619_png.rf.1adbb7f2ad4dfbd1e89dc200283e8fb3.jpg: 1024x416 (no detections), 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1607_png.rf.ecf3e995bfb4045c5ccbbd914a0fab8c.jpg: 544x1024 None7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 2.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1219_png.rf.29d7e993924eceda219d0666c7a24c99.jpg: 1024x416 (no detections), 9.0ms\n",
      "Speed: 2.4ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_67_png.rf.1998f3deb5276d06098206d3f64645e3.jpg: 768x1024 (no detections), 8.2ms\n",
      "Speed: 3.5ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_96_png.rf.84e1d4c27219711b3bab09d6f54745b0.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 4.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1162_png.rf.a9ca54e5f83ea42fe572d4f481d44fa2.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 3.7ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1332_png.rf.9a84efb79d01516ea4ca07f134749fdc.jpg: 1024x736 None8.4ms\n",
      "Speed: 2.8ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_40_png.rf.ce0d9db6d63a665f62d612038969b714.jpg: 832x1024 (no detections), 8.3ms\n",
      "Speed: 3.5ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4518_png.rf.9373c879091da54e6b8fd8b2821d4f14.jpg: 832x1024 None7.3ms\n",
      "Speed: 4.1ms preprocess, 7.3ms inference, 2.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_914_png.rf.d0677318163cbe8b14f568eaf626da0d.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 3.8ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_523_png.rf.4bb744d1275215860b111014ca3c09ec.jpg: 864x1024 None7.7ms\n",
      "Speed: 4.1ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2291_png.rf.62cfeef40c65e7f1fe873335c535e13d.jpg: 1024x832 None7.8ms\n",
      "Speed: 4.1ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_160_png.rf.1aab63e9be605a27276dbf3c8847a481.jpg: 864x1024 (no detections), 7.8ms\n",
      "Speed: 4.2ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_300_png.rf.471f4c12d227a7fc051011a489a33d77.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 5.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_102_png.rf.c78fe3e151ea0c9779767726479e4d4d.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.3ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_271_png.rf.983fadda251d3b2062fe025e5c232670.jpg: 1024x480 (no detections), 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1041_png.rf.b33a555439c5eb1e11622df417413e60.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_81_png.rf.d551166cae9a8e403ba25aa323d2da5f.jpg: 1024x1024 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_250_png.rf.e310e0db325a7658edf360b19df8f77a.jpg: 832x1024 None7.7ms\n",
      "Speed: 3.6ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_328_png.rf.60bc94b23a699b9ae0752b822dde1448.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 3.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_736_png.rf.b756c2fdf5d848be0d65d92829568eed.jpg: 832x1024 (no detections), 7.5ms\n",
      "Speed: 3.6ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2858_png.rf.15403dca00c9e35ff409afb947497d65.jpg: 1024x288 (no detections), 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4652_png.rf.cfb34ce6d90ebf9152f2a4e1dab5d894.jpg: 1024x960 (no detections), 9.2ms\n",
      "Speed: 4.5ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_345_png.rf.2a31e2cc93af547720719038f3207b42.jpg: 1024x864 (no detections), 9.1ms\n",
      "Speed: 3.0ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1406_png.rf.442f619509c72d9c10acb0d70dae7b80.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_553_png.rf.c99ef4abcbc78efebc1459ffbcc3a948.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_97_png.rf.f938359f79cc4aa2475eb6f204366293.jpg: 864x1024 (no detections), 7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_720_png.rf.11b40e1391290b44509a2746ab59a2d5.jpg: 1024x448 None7.6ms\n",
      "Speed: 2.3ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_315_png.rf.59b26f6bb5a4987ecd21d3ec3bd0b78b.jpg: 1024x864 None8.0ms\n",
      "Speed: 4.3ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_531_png.rf.1f3150f1706276016448444146196eef.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 3.8ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_239_png.rf.b7a90eccb9159352a9d837a4a91d74e0.jpg: 896x1024 (no detections), 9.6ms\n",
      "Speed: 4.2ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1564_png.rf.d757abb86730c13f31c43a18cd6cca3f.jpg: 1024x352 (no detections), 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4344_png.rf.6c8260143f2213e8f88f00e2db33f712.jpg: 1024x512 None8.9ms\n",
      "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_127_png.rf.3d98767272a28a66afa6490e6e58d787.jpg: 1024x864 (no detections), 8.9ms\n",
      "Speed: 3.6ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_339_png.rf.d2607bc319ab0fe88cdbc0bda36b597e.jpg: 1024x672 (no detections), 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_791_png.rf.78165ef6301220ccf5c21e45f0dd74d1.jpg: 832x1024 (no detections), 7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_353_png.rf.79d70a2a208a0da8801a83a545abb85d.jpg: 1024x736 (no detections), 7.5ms\n",
      "Speed: 2.8ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_539_png.rf.977500280ffa2b81fa655c839bd2a9ff.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 4.3ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3194_png.rf.7e5015504f25d25ffba4ce89ab2203d4.jpg: 1024x832 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_399_png.rf.df2e9f74adbd02e52c25268903aa1c97.jpg: 1024x864 (no detections), 8.4ms\n",
      "Speed: 3.8ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_527_png.rf.238305d49f0df82fd065fd5803e8cdcb.jpg: 1024x832 (no detections), 8.6ms\n",
      "Speed: 3.4ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_229_png.rf.ffa8edd3e93e936bd77d678fc83a9b86.jpg: 1024x352 None7.8ms\n",
      "Speed: 1.4ms preprocess, 7.8ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7108_png.rf.a500619ae213e7d7abde9bedc812458f.jpg: 992x1024 None8.6ms\n",
      "Speed: 4.3ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_171_png.rf.5dd7c145fd2f9c667737c927d73fdf8c.jpg: 832x1024 (no detections), 7.9ms\n",
      "Speed: 2.9ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_803_png.rf.c72a577f195e48ac21070e632ca56480.jpg: 1024x832 None7.6ms\n",
      "Speed: 2.9ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_335_png.rf.9b5caab439858723bfc096a05bcfc919.jpg: 1024x800 (no detections), 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_580_png.rf.7be35c41e93d72df78598df93f0d4ae5.jpg: 928x1024 (no detections), 7.5ms\n",
      "Speed: 4.2ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 928, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_534_png.rf.dabb95e8446c3dd899ed858797b725fc.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 4.1ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_22_png.rf.06c62da585c7275aade0d95428e27136.jpg: 1024x896 (no detections), 36.1ms\n",
      "Speed: 3.8ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_80_png.rf.d332cb93ec3ed9e475dd6603e8335b1a.jpg: 1024x416 (no detections), 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1706_png.rf.7afc2d834039cee5f5a66f18ba3130a3.jpg: 864x1024 (no detections), 8.0ms\n",
      "Speed: 3.7ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2327_png.rf.767b817c34c6d8d9a23d3f3914f8485e.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 3.8ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2351_png.rf.aa671e779b5d5e1b02b717307c96b5db.jpg: 1024x864 None8.1ms\n",
      "Speed: 3.5ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_298_png.rf.4af54f3971247f6fc07f99eb12f4a098.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.7ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1214_png.rf.bb8204c8269ee3bd35ae3160c52b4c8e.jpg: 864x1024 (no detections), 8.5ms\n",
      "Speed: 4.0ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2648_png.rf.c61d3b5957667c312078bb290f1fcc9e.jpg: 1024x640 (no detections), 8.7ms\n",
      "Speed: 2.3ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_5969_png.rf.92335c3790abb78579bfc9aaa2cbd87c.jpg: 832x1024 None7.8ms\n",
      "Speed: 3.2ms preprocess, 7.8ms inference, 3.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7058_png.rf.029c63a7047dedf16c6d0ce01533b98b.jpg: 1024x832 None8.8ms\n",
      "Speed: 3.1ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_821_png.rf.d28b7602f6e87bab6da1503d5a0c68b3.jpg: 832x1024 (no detections), 11.5ms\n",
      "Speed: 6.0ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1129_png.rf.8db430ad388bce8ef6b097eeb1e85515.jpg: 1024x864 None10.8ms\n",
      "Speed: 6.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_658_png.rf.de1a730e82584f8353c1187bd2da792b.jpg: 1024x928 (no detections), 9.4ms\n",
      "Speed: 4.4ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1581_png.rf.a4a944611a6bca845d4190be10d96fa1.jpg: 1024x768 None8.4ms\n",
      "Speed: 4.5ms preprocess, 8.4ms inference, 3.1ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_567_png.rf.1ff9e6e8bb53e2d54f223feea5743936.jpg: 1024x576 (no detections), 7.8ms\n",
      "Speed: 2.1ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1049_png.rf.f5a123abb07f43506a840667ad755261.jpg: 1024x448 (no detections), 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1144_png.rf.173ad79aad372549ebed7d37647c85a8.jpg: 832x1024 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2062_png.rf.96caca3e4789f028ac1329ea33773425.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 3.7ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_393_png.rf.0b282078360e227eac878ead28fe31a2.jpg: 1024x864 (no detections), 8.3ms\n",
      "Speed: 3.8ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2476_png.rf.8c979b58ab2997484f0de77252f4bae8.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 3.5ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3502_png.rf.30648c59cd93171dd03dae1612ebc5af.jpg: 1024x832 None8.0ms\n",
      "Speed: 3.5ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2188_png.rf.45749597974be4fac3fb3041c42cac73.jpg: 1024x576 (no detections), 9.0ms\n",
      "Speed: 2.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_471_png.rf.88afffd3f2fe6958bd2c21514800a016.jpg: 1024x864 (no detections), 8.4ms\n",
      "Speed: 3.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_136_png.rf.84e1aaf6371bc7c19e7958cb96ae0dca.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.0ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_274_png.rf.51882731bb010b99adf0d39b585fd4b6.jpg: 992x1024 (no detections), 8.2ms\n",
      "Speed: 4.3ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_90_png.rf.349e8042b0cd6b53179ba3abb4f3c44c.jpg: 832x1024 (no detections), 7.4ms\n",
      "Speed: 3.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_197_png.rf.44a35017dd213d2d77f0496072cfb41e.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 4.0ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_802_png.rf.2caa782264ce757cb9b158d442581df6.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 3.4ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_0_png.rf.d29cab92b154a83ca5bf7e40083673a2.jpg: 1024x480 (no detections), 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_56_png.rf.07ffbc9bafd21d80db9c78b4f935ba3a.jpg: 1024x640 (no detections), 7.8ms\n",
      "Speed: 2.8ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_515_png.rf.3065d50267a627b72fecc33855b2bc00.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 3.5ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2589_png.rf.797db3537a24d6247c99810896acaa5f.jpg: 1024x544 (no detections), 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_287_png.rf.1963bdf654969c5d608bf0ccff643bdd.jpg: 1024x832 (no detections), 7.6ms\n",
      "Speed: 4.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_488_png.rf.72acecd3750485a10f790fccf953870a.jpg: 1024x608 None7.5ms\n",
      "Speed: 2.8ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_237_png.rf.3c70555567d76e1b792a000d60404ff7.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 4.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_690_png.rf.27ef5e8de20af80de9e977fc813e9aa8.jpg: 1024x832 (no detections), 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3358_png.rf.a5c4fda37c0493839f06dbaa096908e9.jpg: 832x1024 (no detections), 9.5ms\n",
      "Speed: 3.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_84_png.rf.f14fe69a9b05f7d5a40b1bffa61b8ead.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_707_png.rf.a68ed3710da7fc1c84ae02bfecc5caa5.jpg: 864x1024 (no detections), 7.8ms\n",
      "Speed: 3.6ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_169_png.rf.48e9271b5fe8dbc321bc7cfd10b1d55f.jpg: 1024x1024 (no detections), 8.4ms\n",
      "Speed: 3.5ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_796_png.rf.1776a6aa61508cdf674ad9ae5578986e.jpg: 960x1024 (no detections), 37.1ms\n",
      "Speed: 4.4ms preprocess, 37.1ms inference, 0.4ms postprocess per image at shape (1, 3, 960, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_137_png.rf.328a6c166540a20557e3e9ad6037a1df.jpg: 832x1024 (no detections), 8.1ms\n",
      "Speed: 3.1ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_108_png.rf.7412c1568c7a0071fa200a4e13a550b7.jpg: 1024x448 (no detections), 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1036_png.rf.4743d6d5ca4bcd7df70a2083802b981a.jpg: 1024x768 (no detections), 7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2487_png.rf.d44e02e62692a0c9e37bdcfc4ef78003.jpg: 1024x1024 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_463_png.rf.05af36580d7b5dcd5927b38341446775.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 3.6ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_173_png.rf.8d122003e666d1b43c9f60e9ef3f0ccf.jpg: 1024x768 (no detections), 7.4ms\n",
      "Speed: 3.4ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4372_png.rf.701d0f949a89d7d1fba3825b7008e787.jpg: 1024x928 (no detections), 8.5ms\n",
      "Speed: 4.7ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_477_png.rf.734af8f7cc7e630ac0df48d90b76de7e.jpg: 1024x704 (no detections), 7.7ms\n",
      "Speed: 2.9ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1514_png.rf.8aa5c1d4670140b9b9b8b84d6ad70fbc.jpg: 992x1024 (no detections), 9.8ms\n",
      "Speed: 4.7ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_252_png.rf.65bf1d39beb17acc6be39ee33ef00908.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.4ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_947_png.rf.c09499f3067dd00d1e9fe5c6ea497ff2.jpg: 448x1024 (no detections), 34.6ms\n",
      "Speed: 1.7ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_71_png.rf.43f9fc97520abda66fbab2a45f328d26.jpg: 832x1024 None7.5ms\n",
      "Speed: 3.4ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_365_png.rf.f5615050309ece820912d0d09859a5f0.jpg: 1024x448 (no detections), 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_140_png.rf.b63ac9f299096c7ef259e393038b4be1.jpg: 832x1024 (no detections), 11.5ms\n",
      "Speed: 6.2ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_876_png.rf.7fc4b4b05beb4f0ff9fefbb9d4fa1ab3.jpg: 1024x800 (no detections), 9.4ms\n",
      "Speed: 5.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_345_png.rf.06185501b45cfee439ac1cfc71031455.jpg: 1024x352 (no detections), 9.2ms\n",
      "Speed: 1.6ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_5_png.rf.49ecdad27d07b6b8901d9931c2067bec.jpg: 320x1024 None35.8ms\n",
      "Speed: 1.5ms preprocess, 35.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_235_png.rf.b1941b81c75ae13ea1add97bf50e69aa.jpg: 1024x512 (no detections), 9.3ms\n",
      "Speed: 1.9ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_179_png.rf.2dac77668440f0f798140d3233888a64.jpg: 416x1024 (no detections), 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_388_png.rf.62b2788f9c10885a6075e38b46653acc.jpg: 896x1024 (no detections), 7.7ms\n",
      "Speed: 4.4ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1776_png.rf.a86ba5c63c5c70eb7718401a9e15e50e.jpg: 1024x864 None8.0ms\n",
      "Speed: 3.8ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_907_png.rf.44416cf779b4ea8d8fa95afee51f5e3f.jpg: 1024x448 None7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1186_png.rf.3cfc6477bbc733ebdf562bb8d455e907.jpg: 1024x960 None7.6ms\n",
      "Speed: 4.5ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_110_png.rf.7fc86b639738b0a2cd6e55e66cd73b99.jpg: 1024x352 (no detections), 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_380_png.rf.a3edc138e5863941008841820260e1db.jpg: 1024x832 (no detections), 9.1ms\n",
      "Speed: 4.0ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1673_png.rf.682b1cc99342f353d0d34689f8bbaf59.jpg: 1024x480 (no detections), 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4373_png.rf.cbac67cb2e9e3495ee9e136ec1f2ec9a.jpg: 1024x960 (no detections), 10.3ms\n",
      "Speed: 4.3ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_516_png.rf.91d7d5784d59db1c419b9be508e4a37e.jpg: 544x1024 None7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 2.8ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_142_png.rf.d563056b013def35087f83ce9f0119be.jpg: 1024x864 None7.7ms\n",
      "Speed: 3.1ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_111_png.rf.3893d8f7588cea4d796d26119e52637f.jpg: 1024x576 (no detections), 7.8ms\n",
      "Speed: 2.2ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_316_png.rf.22de12a5772f6b00cfdef17d8f66a7ba.jpg: 1024x864 None8.1ms\n",
      "Speed: 4.3ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_263_png.rf.eab7542bedd4be63c435b906ce9d4651.jpg: 1024x1024 None8.3ms\n",
      "Speed: 4.9ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_110_png.rf.b0aff58a40e98042e37cb897e756b08e.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1802_png.rf.ada9b0ad89e89af07a36ed5590773b7e.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.4ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1560_png.rf.22e6f99275f437d9906a7f4a608a3985.jpg: 1024x672 None7.6ms\n",
      "Speed: 2.8ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3994_png.rf.5f4d9a9a84fa26b7ba96ae6e2e40a259.jpg: 1024x416 (no detections), 8.2ms\n",
      "Speed: 1.9ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1680_png.rf.cddfca6e707beecf1ca52e4946adeeee.jpg: 640x1024 (no detections), 34.3ms\n",
      "Speed: 2.6ms preprocess, 34.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_392_png.rf.666304237d915a705d6830016a7c22c1.jpg: 1024x864 (no detections), 8.8ms\n",
      "Speed: 3.5ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_504_png.rf.a70dbb22c8ed59e8fa9535a59973eac5.jpg: 1024x896 (no detections), 9.2ms\n",
      "Speed: 3.8ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_436_png.rf.163f5793186cc5a322fad8a193d892e1.jpg: 1024x704 (no detections), 7.9ms\n",
      "Speed: 2.7ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_316_png.rf.61dbf14487cee0fdf8a82602742726a0.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2929_png.rf.5281aae6cdac82080777a2ba5270e050.jpg: 1024x672 None7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1806_png.rf.8a13aca157648bc2ca883135c439304a.jpg: 864x1024 (no detections), 7.7ms\n",
      "Speed: 4.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1031_png.rf.0f84f2c23a4cd720a80e74e445be6466.jpg: 1024x448 (no detections), 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_787_png.rf.bf6694681dafe401cf0123e5b2733ae0.jpg: 1024x704 (no detections), 9.1ms\n",
      "Speed: 2.6ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1107_png.rf.f261d35066d972aeae64edc4b34a5d7e.jpg: 544x1024 (no detections), 8.4ms\n",
      "Speed: 2.5ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_548_png.rf.042f9ef1d41fe9e8cfc84c43a6d33bed.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1098_png.rf.89eea31a3d88c2de0f0e605a12968a91.jpg: 992x1024 (no detections), 9.7ms\n",
      "Speed: 5.2ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_98_png.rf.760919589e2de7e93ced78b7dfa3c62b.jpg: 1024x864 None8.4ms\n",
      "Speed: 3.1ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_304_png.rf.02b33477f70bcaae759cf80b1c7d3730.jpg: 1024x576 (no detections), 26.2ms\n",
      "Speed: 10.2ms preprocess, 26.2ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_472_png.rf.75e038dd70d155dd6355dc7906aeec02.jpg: 1024x832 (no detections), 9.4ms\n",
      "Speed: 3.9ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_142_png.rf.05bdcca221eee8efc0651e3fb54f932f.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.2ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_615_png.rf.cef477ebb9daca0f6f69f1eb39a7b53d.jpg: 1024x640 (no detections), 7.4ms\n",
      "Speed: 3.2ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_155_png.rf.80393d981ea40b6c1b8b9dc753eb308c.jpg: 1024x704 None7.5ms\n",
      "Speed: 2.9ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1149_png.rf.235191fb233abff0b4926a7e39a9eea4.jpg: 864x1024 None9.5ms\n",
      "Speed: 3.9ms preprocess, 9.5ms inference, 3.1ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_290_png.rf.9635aba99a64bd1ea314ae43241ac044.jpg: 1024x576 (no detections), 11.5ms\n",
      "Speed: 3.8ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_306_png.rf.61caa0eea2f392fcfed6a6808aa4174d.jpg: 832x1024 (no detections), 11.1ms\n",
      "Speed: 5.7ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_864_png.rf.a5f519ce8af0f1f08b0439f97599d471.jpg: 1024x800 None9.5ms\n",
      "Speed: 3.3ms preprocess, 9.5ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2152_png.rf.5c2e8ea5ec087257e61a7026e9994011.jpg: 1024x544 None7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1353_png.rf.b843ae50b5e163e10c908171716e5a39.jpg: 1024x1024 (no detections), 8.2ms\n",
      "Speed: 3.9ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_630_png.rf.cdb97ca5544b97e536d241a63bdbd547.jpg: 1024x384 (no detections), 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_21_png.rf.abe115abaadda1c0fdd552fcb1c32032.jpg: 608x1024 (no detections), 33.8ms\n",
      "Speed: 2.4ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 608, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_225_png.rf.2bfd04df55787346cd770f059fc1e7ad.jpg: 1024x1024 None8.2ms\n",
      "Speed: 4.1ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_331_png.rf.a0851e40fddcf6211958fca348bfeb78.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.7ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_356_png.rf.325517fed11d2b059bbae6715a7cb21c.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 3.6ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_68_png.rf.e9c730368efcd367b5e1430616ef2ed6.jpg: 1024x384 (no detections), 8.6ms\n",
      "Speed: 1.5ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1310_png.rf.daf759fe071a5733142e9847fb388e75.jpg: 1024x608 (no detections), 9.2ms\n",
      "Speed: 3.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_2337_png.rf.4f2fc3029cc730ee37e46652fea46036.jpg: 832x1024 None7.9ms\n",
      "Speed: 3.5ms preprocess, 7.9ms inference, 2.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_438_png.rf.dbe2dfbad9f739757ead72d520d2e633.jpg: 768x1024 (no detections), 7.9ms\n",
      "Speed: 2.8ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_206_png.rf.9af7b509cfc87217908dfda627136bf8.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 4.1ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_200_png.rf.5c5667178404f14d0124544574c16083.jpg: 1024x352 None7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_571_png.rf.60239651dc5d9031c3e902d0a16b200d.jpg: 1024x832 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2149_png.rf.2d391a8be0d79857aeb9992f52779eca.jpg: 1024x800 (no detections), 8.4ms\n",
      "Speed: 3.4ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1259_png.rf.ebfab9ae92058e7cca0b9e0fbb64c948.jpg: 1024x864 None8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_697_png.rf.4655bfbfaecb4bb4ecf7fa9478b76ad8.jpg: 1024x832 None9.1ms\n",
      "Speed: 2.9ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_610_png.rf.c0995510828ea9894c4ffdea39630aca.jpg: 1024x864 None9.1ms\n",
      "Speed: 3.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_75_png.rf.9fdc9f8a903295c283ebab365a1888e0.jpg: 1024x672 None8.9ms\n",
      "Speed: 2.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_278_png.rf.aed420df47119889bd8af834c3e1c7b8.jpg: 1024x768 (no detections), 8.4ms\n",
      "Speed: 2.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_513_png.rf.9c41966c467d0bbd6cfa7cd9a8a2953e.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 3.5ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_537_png.rf.0af2211302c463dd9e59caf6ed321ecf.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_78_png.rf.d27b079cf4d9404f9590dc2641f37dc9.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 4.0ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1029_png.rf.8f1dfb1982511a9b38867fa9444965f0.jpg: 832x1024 (no detections), 8.1ms\n",
      "Speed: 3.5ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_256_png.rf.4706c2f841f94188ed9f48b4ad4dba26.jpg: 1024x384 (no detections), 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_340_png.rf.38e0fc7764336e7a7e3c440aea0e2daa.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 3.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1669_png.rf.66de9f8a4d5a71ec06d4c5c4c475ff6c.jpg: 1024x768 (no detections), 7.6ms\n",
      "Speed: 2.8ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1244_png.rf.10768651f2631bbbf28837704e2c9916.jpg: 768x1024 (no detections), 7.5ms\n",
      "Speed: 3.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1264_png.rf.3d9e9ec178bffa0af8674e9f9e69730f.jpg: 1024x864 None8.4ms\n",
      "Speed: 5.7ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_120_png.rf.a013ab648c9c688362f65937d25c190b.jpg: 832x1024 (no detections), 21.8ms\n",
      "Speed: 14.0ms preprocess, 21.8ms inference, 0.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_894_png.rf.d87567f8b64137ef40bc1cf5852d4d03.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 3.8ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2145_png.rf.a47b00248c5acbae164fa4f06f39861b.jpg: 1024x576 None8.8ms\n",
      "Speed: 2.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_158_png.rf.50714cb0fd36bf8ad441d03d4e5c58d3.jpg: 768x1024 (no detections), 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_764_png.rf.ab8fbe451b41e67b0fac185b0f9a4f86.jpg: 768x1024 (no detections), 10.7ms\n",
      "Speed: 5.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_60_png.rf.8d4f7dce9cd64f581cab952df132669a.jpg: 1024x864 (no detections), 11.1ms\n",
      "Speed: 6.6ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_6_png.rf.c1d09879417997e2d668378db7be1a55.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.8ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_499_png.rf.588eaa8ccf68add93a6a4280de716db4.jpg: 832x1024 (no detections), 7.9ms\n",
      "Speed: 6.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/coronoid-process-fracture_jpg.rf.71650459c69a9734ecd545067cf18bf4.jpg: 992x1024 (no detections), 9.5ms\n",
      "Speed: 5.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_891_png.rf.14e1ce98932091652500c98541ec8455.jpg: 1024x512 (no detections), 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_162_png.rf.0132591669e00deaf033b6d409e4d24f.jpg: 1024x864 (no detections), 7.3ms\n",
      "Speed: 3.6ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_481_png.rf.d04c20719ce7d46794b21c816dcee200.jpg: 1024x864 (no detections), 7.0ms\n",
      "Speed: 3.8ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_642_png.rf.da3a47f0d75768392b53c76d73227bbc.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4311_png.rf.94bdbf6b601e08d736b5fca3590c95c1.jpg: 1024x768 (no detections), 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2552_png.rf.7a87da3fa8c3d03f97c51bcec0ead7e7.jpg: 1024x864 (no detections), 9.2ms\n",
      "Speed: 4.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_342_png.rf.c1998dcfe68bc1bab84ea57af9694c51.jpg: 1024x832 None20.5ms\n",
      "Speed: 6.3ms preprocess, 20.5ms inference, 3.7ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_786_png.rf.8799fbcb9ae8f82f1f9eadcf993428bf.jpg: 1024x704 (no detections), 7.5ms\n",
      "Speed: 2.6ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_234_png.rf.8ff82c844e5a90593e9009ee2546dfb0.jpg: 1024x608 (no detections), 7.7ms\n",
      "Speed: 2.2ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_644_png.rf.5e61f3b5f36f82ab41f333281faf6eca.jpg: 1024x1024 (no detections), 8.4ms\n",
      "Speed: 4.4ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_602_png.rf.19b335a39a1557f6b0cdf8f617e3537d.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 3.0ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_581_png.rf.20026bf05c575326d79e00f6772a094a.jpg: 1024x544 None7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_598_png.rf.d5cdf9fdd24ff6626fd9fe2cbc02ea34.jpg: 1024x672 (no detections), 7.5ms\n",
      "Speed: 2.9ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_632_png.rf.65725898246d01bd76a6610f79591127.jpg: 1024x1024 None9.8ms\n",
      "Speed: 4.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_536_png.rf.d14e240fc070711be3f1b81d89416b17.jpg: 1024x1024 (no detections), 7.9ms\n",
      "Speed: 5.5ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_60_png.rf.d9da166ee463c69580031e0462b5c001.jpg: 1024x1024 (no detections), 9.6ms\n",
      "Speed: 4.0ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1175_png.rf.32cf171a1800acd13701cee027eb0940.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 3.3ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1577_png.rf.50a94b433475441003b8b6716e35ee7c.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.3ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_119_png.rf.77de12cb566fc295603927e2a5b2748a.jpg: 1024x512 (no detections), 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../project_name/data/valid/'\n",
    "images_dir = data_dir + 'images/'\n",
    "labels_dir = data_dir + 'labels/'\n",
    "\n",
    "image_paths = os.listdir(images_dir)\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image in image_paths:\n",
    "    label_filename = os.path.splitext(image)[0] + '.txt'\n",
    "    label_path = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "    results = model.predict(source= images_dir + image, save=False)\n",
    "\n",
    "    label = ''\n",
    "\n",
    "    # check and print corresponding label if it exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = f.read()\n",
    "    else:\n",
    "        print(f\"No label file found for {image}\")\n",
    "\n",
    "    predictions.append((image, results, label))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46cd41",
   "metadata": {},
   "source": [
    "First we check if it labels an image if it has a fracture and if it labels when it does not have a fracture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f1117a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "correct = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "\n",
    "    true_label = 0 if label_is_empty else 1\n",
    "    predicted_label = 1 if has_prediction else 0\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084cb81",
   "metadata": {},
   "source": [
    "Let us now create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d1f793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUbNJREFUeJzt3XlcVFX/B/DPHZZhnWERGUgE3BDccEsJExcULc2tXCswl3LJFLWyXBBN1NyttLRETX89mWmlZe4aiqQoamkoikIqYCogIIvM+f3hwzyNoDLOAOL9vHvd14t77rnnfu806Nez3CsJIQSIiIiIZEhR1QEQERERVRUmQkRERCRbTISIiIhItpgIERERkWwxESIiIiLZYiJEREREssVEiIiIiGSLiRARERHJFhMhIiIiki0mQkRkkPPnz6Nr165Qq9WQJAlbt241afuXLl2CJEmIjo42abvVWYcOHdChQ4eqDoPoqcREiKgaunDhAt58803UqVMHVlZWUKlUCAwMxNKlS3Hnzp0KvXZoaChOnz6Njz76COvXr0erVq0q9HqVKSwsDJIkQaVSlfk5nj9/HpIkQZIkLFiwwOD2r169ioiICCQkJJggWiIyBfOqDoCIDLN9+3a88sorUCqVeP3119G4cWMUFhYiJiYGkydPxp9//okvvviiQq59584dxMbG4sMPP8TYsWMr5Bqenp64c+cOLCwsKqT9RzE3N0deXh5++ukn9O/fX+/Yhg0bYGVlhfz8/Mdq++rVq5g5cya8vLzg7+9f7vN27tz5WNcjokdjIkRUjSQnJ2PgwIHw9PTE3r174ebmpjs2ZswYJCUlYfv27RV2/evXrwMAHBwcKuwakiTBysqqwtp/FKVSicDAQPzf//1fqURo48aNePHFF7F58+ZKiSUvLw82NjawtLSslOsRyRGHxoiqkfnz5yMnJwdffvmlXhJUol69enjnnXd0+3fv3sWsWbNQt25dKJVKeHl54YMPPkBBQYHeeV5eXujRowdiYmLw7LPPwsrKCnXq1MG6det0dSIiIuDp6QkAmDx5MiRJgpeXF4B7Q0olP/9bREQEJEnSK9u1axfatWsHBwcH2NnZwcfHBx988IHu+IPmCO3duxfPP/88bG1t4eDggF69euHs2bNlXi8pKQlhYWFwcHCAWq3G0KFDkZeX9+AP9j6DBw/GL7/8gszMTF3Z0aNHcf78eQwePLhU/Zs3b2LSpElo0qQJ7OzsoFKp0L17d5w8eVJXZ//+/WjdujUAYOjQobohtpL77NChAxo3boz4+Hi0b98eNjY2us/l/jlCoaGhsLKyKnX/ISEhcHR0xNWrV8t9r0Ryx0SIqBr56aefUKdOHTz33HPlqj98+HBMnz4dLVq0wOLFixEUFISoqCgMHDiwVN2kpCS8/PLL6NKlCxYuXAhHR0eEhYXhzz//BAD07dsXixcvBgAMGjQI69evx5IlSwyK/88//0SPHj1QUFCAyMhILFy4EC+99BIOHTr00PN2796NkJAQZGRkICIiAuHh4Th8+DACAwNx6dKlUvX79++P27dvIyoqCv3790d0dDRmzpxZ7jj79u0LSZLw/fff68o2btyIhg0bokWLFqXqX7x4EVu3bkWPHj2waNEiTJ48GadPn0ZQUJAuKfH19UVkZCQAYOTIkVi/fj3Wr1+P9u3b69q5ceMGunfvDn9/fyxZsgQdO3YsM76lS5fCxcUFoaGhKC4uBgB8/vnn2LlzJ5YvXw53d/dy3yuR7AkiqhaysrIEANGrV69y1U9ISBAAxPDhw/XKJ02aJACIvXv36so8PT0FAHHw4EFdWUZGhlAqlWLixIm6suTkZAFAfPzxx3pthoaGCk9Pz1IxzJgxQ/z7j5nFixcLAOL69esPjLvkGmvWrNGV+fv7i5o1a4obN27oyk6ePCkUCoV4/fXXS13vjTfe0GuzT58+wtnZ+YHX/Pd92NraCiGEePnll0Xnzp2FEEIUFxcLjUYjZs6cWeZnkJ+fL4qLi0vdh1KpFJGRkbqyo0ePlrq3EkFBQQKAWLlyZZnHgoKC9Mp+/fVXAUDMnj1bXLx4UdjZ2YnevXs/8h6JSB97hIiqiezsbACAvb19uer//PPPAIDw8HC98okTJwJAqblEfn5+eP7553X7Li4u8PHxwcWLFx875vuVzC364YcfoNVqy3XOtWvXkJCQgLCwMDg5OenKmzZtii5duuju89/eeustvf3nn38eN27c0H2G5TF48GDs378faWlp2Lt3L9LS0socFgPuzStSKO79cVpcXIwbN27ohv2OHz9e7msqlUoMHTq0XHW7du2KN998E5GRkejbty+srKzw+eefl/taRHQPEyGiakKlUgEAbt++Xa76ly9fhkKhQL169fTKNRoNHBwccPnyZb3y2rVrl2rD0dERt27desyISxswYAACAwMxfPhwuLq6YuDAgfj2228fmhSVxOnj41PqmK+vL/755x/k5ubqld9/L46OjgBg0L288MILsLe3x3/+8x9s2LABrVu3LvVZltBqtVi8eDHq168PpVKJGjVqwMXFBadOnUJWVla5r/nMM88YNDF6wYIFcHJyQkJCApYtW4aaNWuW+1wiuoeJEFE1oVKp4O7ujj/++MOg8+6frPwgZmZmZZYLIR77GiXzV0pYW1vj4MGD2L17N1577TWcOnUKAwYMQJcuXUrVNYYx91JCqVSib9++WLt2LbZs2fLA3iAAmDNnDsLDw9G+fXt8/fXX+PXXX7Fr1y40atSo3D1fwL3PxxAnTpxARkYGAOD06dMGnUtE9zARIqpGevTogQsXLiA2NvaRdT09PaHVanH+/Hm98vT0dGRmZupWgJmCo6Oj3gqrEvf3OgGAQqFA586dsWjRIpw5cwYfffQR9u7di3379pXZdkmciYmJpY799ddfqFGjBmxtbY27gQcYPHgwTpw4gdu3b5c5wbzEd999h44dO+LLL7/EwIED0bVrVwQHB5f6TMqblJZHbm4uhg4dCj8/P4wcORLz58/H0aNHTdY+kVwwESKqRt59913Y2tpi+PDhSE9PL3X8woULWLp0KYB7QzsASq3sWrRoEQDgxRdfNFlcdevWRVZWFk6dOqUru3btGrZs2aJX7+bNm6XOLXmw4P1L+ku4ubnB398fa9eu1Uss/vjjD+zcuVN3nxWhY8eOmDVrFj755BNoNJoH1jMzMyvV27Rp0yZcuXJFr6wkYSsraTTUe++9h5SUFKxduxaLFi2Cl5cXQkNDH/g5ElHZ+EBFomqkbt262LhxIwYMGABfX1+9J0sfPnwYmzZtQlhYGACgWbNmCA0NxRdffIHMzEwEBQXh999/x9q1a9G7d+8HLs1+HAMHDsR7772HPn36YNy4ccjLy8OKFSvQoEEDvcnCkZGROHjwIF588UV4enoiIyMDn332GWrVqoV27do9sP2PP/4Y3bt3R0BAAIYNG4Y7d+5g+fLlUKvViIiIMNl93E+hUGDq1KmPrNejRw9ERkZi6NCheO6553D69Gls2LABderU0atXt25dODg4YOXKlbC3t4etrS3atGkDb29vg+Lau3cvPvvsM8yYMUO3nH/NmjXo0KEDpk2bhvnz5xvUHpGsVfGqNSJ6DOfOnRMjRowQXl5ewtLSUtjb24vAwECxfPlykZ+fr6tXVFQkZs6cKby9vYWFhYXw8PAQU6ZM0asjxL3l8y+++GKp69y/bPtBy+eFEGLnzp2icePGwtLSUvj4+Iivv/661PL5PXv2iF69egl3d3dhaWkp3N3dxaBBg8S5c+dKXeP+Jea7d+8WgYGBwtraWqhUKtGzZ09x5swZvTol17t/ef6aNWsEAJGcnPzAz1QI/eXzD/Kg5fMTJ04Ubm5uwtraWgQGBorY2Ngyl73/8MMPws/PT5ibm+vdZ1BQkGjUqFGZ1/x3O9nZ2cLT01O0aNFCFBUV6dWbMGGCUCgUIjY29qH3QET/IwlhwOxBIiIioqcI5wgRERGRbDERIiIiItliIkRERESyxUSIiIiIZIuJEBEREckWEyEiIiKSLT5Q8Smm1Wpx9epV2Nvbm/TR/kREVPGEELh9+zbc3d2hUFRcv0V+fj4KCwtN0palpSWsrKxM0lZlYSL0FLt69So8PDyqOgwiIjJCamoqatWqVSFt5+fnw9reGbibZ5L2NBoNkpOTq1UyxEToKWZvbw8AsPQLhWRmWcXREFWMlP0LqjoEogpxOzsb9bw9dH+WV4TCwkLgbh6UfqGAsX9PFBci7cxaFBYWMhGiJ0PJcJhkZslEiJ5aKpWqqkMgqlCVMrXB3MrovyeEVD2nHTMRIiIikjsJgLEJVzWdispEiIiISO4kxb3N2DaqoeoZNREREZEJsEeIiIhI7iTJBENj1XNsjIkQERGR3HFojIiIiEh+2CNEREQkdxwaIyIiIvkywdBYNR1kqp5RExEREZkAe4SIiIjkjkNjREREJFtcNUZEREQkP+wRIiIikjsOjREREZFsyXhojIkQERGR3Mm4R6h6pm9ERERUrR08eBA9e/aEu7s7JEnC1q1bS9U5e/YsXnrpJajVatja2qJ169ZISUnRHc/Pz8eYMWPg7OwMOzs79OvXD+np6QbFwUSIiIhI7kqGxozdDJCbm4tmzZrh008/LfP4hQsX0K5dOzRs2BD79+/HqVOnMG3aNFhZWenqTJgwAT/99BM2bdqEAwcO4OrVq+jbt69BcXBojIiISO4kyQRzhAwbGuvevTu6d+/+wOMffvghXnjhBcyfP19XVrduXd3PWVlZ+PLLL7Fx40Z06tQJALBmzRr4+vriyJEjaNu2bbniYI8QERERPVG0Wi22b9+OBg0aICQkBDVr1kSbNm30hs/i4+NRVFSE4OBgXVnDhg1Ru3ZtxMbGlvtaTISIiIjkTiGZZgOQnZ2ttxUUFBgcTkZGBnJycjB37lx069YNO3fuRJ8+fdC3b18cOHAAAJCWlgZLS0s4ODjonevq6oq0tLRyX4tDY0RERHJnwuXzHh4eesUzZsxARESEQU1ptVoAQK9evTBhwgQAgL+/Pw4fPoyVK1ciKCjIuFj/hYkQERERmUxqaipUKpVuX6lUGtxGjRo1YG5uDj8/P71yX19fxMTEAAA0Gg0KCwuRmZmp1yuUnp4OjUZT7mtxaIyIiEjuSp4jZOwGQKVS6W2PkwhZWlqidevWSExM1Cs/d+4cPD09AQAtW7aEhYUF9uzZozuemJiIlJQUBAQElPta7BEiIiKSuyp4snROTg6SkpJ0+8nJyUhISICTkxNq166NyZMnY8CAAWjfvj06duyIHTt24KeffsL+/fsBAGq1GsOGDUN4eDicnJygUqnw9ttvIyAgoNwrxgAmQkRERFQFjh07ho4dO+r2w8PDAQChoaGIjo5Gnz59sHLlSkRFRWHcuHHw8fHB5s2b0a5dO905ixcvhkKhQL9+/VBQUICQkBB89tlnBsUhCSGEaW6JnjTZ2dlQq9VQNhkBycyyqsMhqhC3jn5S1SEQVYjs7Gy4OquRlZWlN+fG1NdQq9VQdoiAZG716BMeQtzNR8H+iAqNtyKwR4iIiEju+NJVIiIiki2+dJWIiIhIftgjREREJHccGiMiIiLZ4tAYERERkfywR4iIiEj2TDA0Vk37VpgIERERyR2HxoiIiIjkhz1CREREcidJJlg1Vj17hJgIERERyZ2Ml89Xz6iJiIiITIA9QkRERHIn48nSTISIiIjkTsZDY0yEiIiI5E7GPULVM30jIiIiMgH2CBEREckdh8aIiIhItjg0RkRERCQ/7BEiIiKSOUmSIMm0R4iJEBERkczJORHi0BgRERHJFnuEiIiI5E7672ZsG9UQEyEiIiKZ49AYERERkQyxR4iIiEjm5NwjxESIiIhI5pgIERERkWzJORHiHCEiIiKSLfYIERERyR2XzxMREZFccWiMiIiISIbYI0RERCRzkgQT9AiZJpbKxkSIiIhI5iSYYGismmZCHBojIiKiSnfw4EH07NkT7u7ukCQJW7dufWDdt956C5IkYcmSJXrlN2/exJAhQ6BSqeDg4IBhw4YhJyfHoDiYCBEREclcyWRpYzdD5ObmolmzZvj0008fWm/Lli04cuQI3N3dSx0bMmQI/vzzT+zatQvbtm3DwYMHMXLkSIPi4NAYERGR3FXB8vnu3buje/fuD61z5coVvP322/j111/x4osv6h07e/YsduzYgaNHj6JVq1YAgOXLl+OFF17AggULykycysIeISIiIjKZ7Oxsva2goOCx2tFqtXjttdcwefJkNGrUqNTx2NhYODg46JIgAAgODoZCoUBcXFy5r8NEiIiISO5MMSz236ExDw8PqNVq3RYVFfVYIc2bNw/m5uYYN25cmcfT0tJQs2ZNvTJzc3M4OTkhLS2t3Nfh0BgREZHMmeKBiiXnp6amQqVS6cqVSqXBbcXHx2Pp0qU4fvy4CVazPRx7hIiIiGTOlJOlVSqV3vY4idBvv/2GjIwM1K5dG+bm5jA3N8fly5cxceJEeHl5AQA0Gg0yMjL0zrt79y5u3rwJjUZT7muxR4iIiIieKK+99hqCg4P1ykJCQvDaa69h6NChAICAgABkZmYiPj4eLVu2BADs3bsXWq0Wbdq0Kfe1mAgRERHJXRWsGsvJyUFSUpJuPzk5GQkJCXByckLt2rXh7OysV9/CwgIajQY+Pj4AAF9fX3Tr1g0jRozAypUrUVRUhLFjx2LgwIHlXjEGMBEiIiKSPVPOESqvY8eOoWPHjrr98PBwAEBoaCiio6PL1caGDRswduxYdO7cGQqFAv369cOyZcsMioOJEBEREVW6Dh06QAhR7vqXLl0qVebk5ISNGzcaFQcTISIiIpmrih6hJwUTISIiIpmTcyLE5fNEREQkW+wRIiIikjk59wgxESIiIpK7Klg+/6Tg0BgRERHJFnuEiIiIZI5DY0RERCRbTISIiIhItuScCHGOEBEREckWe4SIiIjkTsarxpgIERERyRyHxoiIiIhkiD1CRI/wXPO6ePu1YDRrWBtuLmoMmfQFfj5wSnf81tFPyjxv+tItWP71HgCAg8oG8ye/gpB2jSGEwI97EzBl4XfIvVNYKfdAZIy5X2zHvFW/6JXV93TF799Nq6KIyNTYI1RFwsLCIEkS5s6dq1e+detWoz/Q6Oho3f/Yf2+rV682qt2HiYiIgL+/f4W1T1XDxlqJP85dweT5/ynzuE+3KXrbmMivodVq8eO+BF2dVbNC0bCOG/qO/QQDJ6zEc83rYckHgyvpDoiM17COG/76ZY5u+2X1hKoOiUxIQum/Lw3equkkoSrvEbKyssK8efPw5ptvwtHR0aRtq1QqJCYm6pWp1epS9QoLC2FpaWnSaxtDCIHi4mKYm1f5/x4CsPvwGew+fOaBxzNu3Nbbf6F9E/wWfx6Xr9wAADTwckXwc43Q8fX5SDibAgB4b8EmfLtkFKYt3YK0f7IqLngiEzE3U8C1hqqqwyAyuSqfIxQcHAyNRoOoqKiH1tu8eTMaNWoEpVIJLy8vLFy48JFtS5IEjUajt1lbW+t6blavXg1vb29YWVkBAHbs2IF27drBwcEBzs7O6NGjBy5cuKDX5t9//41BgwbByckJtra2aNWqFeLi4hAdHY2ZM2fi5MmTuuw4Ojoaly5dgiRJSEhI0LWRmZkJSZKwf/9+AMD+/fshSRJ++eUXtGzZEkqlEjExMdBqtYiKioK3tzesra3RrFkzfPfdd4Z9wFSpXJzs0bVdY3z9Q6yurHUTb2Rm5+mSIADY/3sitFqBlo09qyJMIoNdTL0O3+4fwL/XDIyYGo3UtJtVHRKZkNG9QSYYWqsqVd7lYGZmhjlz5mDw4MEYN24catWqVapOfHw8+vfvj4iICAwYMACHDx/G6NGj4ezsjLCwsMe6blJSEjZv3ozvv/8eZmZmAIDc3FyEh4ejadOmyMnJwfTp09GnTx8kJCRAoVAgJycHQUFBeOaZZ/Djjz9Co9Hg+PHj0Gq1GDBgAP744w/s2LEDu3fvBnCv9yk9Pb3cMb3//vtYsGAB6tSpA0dHR0RFReHrr7/GypUrUb9+fRw8eBCvvvoqXFxcEBQU9Fj3TRVr0IttkJObj5/+NSzm6qzC9Vv6vUbFxVrcys6DqzP/hU1PvpaNvPDpjFdRz9MV6f9kYd6qX/DCiMU4/M2HsLe1qurwyBS4fL5q9enTB/7+/pgxYwa+/PLLUscXLVqEzp07Y9q0exPzGjRogDNnzuDjjz9+aCKUlZUFOzs73b6dnR3S0tIA3BsOW7duHVxcXHTH+/Xrp3f+V199BRcXF5w5cwaNGzfGxo0bcf36dRw9ehROTk4AgHr16um1b25uDo1GY/iHACAyMhJdunQBABQUFGDOnDnYvXs3AgICAAB16tRBTEwMPv/88zIToYKCAhQUFOj2s7OzHysOenxDXmqLTTuOoaDwblWHQmQyXQIb6X5uXP8ZtGrshSY9p2Pr7uN4rddzVRgZkfGqfGisxLx587B27VqcPXu21LGzZ88iMDBQrywwMBDnz59HcXHxA9u0t7dHQkKCbjt8+LDumKenp14SBADnz5/HoEGDUKdOHahUKnh5eQEAUlLuDWkkJCSgefPmuiTI1Fq1aqX7OSkpCXl5eejSpQvs7Ox027p160oN15WIioqCWq3WbR4eHhUSJ5UtwL8uGnhpsP6Hw3rl6Tey4eJor1dmZqaAo8oG6TeYrFL1o7a3Qb3aNXEx9XpVh0ImwqGxJ0D79u0REhKCKVOmPPZw1/0UCoVej82/2dralirr2bMnPD09sWrVKri7u0Or1aJx48YoLLy3xNna2vqxYgDuTYAuUVRU9MiYcnJyAADbt2/HM888o1dPqVSWef6UKVMQHh6u28/OzmYyVIle7RWAE2dS8Mf5K3rlR08nw0Flg2YNPXDyr1QAQPtWDaBQSIj/43JVhEpklJy8AiRf+QcDajxb1aGQich5+fwTkwgBwNy5c+Hv7w8fHx+9cl9fXxw6dEiv7NChQ2jQoIFufo+xbty4gcTERKxatQrPP/88ACAmJkavTtOmTbF69WrcvHmzzF4hS0vLUj1UJb1O165dQ/PmzQFAb+L0g/j5+UGpVCIlJaXc84GUSuUDkyR6fLbWlvD2+F/voae7Mxo3eAaZWXn4O/0WAMDe1gq9OjfHtCVbSp1/7lI6dh/+E0s/HIzwqG9gYW6G+ZP74/udx7lijKqFaUu+R7fnm8DDzQnXrmdh7hfbYaZQoF9Iy6oOjUxEku5txrZRHT1RiVCTJk0wZMgQLFu2TK984sSJaN26NWbNmoUBAwYgNjYWn3zyCT777DOTXdvR0RHOzs744osv4ObmhpSUFLz//vt6dQYNGoQ5c+agd+/eiIqKgpubG06cOAF3d3cEBATAy8sLycnJSEhIQK1atWBvbw9ra2u0bdsWc+fOhbe3NzIyMjB16tRHxmNvb49JkyZhwoQJ0Gq1aNeuHbKysnDo0CGoVCqEhoaa7N7p4fx9PbHt83d0+3PC780l27jtCMbM/BoA0LdrS0iShM2/HiuzjRHT1uLjyf2x9bO3dQ9UfH/BpooPnsgErmRkYvjUNbiZlYcajnZo06wOdq2ZiBr3DfkSVUdPVCIE3Jsw/J//6D+4rkWLFvj2228xffp0zJo1C25uboiMjDTZEBpwbwjrm2++wbhx49C4cWP4+Phg2bJl6NChg66OpaUldu7ciYkTJ+KFF17A3bt34efnh08//RTAvcnW33//PTp27IjMzEysWbMGYWFh+OqrrzBs2DC0bNkSPj4+mD9/Prp27frImGbNmgUXFxdERUXh4sWLcHBwQIsWLfDBBx+Y7L7p0Q4dPw/H1mMfWmftlkNYu+XQA49nZudhxLRoE0dGVDm+mvNGVYdAFexej5CxQ2MmCqaSSeLfk1foqZKdnQ21Wg1lkxGQzJ6cB0YSmdKDXnFCVN1lZ2fD1VmNrKwsqFQV86iNkr8n6oz7DmbK0nNnDVFckIuLy16u0HgrwhOzaoyIiIiosj1xQ2NERERUubhqjIiIiGRLzqvGODRGREREssUeISIiIplTKCQoFMZ16Qgjz68qTISIiIhkjkNjRERERDLEHiEiIiKZ46oxIiIiki0OjREREZFslfQIGbsZ4uDBg+jZsyfc3d0hSRK2bt2qO1ZUVIT33nsPTZo0ga2tLdzd3fH666/j6tWrem3cvHkTQ4YMgUqlgoODA4YNG4acnByD4mAiRERERJUuNzcXzZo1072v89/y8vJw/PhxTJs2DcePH8f333+PxMREvPTSS3r1hgwZgj///BO7du3Ctm3bcPDgQYwcOdKgODg0RkREJHNVMUeoe/fu6N69e5nH1Go1du3apVf2ySef4Nlnn0VKSgpq166Ns2fPYseOHTh69ChatWoFAFi+fDleeOEFLFiwAO7u7uWKgz1CREREMlcyR8jYDbj3Itd/bwUFBSaJMSsrC5IkwcHBAQAQGxsLBwcHXRIEAMHBwVAoFIiLiyt3u0yEiIiIyGQ8PDygVqt1W1RUlNFt5ufn47333sOgQYN0b7ZPS0tDzZo19eqZm5vDyckJaWlp5W6bQ2NEREQyJ8EEQ2O4d35qaqouWQEApVJpVLtFRUXo378/hBBYsWKFUW2VhYkQERGRzJly+bxKpdJLhIxRkgRdvnwZe/fu1WtXo9EgIyNDr/7du3dx8+ZNaDSacl+DQ2NERET0xClJgs6fP4/du3fD2dlZ73hAQAAyMzMRHx+vK9u7dy+0Wi3atGlT7uuwR4iIiEjmqmLVWE5ODpKSknT7ycnJSEhIgJOTE9zc3PDyyy/j+PHj2LZtG4qLi3XzfpycnGBpaQlfX19069YNI0aMwMqVK1FUVISxY8di4MCB5V4xBjARIiIikr2qeLL0sWPH0LFjR91+eHg4ACA0NBQRERH48ccfAQD+/v565+3btw8dOnQAAGzYsAFjx45F586doVAo0K9fPyxbtsygOJgIERERUaXr0KEDhBAPPP6wYyWcnJywceNGo+JgIkRERCRzfOkqERERyZacX7rKRIiIiEjm5NwjxOXzREREJFvsESIiIpI7EwyNoXp2CDERIiIikjsOjRERERHJEHuEiIiIZI6rxoiIiEi2ODRGREREJEPsESIiIpI5Do0RERGRbHFojIiIiEiG2CNEREQkc3LuEWIiREREJHOcI0RERESyJeceIc4RIiIiItlijxAREZHMcWiMiIiIZItDY0REREQyxB4hIiIimZNggqExk0RS+ZgIERERyZxCkqAwMhMy9vyqwqExIiIiki32CBEREckcV40RERGRbMl51RgTISIiIplTSPc2Y9uojjhHiIiIiGSLPUJERERyJ5lgaKua9ggxESIiIpI5OU+W5tAYERERyRZ7hIiIiGRO+u9/xrZRHTERIiIikjk5rxorVyJ06tSpcjfYtGnTxw6GiIiIqDKVKxHy9/eHJEkQQpR5vOSYJEkoLi42aYBERERUseT8QMVyTZZOTk7GxYsXkZycXOZWcuzixYsVHS8RERGZWMmqMWM3Qxw8eBA9e/aEu7s7JEnC1q1b9Y4LITB9+nS4ubnB2toawcHBOH/+vF6dmzdvYsiQIVCpVHBwcMCwYcOQk5NjUBzl6hHy9PQ0qFEiIiKih8nNzUWzZs3wxhtvoG/fvqWOz58/H8uWLcPatWvh7e2NadOmISQkBGfOnIGVlRUAYMiQIbh27Rp27dqFoqIiDB06FCNHjsTGjRvLHcdjLZ9fv349AgMD4e7ujsuXLwMAlixZgh9++OFxmiMiIqIqpJAkk2yG6N69O2bPno0+ffqUOiaEwJIlSzB16lT06tULTZs2xbp163D16lVdz9HZs2exY8cOrF69Gm3atEG7du2wfPlyfPPNN7h69Wr5792gqAGsWLEC4eHheOGFF5CZmambE+Tg4IAlS5YY2hwRERFVMVMOjWVnZ+ttBQUFBseTnJyMtLQ0BAcH68rUajXatGmD2NhYAEBsbCwcHBzQqlUrXZ3g4GAoFArExcWV+1oGJ0LLly/HqlWr8OGHH8LMzExX3qpVK5w+fdrQ5oiIiKiKlUyWNnYDAA8PD6jVat0WFRVlcDxpaWkAAFdXV71yV1dX3bG0tDTUrFlT77i5uTmcnJx0dcrD4OcIJScno3nz5qXKlUolcnNzDW2OiIiIniKpqalQqVS6faVSWYXRPJrBPULe3t5ISEgoVb5jxw74+vqaIiYiIiKqRKYcGlOpVHrb4yRCGo0GAJCenq5Xnp6erjum0WiQkZGhd/zu3bu4efOmrk55GNwjFB4ejjFjxiA/Px9CCPz+++/4v//7P0RFRWH16tWGNkdERERV7HEmO5fVhql4e3tDo9Fgz5498Pf3B3Bv7lFcXBxGjRoFAAgICEBmZibi4+PRsmVLAMDevXuh1WrRpk2bcl/L4ERo+PDhsLa2xtSpU5GXl4fBgwfD3d0dS5cuxcCBAw1tjoiIiGQoJycHSUlJuv3k5GQkJCTAyckJtWvXxvjx4zF79mzUr19ft3ze3d0dvXv3BgD4+vqiW7duGDFiBFauXImioiKMHTsWAwcOhLu7e7njeKx3jQ0ZMgRDhgxBXl4ecnJySk1WIiIioupD+u9mbBuGOHbsGDp27KjbDw8PBwCEhoYiOjoa7777LnJzczFy5EhkZmaiXbt22LFjh+4ZQgCwYcMGjB07Fp07d4ZCoUC/fv2wbNkyg+J47JeuZmRkIDExEcC92eYuLi6P2xQRERFVoap4xUaHDh0e+OqukvYiIyMRGRn5wDpOTk4GPTyxLAZPlr59+zZee+01uLu7IygoCEFBQXB3d8err76KrKwso4IhIiIiqkwGJ0LDhw9HXFwctm/fjszMTGRmZmLbtm04duwY3nzzzYqIkYiIiCqQQjLNVh0ZPDS2bds2/Prrr2jXrp2uLCQkBKtWrUK3bt1MGhwRERFVPL593gDOzs5Qq9WlytVqNRwdHU0SFBEREVFlMDgRmjp1KsLDw/UeX52WlobJkydj2rRpJg2OiIiIKocpHqZYHZVraKx58+Z6XV7nz59H7dq1Ubt2bQBASkoKlEolrl+/znlCRERE1Yych8bKlQiVPLyIiIiInj6mmOz8VE+WnjFjRkXHQURERFTpHvuBikRERPR04NCYAYqLi7F48WJ8++23SElJQWFhod7xmzdvmiw4IiIiqnhV8YqNJ4XBq8ZmzpyJRYsWYcCAAcjKykJ4eDj69u0LhUKBiIiICgiRiIiIqGIYnAht2LABq1atwsSJE2Fubo5BgwZh9erVmD59Oo4cOVIRMRIREVEFUkiSSbbqyOBEKC0tDU2aNAEA2NnZ6d4v1qNHD2zfvt200REREVGFM/YZQtX5WUIGJ0K1atXCtWvXAAB169bFzp07AQBHjx6FUqk0bXREREREFcjgRKhPnz7Ys2cPAODtt9/GtGnTUL9+fbz++ut44403TB4gERERVaySVWPGbtWRwavG5s6dq/t5wIAB8PT0xOHDh1G/fn307NnTpMERERFRxTPF0FY1zYMM7xG6X9u2bREeHo42bdpgzpw5poiJiIiIqFIYnQiVuHbtGl+6SkREVA3JedUYnyxNREQkc3IeGmMiREREJHNyfsWGyYbGiIiIiKqbcvcIhYeHP/T49evXjQ6GKsY7EW9BaWtX1WEQVYhRm05VdQhEFaIwL6fSrqWA8T0j1bVnpdyJ0IkTJx5Zp3379kYFQ0RERJVPzkNj5U6E9u3bV5FxEBEREVU6TpYmIiKSOUkCFFw1RkRERHKkMEEiZOz5VaW6zm0iIiIiMhp7hIiIiGSOk6WJiIhItjg0ZqDffvsNr776KgICAnDlyhUAwPr16xETE2PS4IiIiIgqksGJ0ObNmxESEgJra2ucOHECBQUFAICsrCy+fZ6IiKgaKnnXmLFbdWRwIjR79mysXLkSq1atgoWFha48MDAQx48fN2lwREREVPH49nkDJCYmlvkEabVajczMTFPERERERJVIzq/YMDhujUaDpKSkUuUxMTGoU6eOSYIiIiKip1dxcTGmTZsGb29vWFtbo27dupg1axaEELo6QghMnz4dbm5usLa2RnBwMM6fP2/yWAxOhEaMGIF33nkHcXFxkCQJV69exYYNGzBp0iSMGjXK5AESERFRxarsOULz5s3DihUr8Mknn+Ds2bOYN28e5s+fj+XLl+vqzJ8/H8uWLcPKlSsRFxcHW1tbhISEID8/36T3bvDQ2Pvvvw+tVovOnTsjLy8P7du3h1KpxKRJk/D222+bNDgiIiKqeAoYP8dHgfKff/jwYfTq1QsvvvgiAMDLywv/93//h99//x3Avd6gJUuWYOrUqejVqxcAYN26dXB1dcXWrVsxcOBAo2LVj9tAkiThww8/xM2bN/HHH3/gyJEjuH79OmbNmmWyoIiIiOjp9dxzz2HPnj04d+4cAODkyZOIiYlB9+7dAQDJyclIS0tDcHCw7hy1Wo02bdogNjbWpLE89gMVLS0t4efnZ8pYiIiIqAqYYvl7yfnZ2dl65UqlEkqlUq/s/fffR3Z2Nho2bAgzMzMUFxfjo48+wpAhQwAAaWlpAABXV1e981xdXXXHTMXgRKhjx44PfYz23r17jQqIiIiIKpcpnyzt4eGhVz5jxgxERETolX377bfYsGEDNm7ciEaNGiEhIQHjx4+Hu7s7QkNDjQvEQAYnQv7+/nr7RUVFSEhIwB9//FHpwRMREdGTJTU1FSqVSrd/f28QAEyePBnvv/++bq5PkyZNcPnyZURFRSE0NBQajQYAkJ6eDjc3N9156enppfIQYxmcCC1evLjM8oiICOTk5BgdEBEREVUuSYLRk6VLTlepVHqJUFny8vKgUOhPUzYzM4NWqwUAeHt7Q6PRYM+ePbrEJzs7G3FxcSZfoW6yl66++uqrePbZZ7FgwQJTNUlERESVwJRzhMqjZ8+e+Oijj1C7dm00atQIJ06cwKJFi/DGG2/8ty0J48ePx+zZs1G/fn14e3tj2rRpcHd3R+/evY0L9D4mS4RiY2NhZWVlquaIiIjoKbV8+XJMmzYNo0ePRkZGBtzd3fHmm29i+vTpujrvvvsucnNzMXLkSGRmZqJdu3bYsWOHyXMNgxOhvn376u0LIXDt2jUcO3YM06ZNM1lgREREVDlMOVm6POzt7bFkyRIsWbLkgXUkSUJkZCQiIyONC+wRDE6E1Gq13r5CoYCPjw8iIyPRtWtXkwVGRERElUP673/GtlEdGZQIFRcXY+jQoWjSpAkcHR0rKiYiIiKqRJXdI/QkMejJ0mZmZujatSvfMk9ERERPBYNfsdG4cWNcvHixImIhIiKiKlDSI2TsVh0ZnAjNnj0bkyZNwrZt23Dt2jVkZ2frbURERFS9SJJkkq06KvccocjISEycOBEvvPACAOCll17Su2khBCRJQnFxsemjJCIiIqoA5U6EZs6cibfeegv79u2ryHiIiIioksl5snS5EyEhBAAgKCiowoIhIiKiylfZT5Z+khg0R6i6jv8RERERlcWg5wg1aNDgkcnQzZs3jQqIiIiIKpdCkox+6aqx51cVgxKhmTNnlnqyNBEREVVvnCNUTgMHDkTNmjUrKhYiIiKiSlXuRIjzg4iIiJ5SJpgsXU1fNWb4qjEiIiJ6uiggQWFkJmPs+VWl3ImQVqutyDiIiIioinD5PBEREZEMGTRZmoiIiJ4+XDVGREREsiXn5whxaIyIiIhkiz1CREREMifnydJMhIiIiGROARMMjVXT5fMcGiMiIiLZYo8QERGRzHFojIiIiGRLAeOHiKrrEFN1jZuIiIjIaOwRIiIikjlJkox+uXp1fTk7EyEiIiKZk2D8y+OrZxrERIiIiEj2+GRpIiIiIhlijxARERFV26EtYzERIiIikjk5P0eIQ2NEREQkW+wRIiIikjkunyciIiLZ4pOliYiIiCrRlStX8Oqrr8LZ2RnW1tZo0qQJjh07pjsuhMD06dPh5uYGa2trBAcH4/z58yaPg4kQERGRzJUMjRm7ldetW7cQGBgICwsL/PLLLzhz5gwWLlwIR0dHXZ358+dj2bJlWLlyJeLi4mBra4uQkBDk5+eb9N45NEZERCRzlf1k6Xnz5sHDwwNr1qzRlXl7e+t+FkJgyZIlmDp1Knr16gUAWLduHVxdXbF161YMHDjQyGj/hz1CREREVKl+/PFHtGrVCq+88gpq1qyJ5s2bY9WqVbrjycnJSEtLQ3BwsK5MrVajTZs2iI2NNWksTISIiIhkzpRDY9nZ2XpbQUFBqetdvHgRK1asQP369fHrr79i1KhRGDduHNauXQsASEtLAwC4urrqnefq6qo7ZipMhIiIiGROYaINADw8PKBWq3VbVFRUqetptVq0aNECc+bMQfPmzTFy5EiMGDECK1eurND7LAvnCBEREcmcKZ8jlJqaCpVKpStXKpWl6rq5ucHPz0+vzNfXF5s3bwYAaDQaAEB6ejrc3Nx0ddLT0+Hv729UnPdjjxARERGZjEql0tvKSoQCAwORmJioV3bu3Dl4enoCuDdxWqPRYM+ePbrj2dnZiIuLQ0BAgEnjZY8QERGRzFX2qrEJEybgueeew5w5c9C/f3/8/vvv+OKLL/DFF1/ca0uSMH78eMyePRv169eHt7c3pk2bBnd3d/Tu3dvISPUxESIiIpK5yn7pauvWrbFlyxZMmTIFkZGR8Pb2xpIlSzBkyBBdnXfffRe5ubkYOXIkMjMz0a5dO+zYsQNWVlbGBXofJkJERERU6Xr06IEePXo88LgkSYiMjERkZGSFxsFEiIiISOYUkKAwcnDM2POrChMhIiIimavsobEnCVeNERERkWyxR4iIiEjmpP/+Z2wb1RETISIiIpnj0BgRERGRDLFHiIiISOYkE6wa49AYERERVUtyHhpjIkRERCRzck6EOEeIiIiIZIs9QkRERDLH5fNEREQkWwrp3mZsG9URh8aIiIhIttgjREREJHMcGiMiIiLZ4qoxIiIiIhlijxAREZHMSTB+aKuadggxESIiIpI7rhojIiIikiH2CBEZQKvV4vDuOJw5kYjc27mwVdmicUs/BHRqDem/MwWFEDi0Kw6njv6BgjsFcPdyR9feHeFYw6FqgycqJ6W5Ai81ckWzZ9SwtzJH6q072JRwFZdv3QEAvOjnilYeajjaWKJYq0XKrTv44Y80XLp5p4ojp8cl51VjT22PUFhYGCRJKrUlJSVVyPU6dOiA8ePHV0jb9OT4/UA8Eo6cRudeQXgj/DUEdQ/E7wficfzwSb06xw8noEvvjhgyZgAsLcyx6autuFt0twojJyq/V1vVQkNXe0T/norZv57D2fQcvBNUB2qre/92zrhdgP+cuIrZO89hwb4LuJFbhHHt68DO0qyKI6fHVbJqzNitOnpqEyEA6NatG65du6a3eXt769UpLCysoujK9qTFQ/quXL6Gen51ULehN9ROKvg0qQ+v+rVxLTUdwL3eoPhDCWjb6VnUb1QXNd1q4IUBXZGTnYvzZy5WcfREj2ahkND8GTW2nLqGpH9ycT23ENvPpON6TgGC6joDAI6mZuKvjBz8k1uIa9kF+O7kVVhbmOEZB+sqjp4el2SirTp6qhMhpVIJjUajt3Xu3Bljx47F+PHjUaNGDYSEhAAAFi1ahCZNmsDW1hYeHh4YPXo0cnJy9No7dOgQOnToABsbGzg6OiIkJAS3bt1CWFgYDhw4gKVLl+p6ni5duoTo6Gg4ODjotbF161bdEAoAREREwN/fH6tXr4a3tzesrKwAAJmZmRg+fDhcXFygUqnQqVMnnDx5ElS1nvF0w+WkVNy8fgsAkHH1Oq5cvoo6Pp4AgKyb2ci9nQfPeh66c5RWSrh5uOLq5WtVEjORIRQKCWYKCUVaoVdeWCxQt4ZtqfpmkoR2dZyQV1iMvzM5NEbVjyznCK1duxajRo3CoUOHdGUKhQLLli2Dt7c3Ll68iNGjR+Pdd9/FZ599BgBISEhA586d8cYbb2Dp0qUwNzfHvn37UFxcjKVLl+LcuXNo3LgxIiMjAQAuLi7ljicpKQmbN2/G999/DzOze13Lr7zyCqytrfHLL79ArVbj888/R+fOnXHu3Dk4OTmV2U5BQQEKCgp0+9nZ2QZ/NvRwbYJaoSC/EF8uWg+FpIBWaPF81wD4NW8IAMjNyQMA2NrZ6J1na2ejO0b0JCu4q8WFf3Lxgm9NpGXnIzv/LlrXdkAdZxtcz/lfj3VjN3sMa1sblmYKZOffxbKDF5FbWFyFkZMxFJCgMHJsS1FN+4Se6kRo27ZtsLOz0+13794dAFC/fn3Mnz9fr+6/5/d4eXlh9uzZeOutt3SJ0Pz589GqVSvdPgA0atRI97OlpSVsbGyg0WgMjrOwsBDr1q3TJU8xMTH4/fffkZGRAaVSCQBYsGABtm7diu+++w4jR44ss52oqCjMnDnT4OtT+f11+jzOJiSix8BuqOHqhIyr17F322+wU9mhcUvfqg6PyCSif0/Fa61rYW5PPxRrBVIz7+BoSiZqO/5v6OtcRg7m7DwPO6U5Aus4YXiAJ+bvOY/bBUyGqiNTDG1VzzToKU+EOnbsiBUrVuj2bW1tMWjQILRs2bJU3d27dyMqKgp//fUXsrOzcffuXeTn5yMvLw82NjZISEjAK6+8UiFxenp66vUgnTx5Ejk5OXB2dtard+fOHVy4cOGB7UyZMgXh4eG6/ezsbHh4eDywPhnuwM8xeLZDS/g2awAAcNHUQPat24jbfwyNW/rqeoJyc/Jgp/rfMEJuTh5qupW/l5CoKv2TW4jF+y/C0kyClYUZsvPvYljb2vgn9389QoXFAtdzC3E9txDJN/Mws5sPnvN2wq9/Xa/CyIkM91QnQra2tqhXr16Z5f926dIl9OjRA6NGjcJHH30EJycnxMTEYNiwYSgsLISNjQ2srQ2fBKhQKCCE/jh7UVHRI+PJycmBm5sb9u/fX6ru/XOO/k2pVOp6kKhiFBXd1ZvjBQCSQtL9f1Y7qWBrb4OUpFS4ut9LfAryC3AtNR3+bZtWerxExigsFigsvgsbCzP4udpjy6kHz3OTJMBc8VRPO326ybhL6KlOhMorPj4eWq0WCxcuhOK/v8jffvutXp2mTZtiz549Dxx6srS0RHGxfpewi4sLbt++jdzcXF2yk5CQ8Mh4WrRogbS0NJibm8PLy8vwG6IKU7ehN47sPQqVgz1q1HRG+tXrOBZzAk1a3RsmlSQJLQP9Ebv3KBxrOEDtpELMziOwU9mivl+dKo6eqHx8Xe0gAUi/XQAXOyX6NnND+u18HL50E5ZmErr7uuLU1Wxk5RfBztIcQfWc4WBtgeN/Z1Z16PSY5PwcISZCAOrVq4eioiIsX74cPXv2xKFDh7By5Uq9OlOmTEGTJk0wevRovPXWW7C0tMS+ffvwyiuvoEaNGvDy8kJcXBwuXboEOzs7ODk5oU2bNrCxscEHH3yAcePGIS4uDtHR0Y+MJzg4GAEBAejduzfmz5+PBg0a4OrVq9i+fTv69OmDVq1aVdAnQY8S3CsIMTuPYPfW/cjLyYOtyhbNnm2C5zo/q6vzbFBLFBXexa/f70VBfgGe8XLHy0N7wdyCv25UPVhbmKF3Ew0crC2QV1iME1ey8MPpNGgFoBWAq70SI5/zhK2lGXILi3H5Zh4W7ruAa9kFj26c6AnDP5kBNGvWDIsWLcK8efMwZcoUtG/fHlFRUXj99dd1dRo0aICdO3figw8+wLPPPgtra2u0adMGgwYNAgBMmjQJoaGh8PPzw507d5CcnAwvLy98/fXXmDx5MlatWoXOnTsjIiLigZOdS0iShJ9//hkffvghhg4diuvXr0Oj0aB9+/ZwdXWt0M+CHs5SaYlOPdujU8/2D6wjSRLadW2Ldl3bVmJkRKZz/O8sHP87q8xjd7UCX8ReruSIqMKZ4oGI1bNDCJK4fxILPTWys7OhVqvx7uZ4KG3tHn0CUTWUejO/qkMgqhCFeTnYODwQWVlZUKlUFXKNkr8n9iakwM7euGvk3M5GJ//aFRpvReDMNiIiIpItDo0RERHJHVeNERERkVzJedUYh8aIiIhkrqrfPj937lxIkqT3lof8/HyMGTMGzs7OsLOzQ79+/ZCenm78zd6HiRARERFVmaNHj+Lzzz9H06b6D52dMGECfvrpJ2zatAkHDhzA1atX0bdvX5Nfn4kQERGRzEkm2gyVk5ODIUOGYNWqVXB0dNSVZ2Vl4csvv8SiRYvQqVMntGzZEmvWrMHhw4dx5MiRx77PsjARIiIikjsTZkLZ2dl6W0HBgx+0OWbMGLz44osIDg7WK4+Pj0dRUZFeecOGDVG7dm3Exsaa4o51mAgRERGRyXh4eECtVuu2qKioMut98803OH78eJnH09LSYGlpWer9mq6urkhLSzNpvFw1RkREJHOmXDWWmpqq90DFsl4GnpqainfeeQe7du2ClZWVUdc1FnuEiIiIZM6Uq8ZUKpXeVlYiFB8fj4yMDLRo0QLm5uYwNzfHgQMHsGzZMpibm8PV1RWFhYXIzMzUOy89PR0ajcak984eISIiIqpUnTt3xunTp/XKhg4dioYNG+K9996Dh4cHLCwssGfPHvTr1w8AkJiYiJSUFAQEBJg0FiZCREREMlfZD5a2t7dH48aN9cpsbW3h7OysKx82bBjCw8Ph5OQElUqFt99+GwEBAWjb1rQvtGYiREREJHdP4Cs2Fi9eDIVCgX79+qGgoAAhISH47LPPTHsRMBEiIiKiJ8D+/fv19q2srPDpp5/i008/rdDrMhEiIiKSOTm/a4yJEBERkcwZ+66wkjaqIyZCREREMvcEThGqNHyOEBEREckWe4SIiIjkTsZdQkyEiIiIZE7Ok6U5NEZERESyxR4hIiIimeOqMSIiIpItGU8R4tAYERERyRd7hIiIiOROxl1CTISIiIhkjqvGiIiIiGSIPUJEREQyx1VjREREJFsyniLERIiIiEj2ZJwJcY4QERERyRZ7hIiIiGROzqvGmAgRERHJnQkmS1fTPIhDY0RERCRf7BEiIiKSORnPlWYiREREJHsyzoQ4NEZERESyxR4hIiIimeOqMSIiIpItOb9ig0NjREREJFvsESIiIpI5Gc+VZiJEREQkezLOhJgIERERyZycJ0tzjhARERHJFnuEiIiIZE6CCVaNmSSSysdEiIiISOZkPEWIQ2NEREQkX+wRIiIikjk+UJGIiIhkTDLRVj5RUVFo3bo17O3tUbNmTfTu3RuJiYl6dfLz8zFmzBg4OzvDzs4O/fr1Q3p6upH3WRoTISIiIqpUBw4cwJgxY3DkyBHs2rULRUVF6Nq1K3Jzc3V1JkyYgJ9++gmbNm3CgQMHcPXqVfTt29fksXBojIiISOYqe2hsx44devvR0dGoWbMm4uPj0b59e2RlZeHLL7/Exo0b0alTJwDAmjVr4OvriyNHjqBt27bGBfsv7BEiIiKSOVMOjGVnZ+ttBQUFj7x+VlYWAMDJyQkAEB8fj6KiIgQHB+vqNGzYELVr10ZsbKyxt6uHiRARERGZjIeHB9RqtW6Liop6aH2tVovx48cjMDAQjRs3BgCkpaXB0tISDg4OenVdXV2RlpZm0ng5NEZERCRzphwaS01NhUql0pUrlcqHnjdmzBj88ccfiImJMS6Ax8REiIiISOZM+a4xlUqllwg9zNixY7Ft2zYcPHgQtWrV0pVrNBoUFhYiMzNTr1coPT0dGo3GqDjvx6ExIiIiuavc1fMQQmDs2LHYsmUL9u7dC29vb73jLVu2hIWFBfbs2aMrS0xMREpKCgICAh7zJsvGHiEiIiKqVGPGjMHGjRvxww8/wN7eXjfvR61Ww9raGmq1GsOGDUN4eDicnJygUqnw9ttvIyAgwKQrxgAmQkRERLJX2e8aW7FiBQCgQ4cOeuVr1qxBWFgYAGDx4sVQKBTo168fCgoKEBISgs8++8zIKEtjIkRERCRzlf0cISHEI+tYWVnh008/xaeffmpEVI/GOUJEREQkW+wRIiIikjlTrhqrbpgIERERyV1lTxJ6gnBojIiIiGSLPUJEREQyJ+MOISZCREREclfZq8aeJBwaIyIiItlijxAREZHsGb9qrLoOjjERIiIikjkOjRERERHJEBMhIiIiki0OjREREcmcnIfGmAgRERHJnJxfscGhMSIiIpIt9ggRERHJHIfGiIiISLbk/IoNDo0RERGRbLFHiIiISO5k3CXERIiIiEjmuGqMiIiISIbYI0RERCRzXDVGREREsiXjKUJMhIiIiGRPxpkQ5wgRERGRbLFHiIiISObkvGqMiRAREZHMcbI0PZWEEACAgrycKo6EqOIU5uVXdQhEFaLoTi6A//1ZXpGys7OfiDaqAhOhp9jt27cBAEtfC6riSIiI6HHdvn0barW6Qtq2tLSERqNBfW8Pk7Sn0WhgaWlpkrYqiyQqI9WkKqHVanH16lXY29tDqq59ltVIdnY2PDw8kJqaCpVKVdXhEJkcv+OVSwiB27dvw93dHQpFxa1tys/PR2FhoUnasrS0hJWVlUnaqizsEXqKKRQK1KpVq6rDkB2VSsW/JOipxu945amonqB/s7KyqnbJiylx+TwRERHJFhMhIiIiki0mQkQmolQqMWPGDCiVyqoOhahC8DtOTyNOliYiIiLZYo8QERERyRYTISIiIpItJkJEREQkW0yEiIiISLaYCFG1ExYWBkmSMHfuXL3yrVu3Gv0E7ejoaEiSVGpbvXq1Ue0+TEREBPz9/SusfXr6lfxO3L8lJSVVyPU6dOiA8ePHV0jbRJWNT5amasnKygrz5s3Dm2++CUdHR5O2rVKpkJiYqFdW1tNdCwsLn6h36gghUFxcDHNz/lrLUbdu3bBmzRq9MhcXF739J+07+6TFQ/LEHiGqloKDg6HRaBAVFfXQeps3b0ajRo2gVCrh5eWFhQsXPrJtSZKg0Wj0Nmtra13PzerVq+Ht7a17JP2OHTvQrl07ODg4wNnZGT169MCFCxf02vz7778xaNAgODk5wdbWFq1atUJcXByio6Mxc+ZMnDx5Uvev+OjoaFy6dAmSJCEhIUHXRmZmJiRJwv79+wEA+/fvhyRJ+OWXX9CyZUsolUrExMRAq9UiKioK3t7esLa2RrNmzfDdd98Z9gFTtaNUKkt9bzt37oyxY8di/PjxqFGjBkJCQgAAixYtQpMmTWBrawsPDw+MHj0aOTk5eu0dOnQIHTp0gI2NDRwdHRESEoJbt24hLCwMBw4cwNKlS3Xf2UuXLiE6OhoODg56bdzfS/ug36HMzEwMHz4cLi4uUKlU6NSpE06ePFmxHxjRfzERomrJzMwMc+bMwfLly/H333+XWSc+Ph79+/fHwIEDcfr0aURERGDatGmIjo5+7OsmJSVh8+bN+P7773VJSm5uLsLDw3Hs2DHs2bMHCoUCffr0gVarBQDk5OQgKCgIV65cwY8//oiTJ0/i3XffhVarxYABAzBx4kQ0atQI165dw7Vr1zBgwACDYnr//fcxd+5cnD17Fk2bNkVUVBTWrVuHlStX4s8//8SECRPw6quv4sCBA49931R9rV27FpaWljh06BBWrlwJ4N57CJctW4Y///wTa9euxd69e/Huu+/qzklISEDnzp3h5+eH2NhYxMTEoGfPniguLsbSpUsREBCAESNG6L6zHh7lf3N5Wb9Dr7zyCjIyMvDLL78gPj4eLVq0QOfOnXHz5k2TfhZEZRJE1UxoaKjo1auXEEKItm3bijfeeEMIIcSWLVvEv7/SgwcPFl26dNE7d/LkycLPz++Bba9Zs0YAELa2trrN1dVVCCHEjBkzhIWFhcjIyHhofNevXxcAxOnTp4UQQnz++efC3t5e3Lhxo8z6M2bMEM2aNdMrS05OFgDEiRMndGW3bt0SAMS+ffuEEELs27dPABBbt27V1cnPzxc2Njbi8OHDeu0NGzZMDBo06KFxU/UVGhoqzMzM9L63L7/8sggKChLNmzd/5PmbNm0Szs7Ouv1BgwaJwMDAB9YPCgoS77zzjl7ZmjVrhFqt1iu7/3eyrN+h3377TahUKpGfn693bt26dcXnn3/+yNiJjMXJBFStzZs3D506dcKkSZNKHTt79ix69eqlVxYYGIglS5aguLgYZmZmZbZpb2+P48eP6/YViv91nHp6epaad3H+/HlMnz4dcXFx+Oeff3Q9QSkpKWjcuDESEhLQvHlzODk5PfZ9PkyrVq10PyclJSEvLw9dunTRq1NYWIjmzZtXyPXpydCxY0esWLFCt29ra4tBgwahZcuWperu3r0bUVFR+Ouvv5CdnY27d+8iPz8feXl5sLGxQUJCAl555ZUKifP+36GTJ08iJycHzs7OevXu3LlTaoiZqCIwEaJqrX379ggJCcGUKVMQFhZmkjYVCgXq1atX5jFbW9tSZT179oSnpydWrVoFd3d3aLVaNG7cGIWFhQAAa2vrx4oBuDcBukRRUdEjYyqZ57F9+3Y888wzevX4fqinm62tbZnf2/u/s5cuXUKPHj0watQofPTRR3ByckJMTAyGDRuGwsJC2NjYPPZ3Vtz3xqayvrP3x5OTkwM3Nzfd3Ld/u3/OEVFFYCJE1d7cuXPh7+8PHx8fvXJfX18cOnRIr+zQoUNo0KDBA3uDDHXjxg0kJiZi1apVeP755wEAMTExenWaNm2K1atX4+bNm2X2CllaWqK4uFivrORfzNeuXdP15Px74vSD+Pn5QalUIiUlBUFBQY9zS/SUi4+Ph1arxcKFC3UJ97fffqtXp2nTptizZw9mzpxZZhsP+s7evn0bubm5umSnPN/ZFi1aIC0tDebm5vDy8jL8hoiMxMnSVO01adIEQ4YMwbJly/TKJ06ciD179mDWrFk4d+4c1q5di08++aTMYbTH5ejoCGdnZ3zxxRdISkrC3r17ER4erldn0KBB0Gg06N27Nw4dOoSLFy9i8+bNiI2NBQB4eXkhOTkZCQkJ+Oeff1BQUABra2u0bdtWNwn6wIEDmDp16iPjsbe3x6RJkzBhwgSsXbsWFy5cwPHjx7F8+XKsXbvWZPdN1Ve9evVQVFSE5cuX4+LFi1i/fr1uEnWJKVOm4OjRoxg9ejROnTqFv/76CytWrMA///wD4N53Ni4uDpcuXdINB7dp0wY2Njb44IMPcOHCBWzcuLFcCxOCg4MREBCA3r17Y+fOnbh06RIOHz6MDz/8EMeOHauIj4BIX1VPUiIy1L8nS5dITk4WlpaW4v6v9HfffSf8/PyEhYWFqF27tvj4448f2nZZEz5LlDWpWQghdu3aJXx9fYVSqRRNmzYV+/fvFwDEli1bdHUuXbok+vXrJ1QqlbCxsRGtWrUScXFxQoh7E5z79esnHBwcBACxZs0aIYQQZ86cEQEBAcLa2lr4+/uLnTt3ljlZ+tatW3rxaLVasWTJEuHj4yMsLCyEi4uLCAkJEQcOHHjovVP1VdbvhBBlT2oWQohFixYJNzc3YW1tLUJCQsS6detKfZf2798vnnvuOaFUKoWDg4MICQnRHU9MTBRt27YV1tbWAoBITk4WQtybHF2vXj1hbW0tevToIb744otSk6XL+h3Kzs4Wb7/9tnB3dxcWFhbCw8NDDBkyRKSkpBjxqRCVjyTEfYO6RERERDLBoTEiIiKSLSZCREREJFtMhIiIiEi2mAgRERGRbDERIiIiItliIkRERESyxUSIiIiIZIuJEBFViLCwMPTu3Vu336FDB4wfP77S49i/fz8kSUJmZmaFXeP+e30clREnEZXGRIhIRsLCwiBJEiRJgqWlJerVq4fIyEjcvXu3wq/9/fffY9asWeWqW9lJgZeXF5YsWVIp1yKiJwtfukokM926dcOaNWtQUFCAn3/+GWPGjIGFhQWmTJlSqm5hYSEsLS1Nct2yXjhLRFTV2CNEJDNKpRIajQaenp4YNWoUgoOD8eOPPwL43xDPRx99BHd3d/j4+AAAUlNT0b9/fzg4OMDJyQm9evXCpUuXdG0WFxcjPDwcDg4OcHZ2xrvvvov7395z/9BYQUEB3nvvPXh4eECpVKJevXr48ssvcenSJXTs2BHAvZfaSpKEsLAwAIBWq0VUVBS8vb1hbW2NZs2a4bvvvtO7zs8//4wGDRrA2toaHTt21IvzcRQXF2PYsGG6a/r4+GDp0qVl1p05cyZcXFygUqnw1ltvobCwUHesPLETUeVjjxCRzFlbW+PGjRu6/T179kClUmHXrl0AgKKiIoSEhCAgIAC//fYbzM3NMXv2bHTr1g2nTp2CpaUlFi5ciOjoaHz11Vfw9fXFwoULsWXLFnTq1OmB13399dcRGxuLZcuWoVmzZkhOTsY///wDDw8PbN68Gf369UNiYiJUKhWsra0BAFFRUfj666+xcuVK1K9fHwcPHsSrr74KFxcXBAUFITU1FX379sWYMWMwcuRIHDt2DBMnTjTq89FqtahVqxY2bdoEZ2dnHD58GCNHjoSbmxv69++v97lZWVlh//79uHTpEoYOHQpnZ2d89NFH5YqdiKpIFb/0lYgq0b/fUq7VasWuXbuEUqkUkyZN0h13dXUVBQUFunPWr18vfHx8hFar1ZUVFBQIa2tr8euvvwohhHBzcxPz58/XHS8qKhK1atXSeyP6v9+EnpiYKACIXbt2lRnnvn37Sr0NPT8/X9jY2IjDhw/r1R02bJgYNGiQEEKIKVOmCD8/P73j7733Xqm27ufp6SkWL178wOP3GzNmjOjXr59uPzQ0VDg5OYnc3Fxd2YoVK4SdnZ0oLi4uV+xl3TMRVTz2CBHJzLZt22BnZ4eioiJotVoMHjwYERERuuNNmjTRmxd08uRJJCUlwd7eXq+d/Px8XLhwAVlZWbh27RratGmjO2Zubo5WrVqVGh4rkZCQADMzM4N6QpKSkpCXl4cuXbrolRcWFqJ58+YAgLNnz+rFAQABAQHlvsaDfPrpp/jqq6+QkpKCO3fuoLCwEP7+/np1mjVrBhsbG73r5uTkIDU1FTk5OY+MnYiqBhMhIpnp2LEjVqxYAUtLS7i7u8PcXP+PAVtbW739nJwctGzZEhs2bCjVlouLy2PFUDLUZYicnBwAwPbt2/HMM8/oHVMqlY8VR3l88803mDRpEhYuXIiAgADY29vj448/RlxcXLnbqKrYiejRmAgRyYytrS3q1atX7votWrTAf/7zH9SsWRMqlarMOm5uboiLi0P79u0BAHfv3kV8fDxatGhRZv0mTZpAq9XiwIEDCA4OLnW8pEequLhYV+bn5welUomUlJQH9iT5+vrqJn6XOHLkyKNv8iEOHTqE5557DqNHj9aVXbhwoVS9kydP4s6dO7ok78iRI7Czs4OHhwecnJweGTsRVQ2uGiOihxoyZAhq1KiBXr164bfffkNycjL279+PcePG4e+//wYAvPPOO5g7dy62bt2Kv/76C6NHj37oM4C8vLwQGhqKN954A1u3btW1+e233wIAPD09IUkStm3bhuvXryMnJwf29vaYNGkSJkyYgLVr1+LChQs4fvw4li9fjrVr1wIA3nrrLZw/fx6TJ09GYmIiNm7ciOjo6HLd55UrV5CQkKC33bp1C/Xr18exY8fw66+/4ty5c5g2bRqOHj1a6vzCwkIMGzYMZ86cwc8//4wZM2Zg7NixUCgU5YqdiKpIVU9SIqLK8+/J0oYcv3btmnj99ddFjRo1hFKpFHXq1BEjRowQWVlZQoh7k6PfeecdoVKphIODgwgPDxevv/76AydLCyHEnTt3xIQJE4Sbm5uwtLQU9erVE1999ZXueGRkpNBoNEKSJBEaGiqEuDfBe8mSJcLHx0dYWFgIFxcXERISIg4cOKA776effhL16tUTSqVSPP/88+Krr74q12RpAKW29evXi/z8fBEWFibUarVwcHAQo0aNEu+//75o1qxZqc9t+vTpwtnZWdjZ2YkRI0aI/Px8XZ1Hxc7J0kRVQxLiAbMZiYiIiJ5yHBojIiIi2WIiRERERLLFRIiIiIhki4kQERERyRYTISIiIpItJkJEREQkW0yEiIiISLaYCBEREZFsMREiIiIi2WIiRERERLLFRIiIiIhki4kQERERydb/AyRSoeElxB+zAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Fracture', 'Fracture'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680057fd",
   "metadata": {},
   "source": [
    "### Testing bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c0c7e",
   "metadata": {},
   "source": [
    "Now we will see if the bounding boxes are better than if one would select the entire screen. We use shapify to find the IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff165754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def compute_iou(pred_poly, label_poly):\n",
    "\n",
    "    # convert to Polygon class\n",
    "    pred_polygon = Polygon(pred_poly)\n",
    "    label_polygon = Polygon(label_poly)\n",
    "\n",
    "    if not pred_polygon.is_valid or not label_polygon.is_valid:\n",
    "        # print(\"Polygon is not valid\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Get intersection and union\n",
    "    intersection_area = pred_polygon.intersection(label_polygon).area\n",
    "    union_area = pred_polygon.union(label_polygon).area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection_area / union_area, label_polygon.area\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4cbc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random guess: 26, model: 67, total: 93\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_better = 0\n",
    "random_guess_better = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    # if no label is there or the model did not predict, we are unable to calculate IoU\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "    if label_is_empty or not has_prediction:\n",
    "        continue\n",
    "\n",
    "    # split lines of label\n",
    "    label_lines = label.splitlines()\n",
    "    \n",
    "    iou = 0.0\n",
    "    for line in label_lines:\n",
    "        if not line.strip():\n",
    "            continue  # skip empty labels, sanity check\n",
    "\n",
    "        label_parts = line.strip().split()\n",
    "        label_coords = list(map(float, label_parts[1:]))  # skip class label and make it float array\n",
    "        # print(label_coords)\n",
    "\n",
    "        # Go from a line to x y tuples\n",
    "        label_polygon = [(label_coords[i], label_coords[i + 1]) for i in range(0, len(label_coords), 2)]\n",
    " \n",
    "        label_area = 0.0\n",
    "        for r in result:\n",
    "            # print(r.obb.xyxyxyxyn)\n",
    "            pred_coords = r.obb.xyxyxyxyn.cpu().numpy().reshape(-1, 2)\n",
    "            # print(pred_coords)\n",
    "            pred_polygon = [tuple(point) for point in pred_coords]\n",
    "\n",
    "            iou_temp, label_area = compute_iou(pred_polygon, label_polygon)\n",
    "            iou = iou + iou_temp\n",
    "\n",
    "            #print(f\"IoU: {iou:.4f}\")\n",
    "            # print(f\"Label Area: {label_area:.4f}\")\n",
    "    \n",
    "    # Since coordinates of polygon are in normal coordinates, we only have t o check wether IoU is larger than label area. \n",
    "    # Since IoU of a an entire picture with another area has an union area of 1, and a intersection area of the label area.   \n",
    "    if iou > label_area:\n",
    "        model_better = model_better + 1\n",
    "    else:\n",
    "        random_guess_better = random_guess_better + 1\n",
    "\n",
    "print(f\"Random guess: {random_guess_better}, model: {model_better}, total: {random_guess_better + model_better}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
