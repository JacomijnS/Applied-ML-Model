{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057aba3f",
   "metadata": {},
   "source": [
    "### How to prove we are better than random guessing\n",
    "\n",
    "We have an interesting situation where we work with bounding boxes, resulting in a more difficult way to prove that we are better than random guessing. We will show multiple ways to prove that we are better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af98239",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c11277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from project_name.models.yoloModel import YOLOModel\n",
    "model = YOLOModel()\n",
    "model.load_model(\"../runs/obb/train8/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34474148",
   "metadata": {},
   "source": [
    "Let us now predict for every model and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766831e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1542_png.rf.62deacf7980320313580d67dee1ed8a6.jpg: 1024x832 (no detections), 34.6ms\n",
      "Speed: 3.5ms preprocess, 34.6ms inference, 29.2ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_978_png.rf.b1fa6e4655c393a3d4f408f32f9e721c.jpg: 1024x672 None34.9ms\n",
      "Speed: 3.6ms preprocess, 34.9ms inference, 84.0ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_155_png.rf.3b17ee4030dd0461fddfc0f3b5583153.jpg: 992x1024 (no detections), 34.4ms\n",
      "Speed: 5.9ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1773_png.rf.51512561cfc16438d9c13166f1b5457b.jpg: 1024x832 (no detections), 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_545_png.rf.8d73929cbb6032b4eb7f1f2a4d7588e7.jpg: 1024x736 (no detections), 35.5ms\n",
      "Speed: 2.7ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1421_png.rf.c0b0c1daaf1ebeba1ee030d1b730a07f.jpg: 832x1024 None34.7ms\n",
      "Speed: 3.5ms preprocess, 34.7ms inference, 2.1ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2358_png.rf.84f9ec7307749d01f6f471fa0de652b7.jpg: 1024x736 (no detections), 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_300_png.rf.6ab2b8b5cbf58cd8a3383ea39ef25a72.jpg: 1024x832 (no detections), 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1719_png.rf.0f877f7a46aeb634c73b35aec23a719e.jpg: 864x1024 None34.9ms\n",
      "Speed: 2.9ms preprocess, 34.9ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_230_png.rf.71ef1e82cb7249b449e08e1b0f4b6c9b.jpg: 1024x864 (no detections), 34.2ms\n",
      "Speed: 4.7ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1496_png.rf.efbe691d5aeabbbc208713d4bfe48a2f.jpg: 1024x576 (no detections), 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4230_png.rf.5d825ccb19e29b2676e3efaf8bcf065c.jpg: 1024x672 None9.0ms\n",
      "Speed: 2.4ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_391_png.rf.11858d7bfa2cc8d7ab964bacf53f51c4.jpg: 1024x608 None35.2ms\n",
      "Speed: 2.2ms preprocess, 35.2ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1136_png.rf.7fda8b722e043723ecb7747e64a4a23d.jpg: 1024x928 (no detections), 34.8ms\n",
      "Speed: 3.6ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_249_png.rf.0f8d53c1a26d4bc36d1f71a3a89dcebd.jpg: 1024x1024 (no detections), 10.8ms\n",
      "Speed: 5.9ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1712_png.rf.382b330b51f7f47764fd95d2b8366134.jpg: 1024x864 None8.5ms\n",
      "Speed: 3.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_321_png.rf.ecc0b07cea9e33452804e4feda7c7d6f.jpg: 832x1024 (no detections), 8.9ms\n",
      "Speed: 3.8ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_408_png.rf.6552b6bd70d78a47c52b5f1847b5ffd3.jpg: 1024x768 (no detections), 35.2ms\n",
      "Speed: 3.7ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_130_png.rf.4b9ab828064ca9b6e951e6b95689f4dd.jpg: 1024x864 (no detections), 9.6ms\n",
      "Speed: 3.6ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1793_png.rf.27e45bd8854ac26a87f4170628b848cd.jpg: 1024x832 None9.0ms\n",
      "Speed: 3.2ms preprocess, 9.0ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7615_png.rf.304bc2c5cf0a941b6846f0e132be5c3d.jpg: 896x1024 None36.6ms\n",
      "Speed: 3.7ms preprocess, 36.6ms inference, 2.3ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_269_png.rf.6b72c9e7f876960575338223b496d52c.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.7ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_12_png.rf.a1b541915e55c7475ace99b211328e97.jpg: 1024x672 (no detections), 8.8ms\n",
      "Speed: 3.0ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_41_png.rf.59c058f73450f48dd765135e939aee6a.jpg: 1024x864 (no detections), 9.2ms\n",
      "Speed: 4.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_823_png.rf.7efd238ae14f03da48c57ce9bf8d771e.jpg: 1024x864 None9.1ms\n",
      "Speed: 4.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1528_png.rf.4f919e17170960c2a7e3ed00c3550bd1.jpg: 1024x384 None37.0ms\n",
      "Speed: 1.6ms preprocess, 37.0ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1096_png.rf.0201a3553b8b76991d514ced849de390.jpg: 1024x736 (no detections), 8.9ms\n",
      "Speed: 3.3ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1047_png.rf.6d8753139f1f13e21f64d385b3b78865.jpg: 864x1024 (no detections), 7.8ms\n",
      "Speed: 3.6ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4678_png.rf.f0f6bcbfa2128ce420ed5d3809c20a58.jpg: 1024x512 (no detections), 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7_png.rf.4d60e88297d0349d04e0f8ea0189df34.jpg: 864x1024 (no detections), 8.6ms\n",
      "Speed: 3.6ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_899_png.rf.bc3b41fb512474962f558f0f53d5ebae.jpg: 864x1024 (no detections), 7.5ms\n",
      "Speed: 3.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_270_png.rf.1999fa635b0ffddd2ee908b5249452b5.jpg: 832x1024 (no detections), 7.6ms\n",
      "Speed: 3.3ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_63_png.rf.7c34eaff8da54160fa6e24bd8cc767a7.jpg: 1024x480 (no detections), 33.9ms\n",
      "Speed: 2.1ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_195_png.rf.078c6d17c523a8ace6be6124407cfdac.jpg: 1024x832 (no detections), 9.1ms\n",
      "Speed: 3.5ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1090_png.rf.de645f822a5e36175c5e988223f4eeb0.jpg: 1024x512 None7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_277_png.rf.6bec675762045dd3e65c3b265789d9d9.jpg: 1024x384 None7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1148_png.rf.dea6af8d1222d9f33b0d9b123b7d1579.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 4.6ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_199_png.rf.b38f5b057f75781bf591be85d974fa0b.jpg: 1024x1024 (no detections), 8.9ms\n",
      "Speed: 5.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2862_png.rf.3c9b51a1440c76a95163e57308759430.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 3.7ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_226_png.rf.fa703c0ade306795e1bdc15cd9a756ff.jpg: 1024x1024 None9.6ms\n",
      "Speed: 4.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_326_png.rf.1a4c5f7889b7fd54e6bd0e1812431e56.jpg: 1024x640 (no detections), 34.9ms\n",
      "Speed: 2.8ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_811_png.rf.754f721fa3c67e3b94dfbc54d4611a83.jpg: 416x1024 (no detections), 34.2ms\n",
      "Speed: 1.6ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_104_png.rf.86a9d1eeedeec79216455a5b9be63e17.jpg: 1024x576 (no detections), 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1000_png.rf.7eebc2918f75be5baf4c32a091ef963d.jpg: 1024x320 None36.1ms\n",
      "Speed: 1.4ms preprocess, 36.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 320)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_301_png.rf.33c97596525e84921e5150191ce72202.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 5.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1173_png.rf.c4789dee95f6a55c09e3b523d2f71dde.jpg: 1024x576 (no detections), 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_475_png.rf.fa5ec3299479ea066939ff8d0af4cf13.jpg: 1024x832 (no detections), 8.6ms\n",
      "Speed: 3.5ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2193_png.rf.9f98385cf14495eb548024eeca646222.jpg: 1024x544 None35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_712_png.rf.4b96cd2cf2df5d5270aa3bd79e71299c.jpg: 1024x768 (no detections), 7.7ms\n",
      "Speed: 3.6ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_593_png.rf.e9849767ca988ba52ec46984697635ed.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 4.3ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7013_png.rf.306acba02f2efd1e3fa537ae88659c30.jpg: 864x1024 None7.7ms\n",
      "Speed: 4.4ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_803_png.rf.9f52036e63cf0dd6715a051fdd0523ec.jpg: 1024x416 None35.7ms\n",
      "Speed: 1.9ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_979_png.rf.b94742342af786f4577502a93255029a.jpg: 1024x864 None8.6ms\n",
      "Speed: 3.4ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_53_png.rf.bdac91faa4e8950a4e7b01d4ec328c37.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.6ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3244_png.rf.195b93d43b6794dc57bb36564d208192.jpg: 1024x640 None7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1172_png.rf.1da7148474be8ef63728f3a3d870b0e5.jpg: 1024x960 (no detections), 35.8ms\n",
      "Speed: 4.2ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_195_png.rf.f10d144a7c86ab76285046a15305d65a.jpg: 672x1024 (no detections), 33.8ms\n",
      "Speed: 2.5ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 672, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_42_png.rf.71bc29cdbf12ea454839c26f642db1fd.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.9ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_36_png.rf.62ca9fb224a30f6641b2e5bb87a89b2b.jpg: 832x1024 (no detections), 7.1ms\n",
      "Speed: 3.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_888_png.rf.3d1e56f022463d81ebeb8574717e0619.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_441_png.rf.b14bb0935b574b3e3b9e5adf8f0e7f6b.jpg: 1024x768 None8.7ms\n",
      "Speed: 2.7ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1209_png.rf.3ce049ed968acea01b86ab912a605d0a.jpg: 1024x1024 None10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_132_png.rf.6fc485cd30f7a7ac20825477ae74d49b.jpg: 1024x864 (no detections), 8.7ms\n",
      "Speed: 3.7ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_658_png.rf.5205c44bbc71fc2c3efe407d441519a5.jpg: 832x1024 None9.3ms\n",
      "Speed: 2.9ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_198_png.rf.1319d1e6470b497f05ac13a9bb52e704.jpg: 1024x864 (no detections), 11.8ms\n",
      "Speed: 6.0ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_216_png.rf.0b423fd44fe23382c0f302560b3621aa.jpg: 1024x864 (no detections), 9.5ms\n",
      "Speed: 5.9ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_578_png.rf.8214cf7e14c6964d521feb47e2d0739a.jpg: 832x1024 (no detections), 8.8ms\n",
      "Speed: 6.5ms preprocess, 8.8ms inference, 0.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_108_png.rf.90f61f5cd524897a0f80427f56a392ba.jpg: 864x1024 (no detections), 7.6ms\n",
      "Speed: 3.4ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3613_png.rf.04279ec0c858ecc936ec0199d6e898a8.jpg: 1024x416 None8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_80_png.rf.c064670165c0e86584d7e56d8268ac07.jpg: 768x1024 (no detections), 35.1ms\n",
      "Speed: 3.7ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1667_png.rf.b92568dd097508f060cd2afd528f8e62.jpg: 1024x672 None8.3ms\n",
      "Speed: 2.4ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_73_png.rf.d5a8af47f15d4d1eb631a42d4d6b6a6f.jpg: 1024x288 None39.0ms\n",
      "Speed: 1.3ms preprocess, 39.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1223_png.rf.0a498c2e88c243ab32fbec80233b5e72.jpg: 1024x416 (no detections), 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7917_png.rf.70ee7ab7ae89188c2eb7549ccd790991.jpg: 928x1024 None34.4ms\n",
      "Speed: 5.7ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 928, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_264_png.rf.386e1a0bf8e66735ae91a5bcfc01aed5.jpg: 1024x1024 (no detections), 9.5ms\n",
      "Speed: 3.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_598_png.rf.bce390518181b7112f52a7f68e01b987.jpg: 1024x544 (no detections), 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_409_png.rf.627057f41b97e8ba901e4924a9c18743.jpg: 832x1024 (no detections), 8.4ms\n",
      "Speed: 3.6ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1611_png.rf.0c40354a305a2eba353ebdf7f135866a.jpg: 1024x736 (no detections), 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_314_png.rf.c26c252d1302ef5698071371d98689bf.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 4.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1776_png.rf.5937b77f49288051b1400ad65ef8dec7.jpg: 1024x608 None8.0ms\n",
      "Speed: 2.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3247_png.rf.d1046712e475f502514a90fa78f97525.jpg: 1024x864 None8.2ms\n",
      "Speed: 3.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_269_png.rf.223c627685f37552d6119a6af31c4821.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 3.2ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_306_png.rf.4c6dca0ca61755390c534915139b20f1.jpg: 1024x864 (no detections), 7.3ms\n",
      "Speed: 3.3ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_353_png.rf.ea40e7110fc7a9c90b87b2b7e8bf7c1e.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.2ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_396_png.rf.891d048d9125ba147174a6f7d74c57d4.jpg: 1024x864 None7.6ms\n",
      "Speed: 3.4ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2128_png.rf.f8b6cd5da365cf54ad4c51ff43bcb9bf.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.7ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3709_png.rf.9e90ec7d2dfb35d01a1c105b3b2f79c9.jpg: 1024x832 None7.8ms\n",
      "Speed: 5.3ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_285_png.rf.ec8e67b4f493b56be2f41decdf280b62.jpg: 544x1024 (no detections), 33.7ms\n",
      "Speed: 2.8ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1407_png.rf.0c6325cfef96b74c45b60545953f2408.jpg: 864x1024 (no detections), 8.3ms\n",
      "Speed: 3.7ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_620_png.rf.ce4d242b874a9cd276e610097cdcca8b.jpg: 1024x608 (no detections), 7.5ms\n",
      "Speed: 2.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1900_png.rf.b5bcead0522f3d8b2bee79cc15a5477f.jpg: 1024x512 None8.1ms\n",
      "Speed: 2.2ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2562_png.rf.2b1b0b7638fa30068783c6bb6287314d.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 4.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_496_png.rf.4805c81fce35ad473ba1b27e9c054ef8.jpg: 1024x512 None8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2894_png.rf.0a4052446539647c424af73438fb9a06.jpg: 1024x448 None35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_213_png.rf.85241ed9c6ce96f4a18e85ec6482b246.jpg: 1024x864 None7.7ms\n",
      "Speed: 4.1ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_788_png.rf.4099b0223a789948e4b727c46a6092a1.jpg: 1024x1024 None8.2ms\n",
      "Speed: 4.0ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_240_png.rf.60708ec8d8d242f30d399b095c77c7ce.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 4.5ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3593_png.rf.eb2fcd9dc83efe328d4797bd4fede777.jpg: 1024x544 None8.4ms\n",
      "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_819_png.rf.8ebb71ef2e3e83019dc323683c56af2b.jpg: 1024x832 None8.4ms\n",
      "Speed: 3.2ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_429_png.rf.7a3cdb472f4382251ece6195e7ae1e9c.jpg: 1024x1024 (no detections), 9.3ms\n",
      "Speed: 5.5ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1081_png.rf.fa746d423a8a31d9dbcf027ae78016ee.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.2ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1948_png.rf.5cee5ce80ba2f4f1d7786c8aa5bab7f7.jpg: 1024x384 None8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_655_png.rf.f5b259239c2ad2b74ddf445f88e9950d.jpg: 1024x768 None8.7ms\n",
      "Speed: 2.7ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_94_png.rf.5eb2c8f111ad826bfeb20134ba4b6b4f.jpg: 1024x864 (no detections), 8.4ms\n",
      "Speed: 3.2ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1095_png.rf.528793dae32e5d8d6aca1d9bbc7a4511.jpg: 1024x1024 (no detections), 8.5ms\n",
      "Speed: 4.5ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_382_png.rf.051ac683451d7606ad307fdeddfb4899.jpg: 1024x832 (no detections), 7.4ms\n",
      "Speed: 3.0ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_629_png.rf.f6fd2950975f3a90e805f9c36ceff961.jpg: 1024x768 (no detections), 7.7ms\n",
      "Speed: 3.5ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3956_png.rf.4ce7f45835a4a12ebb4bc3a86661f2cd.jpg: 832x1024 (no detections), 7.8ms\n",
      "Speed: 3.7ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_295_png.rf.374489979467919cbf776559311c3364.jpg: 1024x1024 None9.6ms\n",
      "Speed: 4.6ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_61_png.rf.fe73991ac017c1c2fdb5f17cc431872e.jpg: 1024x1024 None8.3ms\n",
      "Speed: 4.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_629_png.rf.fea90f1a2944bd83330277d6fda80964.jpg: 1024x864 (no detections), 7.9ms\n",
      "Speed: 3.7ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_6448_png.rf.2e1b9a29642c01c30e72e1665c936339.jpg: 832x1024 None8.0ms\n",
      "Speed: 3.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_296_png.rf.21cdb7c1c82a8992ceda7a17f7e5512e.jpg: 1024x704 None34.7ms\n",
      "Speed: 2.5ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_357_png.rf.502a511ed8bdcfa15f0a5fdadd29853e.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 3.3ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1026_png.rf.e9dc3004de762ddd0f75d8f17fb5d0f6.jpg: 800x1024 (no detections), 34.6ms\n",
      "Speed: 3.2ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 800, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_8373_png.rf.e4c1577e54e74dc96a3989672dd54301.jpg: 1024x832 None9.1ms\n",
      "Speed: 3.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_37_png.rf.3135ee0014e23b10985bb0773f2f65f9.jpg: 832x1024 (no detections), 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_58_png.rf.80a7b4275735ac207ca21321a12f834c.jpg: 1024x768 (no detections), 11.6ms\n",
      "Speed: 4.9ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1_png.rf.fa169dd72c05264f1fa1b4c2a34d1469.jpg: 1024x864 (no detections), 8.4ms\n",
      "Speed: 6.4ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1224_png.rf.7c20f6876b3efc39ea916cda7db4c00c.jpg: 1024x864 None8.2ms\n",
      "Speed: 7.9ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3789_png.rf.ecb45f4073420238817c80bb9dfb4eac.jpg: 864x1024 None8.2ms\n",
      "Speed: 3.7ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1134_png.rf.d654c836fa7d0df0490cc25e4b8b841d.jpg: 864x1024 (no detections), 7.7ms\n",
      "Speed: 4.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_482_png.rf.bbf4f0951688af0ded3e5b01e37f0dc5.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.8ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_608_png.rf.0c6cc5699987e38bd48f0c177baa7d7e.jpg: 1024x960 None9.0ms\n",
      "Speed: 4.8ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3513_png.rf.9bb8c4ef73a74c038d227eec0bea97db.jpg: 1024x352 (no detections), 35.6ms\n",
      "Speed: 1.3ms preprocess, 35.6ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_694_png.rf.49d9623643bf19c7915f785f9727f497.jpg: 1024x832 None7.8ms\n",
      "Speed: 3.2ms preprocess, 7.8ms inference, 3.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4160_png.rf.da4b4d52bb392c4587f10a38b8818fb5.jpg: 1024x512 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1147_png.rf.5081a993043bcb23358d3bea9981c9ab.jpg: 832x1024 (no detections), 8.7ms\n",
      "Speed: 4.9ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1992_png.rf.379b87658e6c985d51218b5383d5450b.jpg: 1024x544 (no detections), 8.1ms\n",
      "Speed: 2.4ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_754_png.rf.f14f77b3341ceeb367026174400a48a9.jpg: 832x1024 None8.7ms\n",
      "Speed: 3.2ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_604_png.rf.9087b8961228cd207e2d66f1dec266ef.jpg: 1024x864 None8.3ms\n",
      "Speed: 3.4ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1346_png.rf.a708d220c5342918bcb0aee7f80953d5.jpg: 832x1024 None8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_631_png.rf.557ce4882bce1244e45b277f144e1c17.jpg: 1024x832 None8.6ms\n",
      "Speed: 3.0ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image3_138_png.rf.909d6ce0c02babadf555b7aa76a9dcea.jpg: 1024x992 (no detections), 36.0ms\n",
      "Speed: 4.1ms preprocess, 36.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1722_png.rf.450ed72977e9af3f01fb362ea0f7d01e.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 3.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_410_png.rf.08c2ab9f97d8e6f07b98cf875c53d097.jpg: 896x1024 (no detections), 8.0ms\n",
      "Speed: 3.7ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3101_png.rf.99c9bb3c4d074ab053621447b8d313ed.jpg: 1024x832 None7.8ms\n",
      "Speed: 4.8ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1061_png.rf.fbf0e5b8dba2be5aa26bd71df6622c36.jpg: 768x1024 (no detections), 7.6ms\n",
      "Speed: 3.9ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_600_png.rf.da8ecb57a923d4e4d932a6c7fd8ed731.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 4.7ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image3_620_png.rf.5bda3651124325056a68ce9e18c8594e.jpg: 1024x864 None8.1ms\n",
      "Speed: 3.6ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1107_png.rf.806fab17616702fbc33f1485701759d7.jpg: 832x1024 (no detections), 8.6ms\n",
      "Speed: 3.0ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2027_png.rf.d64c9d07c29a2c6b7b76b6df9f8933e5.jpg: 1024x768 None8.9ms\n",
      "Speed: 2.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_621_png.rf.836b9d0613f68f044a0a85fcfe998b98.jpg: 1024x800 None35.1ms\n",
      "Speed: 3.1ms preprocess, 35.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1309_png.rf.792e90812ae6932e3459f8df5b9167e9.jpg: 1024x864 None7.6ms\n",
      "Speed: 4.2ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3619_png.rf.1adbb7f2ad4dfbd1e89dc200283e8fb3.jpg: 1024x416 (no detections), 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1607_png.rf.ecf3e995bfb4045c5ccbbd914a0fab8c.jpg: 544x1024 (no detections), 8.1ms\n",
      "Speed: 2.1ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1219_png.rf.29d7e993924eceda219d0666c7a24c99.jpg: 1024x416 (no detections), 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_67_png.rf.1998f3deb5276d06098206d3f64645e3.jpg: 768x1024 (no detections), 7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_96_png.rf.84e1d4c27219711b3bab09d6f54745b0.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 3.7ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1162_png.rf.a9ca54e5f83ea42fe572d4f481d44fa2.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.6ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1332_png.rf.9a84efb79d01516ea4ca07f134749fdc.jpg: 1024x736 (no detections), 7.7ms\n",
      "Speed: 3.4ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_40_png.rf.ce0d9db6d63a665f62d612038969b714.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4518_png.rf.9373c879091da54e6b8fd8b2821d4f14.jpg: 832x1024 None7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_914_png.rf.d0677318163cbe8b14f568eaf626da0d.jpg: 1024x864 None8.7ms\n",
      "Speed: 3.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_523_png.rf.4bb744d1275215860b111014ca3c09ec.jpg: 864x1024 None8.4ms\n",
      "Speed: 3.1ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2291_png.rf.62cfeef40c65e7f1fe873335c535e13d.jpg: 1024x832 None7.7ms\n",
      "Speed: 3.0ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_160_png.rf.1aab63e9be605a27276dbf3c8847a481.jpg: 864x1024 (no detections), 7.4ms\n",
      "Speed: 3.4ms preprocess, 7.4ms inference, 0.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_300_png.rf.471f4c12d227a7fc051011a489a33d77.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 3.6ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_102_png.rf.c78fe3e151ea0c9779767726479e4d4d.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.7ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_271_png.rf.983fadda251d3b2062fe025e5c232670.jpg: 1024x480 (no detections), 7.7ms\n",
      "Speed: 2.0ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1041_png.rf.b33a555439c5eb1e11622df417413e60.jpg: 1024x832 (no detections), 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_81_png.rf.d551166cae9a8e403ba25aa323d2da5f.jpg: 1024x1024 (no detections), 9.8ms\n",
      "Speed: 3.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_250_png.rf.e310e0db325a7658edf360b19df8f77a.jpg: 832x1024 None9.0ms\n",
      "Speed: 3.4ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_328_png.rf.60bc94b23a699b9ae0752b822dde1448.jpg: 1024x832 (no detections), 9.1ms\n",
      "Speed: 3.0ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_736_png.rf.b756c2fdf5d848be0d65d92829568eed.jpg: 832x1024 None8.7ms\n",
      "Speed: 3.1ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2858_png.rf.15403dca00c9e35ff409afb947497d65.jpg: 1024x288 (no detections), 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4652_png.rf.cfb34ce6d90ebf9152f2a4e1dab5d894.jpg: 1024x960 None8.4ms\n",
      "Speed: 4.9ms preprocess, 8.4ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_345_png.rf.2a31e2cc93af547720719038f3207b42.jpg: 1024x864 None7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1406_png.rf.442f619509c72d9c10acb0d70dae7b80.jpg: 1024x864 None7.1ms\n",
      "Speed: 3.2ms preprocess, 7.1ms inference, 3.1ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_553_png.rf.c99ef4abcbc78efebc1459ffbcc3a948.jpg: 1024x832 (no detections), 7.6ms\n",
      "Speed: 3.2ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_97_png.rf.f938359f79cc4aa2475eb6f204366293.jpg: 864x1024 (no detections), 7.7ms\n",
      "Speed: 3.5ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_720_png.rf.11b40e1391290b44509a2746ab59a2d5.jpg: 1024x448 None7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_315_png.rf.59b26f6bb5a4987ecd21d3ec3bd0b78b.jpg: 1024x864 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_531_png.rf.1f3150f1706276016448444146196eef.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 4.6ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_239_png.rf.b7a90eccb9159352a9d837a4a91d74e0.jpg: 896x1024 (no detections), 8.1ms\n",
      "Speed: 3.6ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1564_png.rf.d757abb86730c13f31c43a18cd6cca3f.jpg: 1024x352 (no detections), 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4344_png.rf.6c8260143f2213e8f88f00e2db33f712.jpg: 1024x512 None7.6ms\n",
      "Speed: 2.1ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_127_png.rf.3d98767272a28a66afa6490e6e58d787.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 3.6ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_339_png.rf.d2607bc319ab0fe88cdbc0bda36b597e.jpg: 1024x672 None10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_791_png.rf.78165ef6301220ccf5c21e45f0dd74d1.jpg: 832x1024 (no detections), 8.3ms\n",
      "Speed: 4.0ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_353_png.rf.79d70a2a208a0da8801a83a545abb85d.jpg: 1024x736 (no detections), 8.2ms\n",
      "Speed: 3.9ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_539_png.rf.977500280ffa2b81fa655c839bd2a9ff.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 5.3ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3194_png.rf.7e5015504f25d25ffba4ce89ab2203d4.jpg: 1024x832 (no detections), 7.6ms\n",
      "Speed: 3.6ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_399_png.rf.df2e9f74adbd02e52c25268903aa1c97.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_527_png.rf.238305d49f0df82fd065fd5803e8cdcb.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_229_png.rf.ffa8edd3e93e936bd77d678fc83a9b86.jpg: 1024x352 (no detections), 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7108_png.rf.a500619ae213e7d7abde9bedc812458f.jpg: 992x1024 None9.0ms\n",
      "Speed: 4.2ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_171_png.rf.5dd7c145fd2f9c667737c927d73fdf8c.jpg: 832x1024 (no detections), 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_803_png.rf.c72a577f195e48ac21070e632ca56480.jpg: 1024x832 None7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_335_png.rf.9b5caab439858723bfc096a05bcfc919.jpg: 1024x800 (no detections), 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_580_png.rf.7be35c41e93d72df78598df93f0d4ae5.jpg: 928x1024 (no detections), 8.5ms\n",
      "Speed: 4.6ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_534_png.rf.dabb95e8446c3dd899ed858797b725fc.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_22_png.rf.06c62da585c7275aade0d95428e27136.jpg: 1024x896 (no detections), 35.6ms\n",
      "Speed: 3.9ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_80_png.rf.d332cb93ec3ed9e475dd6603e8335b1a.jpg: 1024x416 (no detections), 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1706_png.rf.7afc2d834039cee5f5a66f18ba3130a3.jpg: 864x1024 None7.5ms\n",
      "Speed: 3.7ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2327_png.rf.767b817c34c6d8d9a23d3f3914f8485e.jpg: 1024x864 None8.0ms\n",
      "Speed: 3.9ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2351_png.rf.aa671e779b5d5e1b02b717307c96b5db.jpg: 1024x864 None7.5ms\n",
      "Speed: 3.7ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_298_png.rf.4af54f3971247f6fc07f99eb12f4a098.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 4.5ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1214_png.rf.bb8204c8269ee3bd35ae3160c52b4c8e.jpg: 864x1024 (no detections), 8.1ms\n",
      "Speed: 5.3ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2648_png.rf.c61d3b5957667c312078bb290f1fcc9e.jpg: 1024x640 (no detections), 8.2ms\n",
      "Speed: 3.8ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_5969_png.rf.92335c3790abb78579bfc9aaa2cbd87c.jpg: 832x1024 None7.8ms\n",
      "Speed: 3.4ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7058_png.rf.029c63a7047dedf16c6d0ce01533b98b.jpg: 1024x832 None8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_821_png.rf.d28b7602f6e87bab6da1503d5a0c68b3.jpg: 832x1024 None8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1129_png.rf.8db430ad388bce8ef6b097eeb1e85515.jpg: 1024x864 None8.4ms\n",
      "Speed: 3.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_658_png.rf.de1a730e82584f8353c1187bd2da792b.jpg: 1024x928 (no detections), 8.9ms\n",
      "Speed: 4.5ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1581_png.rf.a4a944611a6bca845d4190be10d96fa1.jpg: 1024x768 (no detections), 8.5ms\n",
      "Speed: 2.8ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_567_png.rf.1ff9e6e8bb53e2d54f223feea5743936.jpg: 1024x576 (no detections), 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1049_png.rf.f5a123abb07f43506a840667ad755261.jpg: 1024x448 (no detections), 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1144_png.rf.173ad79aad372549ebed7d37647c85a8.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 4.0ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2062_png.rf.96caca3e4789f028ac1329ea33773425.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 4.1ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_393_png.rf.0b282078360e227eac878ead28fe31a2.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2476_png.rf.8c979b58ab2997484f0de77252f4bae8.jpg: 1024x832 (no detections), 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3502_png.rf.30648c59cd93171dd03dae1612ebc5af.jpg: 1024x832 None7.4ms\n",
      "Speed: 3.3ms preprocess, 7.4ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2188_png.rf.45749597974be4fac3fb3041c42cac73.jpg: 1024x576 (no detections), 7.9ms\n",
      "Speed: 2.4ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_471_png.rf.88afffd3f2fe6958bd2c21514800a016.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 4.0ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_136_png.rf.84e1aaf6371bc7c19e7958cb96ae0dca.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.2ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_274_png.rf.51882731bb010b99adf0d39b585fd4b6.jpg: 992x1024 (no detections), 8.1ms\n",
      "Speed: 4.6ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_90_png.rf.349e8042b0cd6b53179ba3abb4f3c44c.jpg: 832x1024 None8.0ms\n",
      "Speed: 4.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_197_png.rf.44a35017dd213d2d77f0496072cfb41e.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 3.8ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_802_png.rf.2caa782264ce757cb9b158d442581df6.jpg: 1024x832 None8.1ms\n",
      "Speed: 3.6ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_0_png.rf.d29cab92b154a83ca5bf7e40083673a2.jpg: 1024x480 (no detections), 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_56_png.rf.07ffbc9bafd21d80db9c78b4f935ba3a.jpg: 1024x640 None8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_515_png.rf.3065d50267a627b72fecc33855b2bc00.jpg: 1024x832 (no detections), 9.2ms\n",
      "Speed: 3.5ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2589_png.rf.797db3537a24d6247c99810896acaa5f.jpg: 1024x544 (no detections), 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_287_png.rf.1963bdf654969c5d608bf0ccff643bdd.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_488_png.rf.72acecd3750485a10f790fccf953870a.jpg: 1024x608 None7.5ms\n",
      "Speed: 2.4ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_237_png.rf.3c70555567d76e1b792a000d60404ff7.jpg: 832x1024 (no detections), 7.5ms\n",
      "Speed: 4.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_690_png.rf.27ef5e8de20af80de9e977fc813e9aa8.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 3.8ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3358_png.rf.a5c4fda37c0493839f06dbaa096908e9.jpg: 832x1024 (no detections), 8.1ms\n",
      "Speed: 3.1ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_84_png.rf.f14fe69a9b05f7d5a40b1bffa61b8ead.jpg: 1024x864 (no detections), 8.4ms\n",
      "Speed: 3.5ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_707_png.rf.a68ed3710da7fc1c84ae02bfecc5caa5.jpg: 864x1024 (no detections), 8.3ms\n",
      "Speed: 3.4ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_169_png.rf.48e9271b5fe8dbc321bc7cfd10b1d55f.jpg: 1024x1024 (no detections), 9.6ms\n",
      "Speed: 4.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_796_png.rf.1776a6aa61508cdf674ad9ae5578986e.jpg: 960x1024 (no detections), 34.6ms\n",
      "Speed: 4.1ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 960, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_137_png.rf.328a6c166540a20557e3e9ad6037a1df.jpg: 832x1024 (no detections), 7.9ms\n",
      "Speed: 3.4ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_108_png.rf.7412c1568c7a0071fa200a4e13a550b7.jpg: 1024x448 (no detections), 8.8ms\n",
      "Speed: 1.9ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1036_png.rf.4743d6d5ca4bcd7df70a2083802b981a.jpg: 1024x768 (no detections), 11.8ms\n",
      "Speed: 5.1ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2487_png.rf.d44e02e62692a0c9e37bdcfc4ef78003.jpg: 1024x1024 (no detections), 8.8ms\n",
      "Speed: 6.0ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_463_png.rf.05af36580d7b5dcd5927b38341446775.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 4.1ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_173_png.rf.8d122003e666d1b43c9f60e9ef3f0ccf.jpg: 1024x768 (no detections), 8.0ms\n",
      "Speed: 4.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4372_png.rf.701d0f949a89d7d1fba3825b7008e787.jpg: 1024x928 None8.3ms\n",
      "Speed: 5.7ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_477_png.rf.734af8f7cc7e630ac0df48d90b76de7e.jpg: 1024x704 (no detections), 8.4ms\n",
      "Speed: 4.0ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1514_png.rf.8aa5c1d4670140b9b9b8b84d6ad70fbc.jpg: 992x1024 (no detections), 8.1ms\n",
      "Speed: 5.9ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_252_png.rf.65bf1d39beb17acc6be39ee33ef00908.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 4.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_947_png.rf.c09499f3067dd00d1e9fe5c6ea497ff2.jpg: 448x1024 (no detections), 33.7ms\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_71_png.rf.43f9fc97520abda66fbab2a45f328d26.jpg: 832x1024 None7.4ms\n",
      "Speed: 3.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_365_png.rf.f5615050309ece820912d0d09859a5f0.jpg: 1024x448 (no detections), 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_140_png.rf.b63ac9f299096c7ef259e393038b4be1.jpg: 832x1024 (no detections), 9.3ms\n",
      "Speed: 3.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_876_png.rf.7fc4b4b05beb4f0ff9fefbb9d4fa1ab3.jpg: 1024x800 (no detections), 9.4ms\n",
      "Speed: 3.0ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_345_png.rf.06185501b45cfee439ac1cfc71031455.jpg: 1024x352 (no detections), 9.1ms\n",
      "Speed: 1.3ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_5_png.rf.49ecdad27d07b6b8901d9931c2067bec.jpg: 320x1024 (no detections), 37.4ms\n",
      "Speed: 1.6ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 320, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_235_png.rf.b1941b81c75ae13ea1add97bf50e69aa.jpg: 1024x512 (no detections), 9.3ms\n",
      "Speed: 2.5ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_179_png.rf.2dac77668440f0f798140d3233888a64.jpg: 416x1024 (no detections), 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_388_png.rf.62b2788f9c10885a6075e38b46653acc.jpg: 896x1024 (no detections), 9.4ms\n",
      "Speed: 4.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1776_png.rf.a86ba5c63c5c70eb7718401a9e15e50e.jpg: 1024x864 (no detections), 9.5ms\n",
      "Speed: 3.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_907_png.rf.44416cf779b4ea8d8fa95afee51f5e3f.jpg: 1024x448 None8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 3.7ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1186_png.rf.3cfc6477bbc733ebdf562bb8d455e907.jpg: 1024x960 None8.9ms\n",
      "Speed: 4.1ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_110_png.rf.7fc86b639738b0a2cd6e55e66cd73b99.jpg: 1024x352 (no detections), 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_380_png.rf.a3edc138e5863941008841820260e1db.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.2ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1673_png.rf.682b1cc99342f353d0d34689f8bbaf59.jpg: 1024x480 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4373_png.rf.cbac67cb2e9e3495ee9e136ec1f2ec9a.jpg: 1024x960 None8.0ms\n",
      "Speed: 4.5ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_516_png.rf.91d7d5784d59db1c419b9be508e4a37e.jpg: 544x1024 None7.7ms\n",
      "Speed: 2.3ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_142_png.rf.d563056b013def35087f83ce9f0119be.jpg: 1024x864 None8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_111_png.rf.3893d8f7588cea4d796d26119e52637f.jpg: 1024x576 (no detections), 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_316_png.rf.22de12a5772f6b00cfdef17d8f66a7ba.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 3.3ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_263_png.rf.eab7542bedd4be63c435b906ce9d4651.jpg: 1024x1024 None9.1ms\n",
      "Speed: 4.7ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_110_png.rf.b0aff58a40e98042e37cb897e756b08e.jpg: 1024x864 (no detections), 7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1802_png.rf.ada9b0ad89e89af07a36ed5590773b7e.jpg: 1024x832 (no detections), 7.4ms\n",
      "Speed: 3.3ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1560_png.rf.22e6f99275f437d9906a7f4a608a3985.jpg: 1024x672 None11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3994_png.rf.5f4d9a9a84fa26b7ba96ae6e2e40a259.jpg: 1024x416 (no detections), 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1680_png.rf.cddfca6e707beecf1ca52e4946adeeee.jpg: 640x1024 None35.9ms\n",
      "Speed: 3.0ms preprocess, 35.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_392_png.rf.666304237d915a705d6830016a7c22c1.jpg: 1024x864 (no detections), 7.5ms\n",
      "Speed: 3.6ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_504_png.rf.a70dbb22c8ed59e8fa9535a59973eac5.jpg: 1024x896 (no detections), 8.2ms\n",
      "Speed: 4.0ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_436_png.rf.163f5793186cc5a322fad8a193d892e1.jpg: 1024x704 (no detections), 9.1ms\n",
      "Speed: 2.5ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_316_png.rf.61dbf14487cee0fdf8a82602742726a0.jpg: 1024x832 None9.4ms\n",
      "Speed: 4.8ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2929_png.rf.5281aae6cdac82080777a2ba5270e050.jpg: 1024x672 None9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1806_png.rf.8a13aca157648bc2ca883135c439304a.jpg: 864x1024 None8.1ms\n",
      "Speed: 3.9ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1031_png.rf.0f84f2c23a4cd720a80e74e445be6466.jpg: 1024x448 (no detections), 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_787_png.rf.bf6694681dafe401cf0123e5b2733ae0.jpg: 1024x704 (no detections), 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1107_png.rf.f261d35066d972aeae64edc4b34a5d7e.jpg: 544x1024 (no detections), 7.6ms\n",
      "Speed: 2.2ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_548_png.rf.042f9ef1d41fe9e8cfc84c43a6d33bed.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 4.6ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1098_png.rf.89eea31a3d88c2de0f0e605a12968a91.jpg: 992x1024 None8.2ms\n",
      "Speed: 4.9ms preprocess, 8.2ms inference, 2.7ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_98_png.rf.760919589e2de7e93ced78b7dfa3c62b.jpg: 1024x864 None8.6ms\n",
      "Speed: 3.3ms preprocess, 8.6ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_304_png.rf.02b33477f70bcaae759cf80b1c7d3730.jpg: 1024x576 (no detections), 7.5ms\n",
      "Speed: 2.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_472_png.rf.75e038dd70d155dd6355dc7906aeec02.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 3.9ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_142_png.rf.05bdcca221eee8efc0651e3fb54f932f.jpg: 832x1024 (no detections), 8.4ms\n",
      "Speed: 4.9ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_615_png.rf.cef477ebb9daca0f6f69f1eb39a7b53d.jpg: 1024x640 (no detections), 8.2ms\n",
      "Speed: 3.8ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_155_png.rf.80393d981ea40b6c1b8b9dc753eb308c.jpg: 1024x704 None9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1149_png.rf.235191fb233abff0b4926a7e39a9eea4.jpg: 864x1024 None9.1ms\n",
      "Speed: 4.0ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_290_png.rf.9635aba99a64bd1ea314ae43241ac044.jpg: 1024x576 (no detections), 8.5ms\n",
      "Speed: 2.6ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_306_png.rf.61caa0eea2f392fcfed6a6808aa4174d.jpg: 832x1024 (no detections), 8.1ms\n",
      "Speed: 3.1ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_864_png.rf.a5f519ce8af0f1f08b0439f97599d471.jpg: 1024x800 None8.4ms\n",
      "Speed: 2.9ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2152_png.rf.5c2e8ea5ec087257e61a7026e9994011.jpg: 1024x544 None7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1353_png.rf.b843ae50b5e163e10c908171716e5a39.jpg: 1024x1024 (no detections), 8.3ms\n",
      "Speed: 3.9ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_630_png.rf.cdb97ca5544b97e536d241a63bdbd547.jpg: 1024x384 (no detections), 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_21_png.rf.abe115abaadda1c0fdd552fcb1c32032.jpg: 608x1024 (no detections), 33.9ms\n",
      "Speed: 2.5ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 608, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_225_png.rf.2bfd04df55787346cd770f059fc1e7ad.jpg: 1024x1024 None8.2ms\n",
      "Speed: 4.2ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_331_png.rf.a0851e40fddcf6211958fca348bfeb78.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_356_png.rf.325517fed11d2b059bbae6715a7cb21c.jpg: 1024x832 (no detections), 7.2ms\n",
      "Speed: 3.7ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_68_png.rf.e9c730368efcd367b5e1430616ef2ed6.jpg: 1024x384 (no detections), 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1310_png.rf.daf759fe071a5733142e9847fb388e75.jpg: 1024x608 (no detections), 8.6ms\n",
      "Speed: 2.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_2337_png.rf.4f2fc3029cc730ee37e46652fea46036.jpg: 832x1024 None10.6ms\n",
      "Speed: 6.7ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_438_png.rf.dbe2dfbad9f739757ead72d520d2e633.jpg: 768x1024 (no detections), 9.5ms\n",
      "Speed: 4.8ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_206_png.rf.9af7b509cfc87217908dfda627136bf8.jpg: 1024x864 (no detections), 10.2ms\n",
      "Speed: 4.5ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_200_png.rf.5c5667178404f14d0124544574c16083.jpg: 1024x352 (no detections), 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_571_png.rf.60239651dc5d9031c3e902d0a16b200d.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.7ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2149_png.rf.2d391a8be0d79857aeb9992f52779eca.jpg: 1024x800 None8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1259_png.rf.ebfab9ae92058e7cca0b9e0fbb64c948.jpg: 1024x864 None8.3ms\n",
      "Speed: 3.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_697_png.rf.4655bfbfaecb4bb4ecf7fa9478b76ad8.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 2.9ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_610_png.rf.c0995510828ea9894c4ffdea39630aca.jpg: 1024x864 None8.9ms\n",
      "Speed: 3.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_75_png.rf.9fdc9f8a903295c283ebab365a1888e0.jpg: 1024x672 None8.9ms\n",
      "Speed: 2.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_278_png.rf.aed420df47119889bd8af834c3e1c7b8.jpg: 1024x768 (no detections), 9.2ms\n",
      "Speed: 3.4ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_513_png.rf.9c41966c467d0bbd6cfa7cd9a8a2953e.jpg: 1024x864 (no detections), 8.8ms\n",
      "Speed: 3.6ms preprocess, 8.8ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_537_png.rf.0af2211302c463dd9e59caf6ed321ecf.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.0ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_78_png.rf.d27b079cf4d9404f9590dc2641f37dc9.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 3.6ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1029_png.rf.8f1dfb1982511a9b38867fa9444965f0.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_256_png.rf.4706c2f841f94188ed9f48b4ad4dba26.jpg: 1024x384 (no detections), 7.9ms\n",
      "Speed: 2.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_340_png.rf.38e0fc7764336e7a7e3c440aea0e2daa.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1669_png.rf.66de9f8a4d5a71ec06d4c5c4c475ff6c.jpg: 1024x768 None10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1244_png.rf.10768651f2631bbbf28837704e2c9916.jpg: 768x1024 (no detections), 8.5ms\n",
      "Speed: 3.1ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1264_png.rf.3d9e9ec178bffa0af8674e9f9e69730f.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 4.8ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_120_png.rf.a013ab648c9c688362f65937d25c190b.jpg: 832x1024 (no detections), 8.8ms\n",
      "Speed: 3.1ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_894_png.rf.d87567f8b64137ef40bc1cf5852d4d03.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.2ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2145_png.rf.a47b00248c5acbae164fa4f06f39861b.jpg: 1024x576 None7.8ms\n",
      "Speed: 2.2ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_158_png.rf.50714cb0fd36bf8ad441d03d4e5c58d3.jpg: 768x1024 (no detections), 7.6ms\n",
      "Speed: 2.9ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_764_png.rf.ab8fbe451b41e67b0fac185b0f9a4f86.jpg: 768x1024 (no detections), 7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_60_png.rf.8d4f7dce9cd64f581cab952df132669a.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 4.6ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_6_png.rf.c1d09879417997e2d668378db7be1a55.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_499_png.rf.588eaa8ccf68add93a6a4280de716db4.jpg: 832x1024 (no detections), 8.6ms\n",
      "Speed: 2.9ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/coronoid-process-fracture_jpg.rf.71650459c69a9734ecd545067cf18bf4.jpg: 992x1024 (no detections), 8.1ms\n",
      "Speed: 5.9ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_891_png.rf.14e1ce98932091652500c98541ec8455.jpg: 1024x512 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_162_png.rf.0132591669e00deaf033b6d409e4d24f.jpg: 1024x864 None11.3ms\n",
      "Speed: 6.1ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_481_png.rf.d04c20719ce7d46794b21c816dcee200.jpg: 1024x864 (no detections), 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_642_png.rf.da3a47f0d75768392b53c76d73227bbc.jpg: 1024x864 (no detections), 7.2ms\n",
      "Speed: 3.5ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4311_png.rf.94bdbf6b601e08d736b5fca3590c95c1.jpg: 1024x768 (no detections), 7.8ms\n",
      "Speed: 3.7ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2552_png.rf.7a87da3fa8c3d03f97c51bcec0ead7e7.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 5.0ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_342_png.rf.c1998dcfe68bc1bab84ea57af9694c51.jpg: 1024x832 None8.1ms\n",
      "Speed: 3.4ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_786_png.rf.8799fbcb9ae8f82f1f9eadcf993428bf.jpg: 1024x704 (no detections), 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_234_png.rf.8ff82c844e5a90593e9009ee2546dfb0.jpg: 1024x608 (no detections), 9.2ms\n",
      "Speed: 2.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_644_png.rf.5e61f3b5f36f82ab41f333281faf6eca.jpg: 1024x1024 (no detections), 9.6ms\n",
      "Speed: 4.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_602_png.rf.19b335a39a1557f6b0cdf8f617e3537d.jpg: 1024x864 (no detections), 11.3ms\n",
      "Speed: 3.5ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_581_png.rf.20026bf05c575326d79e00f6772a094a.jpg: 1024x544 None11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_598_png.rf.d5cdf9fdd24ff6626fd9fe2cbc02ea34.jpg: 1024x672 (no detections), 10.8ms\n",
      "Speed: 4.0ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_632_png.rf.65725898246d01bd76a6610f79591127.jpg: 1024x1024 None8.6ms\n",
      "Speed: 7.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_536_png.rf.d14e240fc070711be3f1b81d89416b17.jpg: 1024x1024 (no detections), 7.7ms\n",
      "Speed: 5.1ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_60_png.rf.d9da166ee463c69580031e0462b5c001.jpg: 1024x1024 None7.7ms\n",
      "Speed: 4.2ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1175_png.rf.32cf171a1800acd13701cee027eb0940.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 4.8ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1577_png.rf.50a94b433475441003b8b6716e35ee7c.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 4.9ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_119_png.rf.77de12cb566fc295603927e2a5b2748a.jpg: 1024x512 (no detections), 8.9ms\n",
      "Speed: 3.0ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../project_name/data/valid/'\n",
    "images_dir = data_dir + 'images/'\n",
    "labels_dir = data_dir + 'labels/'\n",
    "\n",
    "image_paths = os.listdir(images_dir)\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image in image_paths:\n",
    "    label_filename = os.path.splitext(image)[0] + '.txt'\n",
    "    label_path = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "    results = model.predict(source= images_dir + image, save=False)\n",
    "\n",
    "    label = ''\n",
    "\n",
    "    # check and print corresponding label if it exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = f.read()\n",
    "    else:\n",
    "        print(f\"No label file found for {image}\")\n",
    "\n",
    "    predictions.append((image, results, label))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46cd41",
   "metadata": {},
   "source": [
    "First we check if it labels an image if it has a fracture and if it labels when it does not have a fracture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1117a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "correct = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "\n",
    "    true_label = 0 if label_is_empty else 1\n",
    "    predicted_label = 1 if has_prediction else 0\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084cb81",
   "metadata": {},
   "source": [
    "Let us now create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d1f793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Fracture', 'Fracture'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680057fd",
   "metadata": {},
   "source": [
    "### Testing bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c0c7e",
   "metadata": {},
   "source": [
    "Now we will see if the bounding boxes are better than if one would select the entire screen. We use shapify to find the IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff165754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def compute_iou(pred_poly, label_poly):\n",
    "\n",
    "    # convert to Polygon class\n",
    "    pred_polygon = Polygon(pred_poly)\n",
    "    label_polygon = Polygon(label_poly)\n",
    "\n",
    "    if not pred_polygon.is_valid or not label_polygon.is_valid:\n",
    "        # print(\"Polygon is not valid\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Get intersection and union\n",
    "    intersection_area = pred_polygon.intersection(label_polygon).area\n",
    "    union_area = pred_polygon.union(label_polygon).area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection_area / union_area, label_polygon.area\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4cbc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random guess: 26, model: 67, total: 93\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_better = 0\n",
    "random_guess_better = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    # if no label is there or the model did not predict, we are unable to calculate IoU\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "    if label_is_empty or not has_prediction:\n",
    "        continue\n",
    "\n",
    "    # split lines of label\n",
    "    label_lines = label.splitlines()\n",
    "    \n",
    "    iou = 0.0\n",
    "    for line in label_lines:\n",
    "        if not line.strip():\n",
    "            continue  # skip empty labels, sanity check\n",
    "\n",
    "        label_parts = line.strip().split()\n",
    "        label_coords = list(map(float, label_parts[1:]))  # skip class label and make it float array\n",
    "        # print(label_coords)\n",
    "\n",
    "        # Go from a line to x y tuples\n",
    "        label_polygon = [(label_coords[i], label_coords[i + 1]) for i in range(0, len(label_coords), 2)]\n",
    " \n",
    "        label_area = 0.0\n",
    "        for r in result:\n",
    "            # print(r.obb.xyxyxyxyn)\n",
    "            pred_coords = r.obb.xyxyxyxyn.cpu().numpy().reshape(-1, 2)\n",
    "            # print(pred_coords)\n",
    "            pred_polygon = [tuple(point) for point in pred_coords]\n",
    "\n",
    "            iou_temp, label_area = compute_iou(pred_polygon, label_polygon)\n",
    "            iou = iou + iou_temp\n",
    "\n",
    "            #print(f\"IoU: {iou:.4f}\")\n",
    "            # print(f\"Label Area: {label_area:.4f}\")\n",
    "    \n",
    "    # Since coordinates of polygon are in normal coordinates, we only have t o check wether IoU is larger than label area. \n",
    "    # Since IoU of a an entire picture with another area has an union area of 1, and a intersection area of the label area.   \n",
    "    if iou > label_area:\n",
    "        model_better = model_better + 1\n",
    "    else:\n",
    "        random_guess_better = random_guess_better + 1\n",
    "\n",
    "print(f\"Random guess: {random_guess_better}, model: {model_better}, total: {random_guess_better + model_better}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
