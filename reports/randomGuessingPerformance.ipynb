{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057aba3f",
   "metadata": {},
   "source": [
    "### How to prove we are better than random guessing\n",
    "\n",
    "We have an interesting situation where we work with bounding boxes, resulting in a more difficult way to prove that we are better than random guessing. We will show multiple ways to prove that we are better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af98239",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c11277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from project_name.models.yoloModel import YOLOModel\n",
    "model = YOLOModel()\n",
    "model.load_model(\"../runs/obb/train19/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34474148",
   "metadata": {},
   "source": [
    "Let us now predict for every model and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766831e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1542_png.rf.62deacf7980320313580d67dee1ed8a6.jpg: 1024x832 (no detections), 34.6ms\n",
      "Speed: 86.3ms preprocess, 34.6ms inference, 1274.2ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_978_png.rf.b1fa6e4655c393a3d4f408f32f9e721c.jpg: 1024x672 None34.5ms\n",
      "Speed: 4.0ms preprocess, 34.5ms inference, 2111.0ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_155_png.rf.3b17ee4030dd0461fddfc0f3b5583153.jpg: 992x1024 (no detections), 35.2ms\n",
      "Speed: 3.5ms preprocess, 35.2ms inference, 1.3ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1773_png.rf.51512561cfc16438d9c13166f1b5457b.jpg: 1024x832 None11.1ms\n",
      "Speed: 5.1ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_545_png.rf.8d73929cbb6032b4eb7f1f2a4d7588e7.jpg: 1024x736 (no detections), 34.0ms\n",
      "Speed: 2.8ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1421_png.rf.c0b0c1daaf1ebeba1ee030d1b730a07f.jpg: 832x1024 None36.2ms\n",
      "Speed: 3.0ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2358_png.rf.84f9ec7307749d01f6f471fa0de652b7.jpg: 1024x736 (no detections), 7.6ms\n",
      "Speed: 3.6ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_300_png.rf.6ab2b8b5cbf58cd8a3383ea39ef25a72.jpg: 1024x832 (no detections), 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1719_png.rf.0f877f7a46aeb634c73b35aec23a719e.jpg: 864x1024 None36.9ms\n",
      "Speed: 3.2ms preprocess, 36.9ms inference, 2.0ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_230_png.rf.71ef1e82cb7249b449e08e1b0f4b6c9b.jpg: 1024x864 (no detections), 34.2ms\n",
      "Speed: 4.7ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1496_png.rf.efbe691d5aeabbbc208713d4bfe48a2f.jpg: 1024x576 (no detections), 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4230_png.rf.5d825ccb19e29b2676e3efaf8bcf065c.jpg: 1024x672 (no detections), 8.7ms\n",
      "Speed: 2.6ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_391_png.rf.11858d7bfa2cc8d7ab964bacf53f51c4.jpg: 1024x608 None35.2ms\n",
      "Speed: 2.5ms preprocess, 35.2ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1136_png.rf.7fda8b722e043723ecb7747e64a4a23d.jpg: 1024x928 (no detections), 34.6ms\n",
      "Speed: 3.7ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_249_png.rf.0f8d53c1a26d4bc36d1f71a3a89dcebd.jpg: 1024x1024 (no detections), 12.3ms\n",
      "Speed: 5.1ms preprocess, 12.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1712_png.rf.382b330b51f7f47764fd95d2b8366134.jpg: 1024x864 None10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_321_png.rf.ecc0b07cea9e33452804e4feda7c7d6f.jpg: 832x1024 (no detections), 9.1ms\n",
      "Speed: 3.6ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_408_png.rf.6552b6bd70d78a47c52b5f1847b5ffd3.jpg: 1024x768 (no detections), 34.4ms\n",
      "Speed: 3.4ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_130_png.rf.4b9ab828064ca9b6e951e6b95689f4dd.jpg: 1024x864 (no detections), 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1793_png.rf.27e45bd8854ac26a87f4170628b848cd.jpg: 1024x832 None9.6ms\n",
      "Speed: 3.4ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7615_png.rf.304bc2c5cf0a941b6846f0e132be5c3d.jpg: 896x1024 None34.3ms\n",
      "Speed: 4.0ms preprocess, 34.3ms inference, 1.9ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_269_png.rf.6b72c9e7f876960575338223b496d52c.jpg: 1024x864 (no detections), 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_12_png.rf.a1b541915e55c7475ace99b211328e97.jpg: 1024x672 None9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_41_png.rf.59c058f73450f48dd765135e939aee6a.jpg: 1024x864 (no detections), 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_823_png.rf.7efd238ae14f03da48c57ce9bf8d771e.jpg: 1024x864 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1528_png.rf.4f919e17170960c2a7e3ed00c3550bd1.jpg: 1024x384 None427.0ms\n",
      "Speed: 1.4ms preprocess, 427.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1096_png.rf.0201a3553b8b76991d514ced849de390.jpg: 1024x736 (no detections), 9.5ms\n",
      "Speed: 3.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1047_png.rf.6d8753139f1f13e21f64d385b3b78865.jpg: 864x1024 None10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4678_png.rf.f0f6bcbfa2128ce420ed5d3809c20a58.jpg: 1024x512 (no detections), 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7_png.rf.4d60e88297d0349d04e0f8ea0189df34.jpg: 864x1024 (no detections), 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_899_png.rf.bc3b41fb512474962f558f0f53d5ebae.jpg: 864x1024 (no detections), 8.6ms\n",
      "Speed: 4.3ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_270_png.rf.1999fa635b0ffddd2ee908b5249452b5.jpg: 832x1024 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_63_png.rf.7c34eaff8da54160fa6e24bd8cc767a7.jpg: 1024x480 (no detections), 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_195_png.rf.078c6d17c523a8ace6be6124407cfdac.jpg: 1024x832 (no detections), 8.6ms\n",
      "Speed: 3.8ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1090_png.rf.de645f822a5e36175c5e988223f4eeb0.jpg: 1024x512 None7.5ms\n",
      "Speed: 2.2ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_277_png.rf.6bec675762045dd3e65c3b265789d9d9.jpg: 1024x384 (no detections), 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1148_png.rf.dea6af8d1222d9f33b0d9b123b7d1579.jpg: 832x1024 (no detections), 9.5ms\n",
      "Speed: 3.5ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_199_png.rf.b38f5b057f75781bf591be85d974fa0b.jpg: 1024x1024 (no detections), 12.0ms\n",
      "Speed: 4.6ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2862_png.rf.3c9b51a1440c76a95163e57308759430.jpg: 1024x864 None10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_226_png.rf.fa703c0ade306795e1bdc15cd9a756ff.jpg: 1024x1024 None12.0ms\n",
      "Speed: 4.2ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_326_png.rf.1a4c5f7889b7fd54e6bd0e1812431e56.jpg: 1024x640 (no detections), 34.6ms\n",
      "Speed: 2.6ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_811_png.rf.754f721fa3c67e3b94dfbc54d4611a83.jpg: 416x1024 (no detections), 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_104_png.rf.86a9d1eeedeec79216455a5b9be63e17.jpg: 1024x576 (no detections), 8.0ms\n",
      "Speed: 2.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1000_png.rf.7eebc2918f75be5baf4c32a091ef963d.jpg: 1024x320 (no detections), 527.5ms\n",
      "Speed: 1.5ms preprocess, 527.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 320)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_301_png.rf.33c97596525e84921e5150191ce72202.jpg: 1024x864 (no detections), 10.6ms\n",
      "Speed: 4.8ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1173_png.rf.c4789dee95f6a55c09e3b523d2f71dde.jpg: 1024x576 (no detections), 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_475_png.rf.fa5ec3299479ea066939ff8d0af4cf13.jpg: 1024x832 (no detections), 9.1ms\n",
      "Speed: 3.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2193_png.rf.9f98385cf14495eb548024eeca646222.jpg: 1024x544 None34.4ms\n",
      "Speed: 2.2ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_712_png.rf.4b96cd2cf2df5d5270aa3bd79e71299c.jpg: 1024x768 (no detections), 9.0ms\n",
      "Speed: 3.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_593_png.rf.e9849767ca988ba52ec46984697635ed.jpg: 1024x832 (no detections), 9.1ms\n",
      "Speed: 3.6ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7013_png.rf.306acba02f2efd1e3fa537ae88659c30.jpg: 864x1024 None8.1ms\n",
      "Speed: 3.8ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_803_png.rf.9f52036e63cf0dd6715a051fdd0523ec.jpg: 1024x416 (no detections), 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_979_png.rf.b94742342af786f4577502a93255029a.jpg: 1024x864 None10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_53_png.rf.bdac91faa4e8950a4e7b01d4ec328c37.jpg: 1024x864 (no detections), 7.9ms\n",
      "Speed: 3.6ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3244_png.rf.195b93d43b6794dc57bb36564d208192.jpg: 1024x640 None7.6ms\n",
      "Speed: 2.7ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1172_png.rf.1da7148474be8ef63728f3a3d870b0e5.jpg: 1024x960 (no detections), 33.7ms\n",
      "Speed: 4.3ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_195_png.rf.f10d144a7c86ab76285046a15305d65a.jpg: 672x1024 (no detections), 32.8ms\n",
      "Speed: 2.5ms preprocess, 32.8ms inference, 0.4ms postprocess per image at shape (1, 3, 672, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_42_png.rf.71bc29cdbf12ea454839c26f642db1fd.jpg: 832x1024 (no detections), 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_36_png.rf.62ca9fb224a30f6641b2e5bb87a89b2b.jpg: 832x1024 None9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_888_png.rf.3d1e56f022463d81ebeb8574717e0619.jpg: 832x1024 None9.2ms\n",
      "Speed: 3.1ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_441_png.rf.b14bb0935b574b3e3b9e5adf8f0e7f6b.jpg: 1024x768 (no detections), 7.5ms\n",
      "Speed: 3.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1209_png.rf.3ce049ed968acea01b86ab912a605d0a.jpg: 1024x1024 None10.9ms\n",
      "Speed: 3.8ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_132_png.rf.6fc485cd30f7a7ac20825477ae74d49b.jpg: 1024x864 (no detections), 9.1ms\n",
      "Speed: 3.7ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_658_png.rf.5205c44bbc71fc2c3efe407d441519a5.jpg: 832x1024 None8.6ms\n",
      "Speed: 3.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_198_png.rf.1319d1e6470b497f05ac13a9bb52e704.jpg: 1024x864 (no detections), 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_216_png.rf.0b423fd44fe23382c0f302560b3621aa.jpg: 1024x864 (no detections), 9.4ms\n",
      "Speed: 3.0ms preprocess, 9.4ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_578_png.rf.8214cf7e14c6964d521feb47e2d0739a.jpg: 832x1024 None9.7ms\n",
      "Speed: 2.9ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_108_png.rf.90f61f5cd524897a0f80427f56a392ba.jpg: 864x1024 (no detections), 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3613_png.rf.04279ec0c858ecc936ec0199d6e898a8.jpg: 1024x416 None8.3ms\n",
      "Speed: 1.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_80_png.rf.c064670165c0e86584d7e56d8268ac07.jpg: 768x1024 (no detections), 33.2ms\n",
      "Speed: 3.3ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1667_png.rf.b92568dd097508f060cd2afd528f8e62.jpg: 1024x672 (no detections), 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_73_png.rf.d5a8af47f15d4d1eb631a42d4d6b6a6f.jpg: 1024x288 None291.0ms\n",
      "Speed: 1.6ms preprocess, 291.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1223_png.rf.0a498c2e88c243ab32fbec80233b5e72.jpg: 1024x416 (no detections), 7.9ms\n",
      "Speed: 2.4ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7917_png.rf.70ee7ab7ae89188c2eb7549ccd790991.jpg: 928x1024 None33.6ms\n",
      "Speed: 4.4ms preprocess, 33.6ms inference, 2.3ms postprocess per image at shape (1, 3, 928, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_264_png.rf.386e1a0bf8e66735ae91a5bcfc01aed5.jpg: 1024x1024 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_598_png.rf.bce390518181b7112f52a7f68e01b987.jpg: 1024x544 (no detections), 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_409_png.rf.627057f41b97e8ba901e4924a9c18743.jpg: 832x1024 (no detections), 8.4ms\n",
      "Speed: 3.6ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1611_png.rf.0c40354a305a2eba353ebdf7f135866a.jpg: 1024x736 None7.4ms\n",
      "Speed: 2.9ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_314_png.rf.c26c252d1302ef5698071371d98689bf.jpg: 1024x864 (no detections), 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1776_png.rf.5937b77f49288051b1400ad65ef8dec7.jpg: 1024x608 None7.2ms\n",
      "Speed: 2.3ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3247_png.rf.d1046712e475f502514a90fa78f97525.jpg: 1024x864 None10.0ms\n",
      "Speed: 3.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_269_png.rf.223c627685f37552d6119a6af31c4821.jpg: 1024x864 (no detections), 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_306_png.rf.4c6dca0ca61755390c534915139b20f1.jpg: 1024x864 (no detections), 9.6ms\n",
      "Speed: 3.2ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_353_png.rf.ea40e7110fc7a9c90b87b2b7e8bf7c1e.jpg: 832x1024 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_396_png.rf.891d048d9125ba147174a6f7d74c57d4.jpg: 1024x864 None10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2128_png.rf.f8b6cd5da365cf54ad4c51ff43bcb9bf.jpg: 1024x832 None9.2ms\n",
      "Speed: 3.1ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3709_png.rf.9e90ec7d2dfb35d01a1c105b3b2f79c9.jpg: 1024x832 (no detections), 9.7ms\n",
      "Speed: 3.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_285_png.rf.ec8e67b4f493b56be2f41decdf280b62.jpg: 544x1024 (no detections), 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1407_png.rf.0c6325cfef96b74c45b60545953f2408.jpg: 864x1024 None8.9ms\n",
      "Speed: 4.0ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_620_png.rf.ce4d242b874a9cd276e610097cdcca8b.jpg: 1024x608 (no detections), 7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1900_png.rf.b5bcead0522f3d8b2bee79cc15a5477f.jpg: 1024x512 None8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2562_png.rf.2b1b0b7638fa30068783c6bb6287314d.jpg: 832x1024 (no detections), 8.6ms\n",
      "Speed: 3.4ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_496_png.rf.4805c81fce35ad473ba1b27e9c054ef8.jpg: 1024x512 (no detections), 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2894_png.rf.0a4052446539647c424af73438fb9a06.jpg: 1024x448 None34.8ms\n",
      "Speed: 2.2ms preprocess, 34.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_213_png.rf.85241ed9c6ce96f4a18e85ec6482b246.jpg: 1024x864 (no detections), 10.1ms\n",
      "Speed: 3.8ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_788_png.rf.4099b0223a789948e4b727c46a6092a1.jpg: 1024x1024 None10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_240_png.rf.60708ec8d8d242f30d399b095c77c7ce.jpg: 1024x864 (no detections), 9.4ms\n",
      "Speed: 4.0ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3593_png.rf.eb2fcd9dc83efe328d4797bd4fede777.jpg: 1024x544 (no detections), 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_819_png.rf.8ebb71ef2e3e83019dc323683c56af2b.jpg: 1024x832 None9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_429_png.rf.7a3cdb472f4382251ece6195e7ae1e9c.jpg: 1024x1024 (no detections), 11.8ms\n",
      "Speed: 4.5ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1081_png.rf.fa746d423a8a31d9dbcf027ae78016ee.jpg: 1024x832 (no detections), 9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1948_png.rf.5cee5ce80ba2f4f1d7786c8aa5bab7f7.jpg: 1024x384 (no detections), 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_655_png.rf.f5b259239c2ad2b74ddf445f88e9950d.jpg: 1024x768 (no detections), 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_94_png.rf.5eb2c8f111ad826bfeb20134ba4b6b4f.jpg: 1024x864 (no detections), 9.7ms\n",
      "Speed: 3.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1095_png.rf.528793dae32e5d8d6aca1d9bbc7a4511.jpg: 1024x1024 None11.8ms\n",
      "Speed: 4.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_382_png.rf.051ac683451d7606ad307fdeddfb4899.jpg: 1024x832 (no detections), 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_629_png.rf.f6fd2950975f3a90e805f9c36ceff961.jpg: 1024x768 (no detections), 8.9ms\n",
      "Speed: 2.8ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3956_png.rf.4ce7f45835a4a12ebb4bc3a86661f2cd.jpg: 832x1024 (no detections), 9.2ms\n",
      "Speed: 2.9ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_295_png.rf.374489979467919cbf776559311c3364.jpg: 1024x1024 None9.8ms\n",
      "Speed: 4.6ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_61_png.rf.fe73991ac017c1c2fdb5f17cc431872e.jpg: 1024x1024 None8.9ms\n",
      "Speed: 3.5ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_629_png.rf.fea90f1a2944bd83330277d6fda80964.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 3.4ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_6448_png.rf.2e1b9a29642c01c30e72e1665c936339.jpg: 832x1024 None7.5ms\n",
      "Speed: 3.4ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_296_png.rf.21cdb7c1c82a8992ceda7a17f7e5512e.jpg: 1024x704 None33.5ms\n",
      "Speed: 2.6ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_357_png.rf.502a511ed8bdcfa15f0a5fdadd29853e.jpg: 1024x832 (no detections), 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1026_png.rf.e9dc3004de762ddd0f75d8f17fb5d0f6.jpg: 800x1024 (no detections), 33.7ms\n",
      "Speed: 2.9ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 800, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_8373_png.rf.e4c1577e54e74dc96a3989672dd54301.jpg: 1024x832 (no detections), 7.6ms\n",
      "Speed: 3.7ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_37_png.rf.3135ee0014e23b10985bb0773f2f65f9.jpg: 832x1024 (no detections), 7.4ms\n",
      "Speed: 3.2ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_58_png.rf.80a7b4275735ac207ca21321a12f834c.jpg: 1024x768 (no detections), 7.4ms\n",
      "Speed: 3.0ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1_png.rf.fa169dd72c05264f1fa1b4c2a34d1469.jpg: 1024x864 (no detections), 9.6ms\n",
      "Speed: 3.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1224_png.rf.7c20f6876b3efc39ea916cda7db4c00c.jpg: 1024x864 None9.1ms\n",
      "Speed: 3.3ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3789_png.rf.ecb45f4073420238817c80bb9dfb4eac.jpg: 864x1024 None7.5ms\n",
      "Speed: 3.2ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1134_png.rf.d654c836fa7d0df0490cc25e4b8b841d.jpg: 864x1024 (no detections), 7.8ms\n",
      "Speed: 3.2ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_482_png.rf.bbf4f0951688af0ded3e5b01e37f0dc5.jpg: 1024x832 (no detections), 8.4ms\n",
      "Speed: 3.2ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_608_png.rf.0c6cc5699987e38bd48f0c177baa7d7e.jpg: 1024x960 None10.0ms\n",
      "Speed: 4.2ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3513_png.rf.9bb8c4ef73a74c038d227eec0bea97db.jpg: 1024x352 None32.7ms\n",
      "Speed: 1.5ms preprocess, 32.7ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_694_png.rf.49d9623643bf19c7915f785f9727f497.jpg: 1024x832 None7.6ms\n",
      "Speed: 3.3ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4160_png.rf.da4b4d52bb392c4587f10a38b8818fb5.jpg: 1024x512 (no detections), 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1147_png.rf.5081a993043bcb23358d3bea9981c9ab.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.3ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1992_png.rf.379b87658e6c985d51218b5383d5450b.jpg: 1024x544 (no detections), 7.5ms\n",
      "Speed: 2.5ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_754_png.rf.f14f77b3341ceeb367026174400a48a9.jpg: 832x1024 None9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_604_png.rf.9087b8961228cd207e2d66f1dec266ef.jpg: 1024x864 None7.9ms\n",
      "Speed: 3.5ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1346_png.rf.a708d220c5342918bcb0aee7f80953d5.jpg: 832x1024 (no detections), 8.6ms\n",
      "Speed: 3.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_631_png.rf.557ce4882bce1244e45b277f144e1c17.jpg: 1024x832 (no detections), 9.0ms\n",
      "Speed: 2.9ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image3_138_png.rf.909d6ce0c02babadf555b7aa76a9dcea.jpg: 1024x992 (no detections), 33.5ms\n",
      "Speed: 4.2ms preprocess, 33.5ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1722_png.rf.450ed72977e9af3f01fb362ea0f7d01e.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 3.4ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_410_png.rf.08c2ab9f97d8e6f07b98cf875c53d097.jpg: 896x1024 (no detections), 8.4ms\n",
      "Speed: 3.6ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3101_png.rf.99c9bb3c4d074ab053621447b8d313ed.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 3.5ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1061_png.rf.fbf0e5b8dba2be5aa26bd71df6622c36.jpg: 768x1024 (no detections), 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_600_png.rf.da8ecb57a923d4e4d932a6c7fd8ed731.jpg: 1024x864 (no detections), 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image3_620_png.rf.5bda3651124325056a68ce9e18c8594e.jpg: 1024x864 None8.7ms\n",
      "Speed: 3.2ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1107_png.rf.806fab17616702fbc33f1485701759d7.jpg: 832x1024 (no detections), 7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2027_png.rf.d64c9d07c29a2c6b7b76b6df9f8933e5.jpg: 1024x768 (no detections), 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_621_png.rf.836b9d0613f68f044a0a85fcfe998b98.jpg: 1024x800 None33.3ms\n",
      "Speed: 3.2ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1309_png.rf.792e90812ae6932e3459f8df5b9167e9.jpg: 1024x864 (no detections), 9.1ms\n",
      "Speed: 3.8ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3619_png.rf.1adbb7f2ad4dfbd1e89dc200283e8fb3.jpg: 1024x416 (no detections), 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1607_png.rf.ecf3e995bfb4045c5ccbbd914a0fab8c.jpg: 544x1024 (no detections), 7.7ms\n",
      "Speed: 2.1ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1219_png.rf.29d7e993924eceda219d0666c7a24c99.jpg: 1024x416 (no detections), 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_67_png.rf.1998f3deb5276d06098206d3f64645e3.jpg: 768x1024 (no detections), 7.6ms\n",
      "Speed: 3.4ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_96_png.rf.84e1d4c27219711b3bab09d6f54745b0.jpg: 1024x864 (no detections), 7.7ms\n",
      "Speed: 4.0ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1162_png.rf.a9ca54e5f83ea42fe572d4f481d44fa2.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.0ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1332_png.rf.9a84efb79d01516ea4ca07f134749fdc.jpg: 1024x736 (no detections), 7.6ms\n",
      "Speed: 2.9ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_40_png.rf.ce0d9db6d63a665f62d612038969b714.jpg: 832x1024 (no detections), 7.8ms\n",
      "Speed: 3.3ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4518_png.rf.9373c879091da54e6b8fd8b2821d4f14.jpg: 832x1024 (no detections), 7.2ms\n",
      "Speed: 3.6ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_914_png.rf.d0677318163cbe8b14f568eaf626da0d.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.5ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_523_png.rf.4bb744d1275215860b111014ca3c09ec.jpg: 864x1024 None7.9ms\n",
      "Speed: 3.5ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2291_png.rf.62cfeef40c65e7f1fe873335c535e13d.jpg: 1024x832 None7.7ms\n",
      "Speed: 3.2ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_160_png.rf.1aab63e9be605a27276dbf3c8847a481.jpg: 864x1024 (no detections), 8.3ms\n",
      "Speed: 3.5ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_300_png.rf.471f4c12d227a7fc051011a489a33d77.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.1ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_102_png.rf.c78fe3e151ea0c9779767726479e4d4d.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_271_png.rf.983fadda251d3b2062fe025e5c232670.jpg: 1024x480 (no detections), 7.5ms\n",
      "Speed: 2.1ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1041_png.rf.b33a555439c5eb1e11622df417413e60.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_81_png.rf.d551166cae9a8e403ba25aa323d2da5f.jpg: 1024x1024 (no detections), 8.9ms\n",
      "Speed: 4.0ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_250_png.rf.e310e0db325a7658edf360b19df8f77a.jpg: 832x1024 None7.7ms\n",
      "Speed: 3.7ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_328_png.rf.60bc94b23a699b9ae0752b822dde1448.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 2.9ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_736_png.rf.b756c2fdf5d848be0d65d92829568eed.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2858_png.rf.15403dca00c9e35ff409afb947497d65.jpg: 1024x288 (no detections), 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4652_png.rf.cfb34ce6d90ebf9152f2a4e1dab5d894.jpg: 1024x960 None7.6ms\n",
      "Speed: 4.2ms preprocess, 7.6ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_345_png.rf.2a31e2cc93af547720719038f3207b42.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1406_png.rf.442f619509c72d9c10acb0d70dae7b80.jpg: 1024x864 None7.1ms\n",
      "Speed: 3.2ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_553_png.rf.c99ef4abcbc78efebc1459ffbcc3a948.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 3.1ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_97_png.rf.f938359f79cc4aa2475eb6f204366293.jpg: 864x1024 (no detections), 7.4ms\n",
      "Speed: 3.6ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_720_png.rf.11b40e1391290b44509a2746ab59a2d5.jpg: 1024x448 None7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_315_png.rf.59b26f6bb5a4987ecd21d3ec3bd0b78b.jpg: 1024x864 None7.8ms\n",
      "Speed: 3.6ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_531_png.rf.1f3150f1706276016448444146196eef.jpg: 1024x832 (no detections), 7.5ms\n",
      "Speed: 3.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_239_png.rf.b7a90eccb9159352a9d837a4a91d74e0.jpg: 896x1024 (no detections), 8.4ms\n",
      "Speed: 3.6ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1564_png.rf.d757abb86730c13f31c43a18cd6cca3f.jpg: 1024x352 (no detections), 7.6ms\n",
      "Speed: 1.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4344_png.rf.6c8260143f2213e8f88f00e2db33f712.jpg: 1024x512 (no detections), 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_127_png.rf.3d98767272a28a66afa6490e6e58d787.jpg: 1024x864 (no detections), 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_339_png.rf.d2607bc319ab0fe88cdbc0bda36b597e.jpg: 1024x672 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_791_png.rf.78165ef6301220ccf5c21e45f0dd74d1.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.1ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_353_png.rf.79d70a2a208a0da8801a83a545abb85d.jpg: 1024x736 (no detections), 8.3ms\n",
      "Speed: 3.0ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_539_png.rf.977500280ffa2b81fa655c839bd2a9ff.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 4.1ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3194_png.rf.7e5015504f25d25ffba4ce89ab2203d4.jpg: 1024x832 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_399_png.rf.df2e9f74adbd02e52c25268903aa1c97.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_527_png.rf.238305d49f0df82fd065fd5803e8cdcb.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_229_png.rf.ffa8edd3e93e936bd77d678fc83a9b86.jpg: 1024x352 (no detections), 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7108_png.rf.a500619ae213e7d7abde9bedc812458f.jpg: 992x1024 None12.2ms\n",
      "Speed: 4.0ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_171_png.rf.5dd7c145fd2f9c667737c927d73fdf8c.jpg: 832x1024 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_803_png.rf.c72a577f195e48ac21070e632ca56480.jpg: 1024x832 None10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_335_png.rf.9b5caab439858723bfc096a05bcfc919.jpg: 1024x800 (no detections), 8.8ms\n",
      "Speed: 3.6ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_580_png.rf.7be35c41e93d72df78598df93f0d4ae5.jpg: 928x1024 (no detections), 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 928, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_534_png.rf.dabb95e8446c3dd899ed858797b725fc.jpg: 1024x864 (no detections), 9.8ms\n",
      "Speed: 3.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_22_png.rf.06c62da585c7275aade0d95428e27136.jpg: 1024x896 (no detections), 34.4ms\n",
      "Speed: 4.1ms preprocess, 34.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_80_png.rf.d332cb93ec3ed9e475dd6603e8335b1a.jpg: 1024x416 None7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1706_png.rf.7afc2d834039cee5f5a66f18ba3130a3.jpg: 864x1024 (no detections), 10.1ms\n",
      "Speed: 3.3ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2327_png.rf.767b817c34c6d8d9a23d3f3914f8485e.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.3ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2351_png.rf.aa671e779b5d5e1b02b717307c96b5db.jpg: 1024x864 None9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_298_png.rf.4af54f3971247f6fc07f99eb12f4a098.jpg: 832x1024 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1214_png.rf.bb8204c8269ee3bd35ae3160c52b4c8e.jpg: 864x1024 (no detections), 9.9ms\n",
      "Speed: 3.4ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2648_png.rf.c61d3b5957667c312078bb290f1fcc9e.jpg: 1024x640 (no detections), 8.8ms\n",
      "Speed: 2.2ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_5969_png.rf.92335c3790abb78579bfc9aaa2cbd87c.jpg: 832x1024 None8.0ms\n",
      "Speed: 3.3ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_7058_png.rf.029c63a7047dedf16c6d0ce01533b98b.jpg: 1024x832 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_821_png.rf.d28b7602f6e87bab6da1503d5a0c68b3.jpg: 832x1024 (no detections), 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1129_png.rf.8db430ad388bce8ef6b097eeb1e85515.jpg: 1024x864 None10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_658_png.rf.de1a730e82584f8353c1187bd2da792b.jpg: 1024x928 (no detections), 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1581_png.rf.a4a944611a6bca845d4190be10d96fa1.jpg: 1024x768 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_567_png.rf.1ff9e6e8bb53e2d54f223feea5743936.jpg: 1024x576 (no detections), 9.1ms\n",
      "Speed: 2.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1049_png.rf.f5a123abb07f43506a840667ad755261.jpg: 1024x448 (no detections), 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1144_png.rf.173ad79aad372549ebed7d37647c85a8.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 3.4ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2062_png.rf.96caca3e4789f028ac1329ea33773425.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.7ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_393_png.rf.0b282078360e227eac878ead28fe31a2.jpg: 1024x864 (no detections), 8.9ms\n",
      "Speed: 3.8ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2476_png.rf.8c979b58ab2997484f0de77252f4bae8.jpg: 1024x832 (no detections), 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3502_png.rf.30648c59cd93171dd03dae1612ebc5af.jpg: 1024x832 None7.9ms\n",
      "Speed: 3.7ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2188_png.rf.45749597974be4fac3fb3041c42cac73.jpg: 1024x576 (no detections), 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_471_png.rf.88afffd3f2fe6958bd2c21514800a016.jpg: 1024x864 (no detections), 10.4ms\n",
      "Speed: 3.6ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_136_png.rf.84e1aaf6371bc7c19e7958cb96ae0dca.jpg: 1024x832 (no detections), 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_274_png.rf.51882731bb010b99adf0d39b585fd4b6.jpg: 992x1024 (no detections), 12.1ms\n",
      "Speed: 4.1ms preprocess, 12.1ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_90_png.rf.349e8042b0cd6b53179ba3abb4f3c44c.jpg: 832x1024 (no detections), 9.4ms\n",
      "Speed: 3.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_197_png.rf.44a35017dd213d2d77f0496072cfb41e.jpg: 1024x864 (no detections), 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_802_png.rf.2caa782264ce757cb9b158d442581df6.jpg: 1024x832 (no detections), 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_0_png.rf.d29cab92b154a83ca5bf7e40083673a2.jpg: 1024x480 (no detections), 8.2ms\n",
      "Speed: 1.9ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_56_png.rf.07ffbc9bafd21d80db9c78b4f935ba3a.jpg: 1024x640 None7.7ms\n",
      "Speed: 2.5ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_515_png.rf.3065d50267a627b72fecc33855b2bc00.jpg: 1024x832 (no detections), 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2589_png.rf.797db3537a24d6247c99810896acaa5f.jpg: 1024x544 (no detections), 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_287_png.rf.1963bdf654969c5d608bf0ccff643bdd.jpg: 1024x832 (no detections), 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_488_png.rf.72acecd3750485a10f790fccf953870a.jpg: 1024x608 (no detections), 8.8ms\n",
      "Speed: 2.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_237_png.rf.3c70555567d76e1b792a000d60404ff7.jpg: 832x1024 (no detections), 8.5ms\n",
      "Speed: 3.7ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_690_png.rf.27ef5e8de20af80de9e977fc813e9aa8.jpg: 1024x832 (no detections), 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3358_png.rf.a5c4fda37c0493839f06dbaa096908e9.jpg: 832x1024 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_84_png.rf.f14fe69a9b05f7d5a40b1bffa61b8ead.jpg: 1024x864 (no detections), 9.1ms\n",
      "Speed: 4.0ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_707_png.rf.a68ed3710da7fc1c84ae02bfecc5caa5.jpg: 864x1024 (no detections), 8.8ms\n",
      "Speed: 3.9ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_169_png.rf.48e9271b5fe8dbc321bc7cfd10b1d55f.jpg: 1024x1024 (no detections), 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_796_png.rf.1776a6aa61508cdf674ad9ae5578986e.jpg: 960x1024 (no detections), 34.5ms\n",
      "Speed: 4.4ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 960, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_137_png.rf.328a6c166540a20557e3e9ad6037a1df.jpg: 832x1024 (no detections), 7.5ms\n",
      "Speed: 3.1ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_108_png.rf.7412c1568c7a0071fa200a4e13a550b7.jpg: 1024x448 (no detections), 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1036_png.rf.4743d6d5ca4bcd7df70a2083802b981a.jpg: 1024x768 (no detections), 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2487_png.rf.d44e02e62692a0c9e37bdcfc4ef78003.jpg: 1024x1024 (no detections), 11.4ms\n",
      "Speed: 3.4ms preprocess, 11.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_463_png.rf.05af36580d7b5dcd5927b38341446775.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 4.0ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_173_png.rf.8d122003e666d1b43c9f60e9ef3f0ccf.jpg: 1024x768 (no detections), 8.2ms\n",
      "Speed: 3.0ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4372_png.rf.701d0f949a89d7d1fba3825b7008e787.jpg: 1024x928 (no detections), 10.5ms\n",
      "Speed: 3.9ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_477_png.rf.734af8f7cc7e630ac0df48d90b76de7e.jpg: 1024x704 (no detections), 8.6ms\n",
      "Speed: 2.5ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1514_png.rf.8aa5c1d4670140b9b9b8b84d6ad70fbc.jpg: 992x1024 (no detections), 9.7ms\n",
      "Speed: 4.0ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_252_png.rf.65bf1d39beb17acc6be39ee33ef00908.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_947_png.rf.c09499f3067dd00d1e9fe5c6ea497ff2.jpg: 448x1024 (no detections), 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_71_png.rf.43f9fc97520abda66fbab2a45f328d26.jpg: 832x1024 None8.1ms\n",
      "Speed: 3.1ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_365_png.rf.f5615050309ece820912d0d09859a5f0.jpg: 1024x448 None7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_140_png.rf.b63ac9f299096c7ef259e393038b4be1.jpg: 832x1024 (no detections), 8.4ms\n",
      "Speed: 3.2ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_876_png.rf.7fc4b4b05beb4f0ff9fefbb9d4fa1ab3.jpg: 1024x800 (no detections), 8.1ms\n",
      "Speed: 3.0ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_345_png.rf.06185501b45cfee439ac1cfc71031455.jpg: 1024x352 (no detections), 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_5_png.rf.49ecdad27d07b6b8901d9931c2067bec.jpg: 320x1024 (no detections), 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_235_png.rf.b1941b81c75ae13ea1add97bf50e69aa.jpg: 1024x512 (no detections), 7.8ms\n",
      "Speed: 1.9ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_179_png.rf.2dac77668440f0f798140d3233888a64.jpg: 416x1024 (no detections), 7.7ms\n",
      "Speed: 1.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_388_png.rf.62b2788f9c10885a6075e38b46653acc.jpg: 896x1024 (no detections), 7.4ms\n",
      "Speed: 4.5ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 896, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1776_png.rf.a86ba5c63c5c70eb7718401a9e15e50e.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 3.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_907_png.rf.44416cf779b4ea8d8fa95afee51f5e3f.jpg: 1024x448 (no detections), 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1186_png.rf.3cfc6477bbc733ebdf562bb8d455e907.jpg: 1024x960 None11.2ms\n",
      "Speed: 4.0ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_110_png.rf.7fc86b639738b0a2cd6e55e66cd73b99.jpg: 1024x352 (no detections), 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_380_png.rf.a3edc138e5863941008841820260e1db.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1673_png.rf.682b1cc99342f353d0d34689f8bbaf59.jpg: 1024x480 (no detections), 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4373_png.rf.cbac67cb2e9e3495ee9e136ec1f2ec9a.jpg: 1024x960 (no detections), 9.4ms\n",
      "Speed: 4.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_516_png.rf.91d7d5784d59db1c419b9be508e4a37e.jpg: 544x1024 None7.4ms\n",
      "Speed: 2.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_142_png.rf.d563056b013def35087f83ce9f0119be.jpg: 1024x864 None10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_111_png.rf.3893d8f7588cea4d796d26119e52637f.jpg: 1024x576 (no detections), 7.6ms\n",
      "Speed: 2.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_316_png.rf.22de12a5772f6b00cfdef17d8f66a7ba.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.7ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_263_png.rf.eab7542bedd4be63c435b906ce9d4651.jpg: 1024x1024 None10.3ms\n",
      "Speed: 5.5ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_110_png.rf.b0aff58a40e98042e37cb897e756b08e.jpg: 1024x864 (no detections), 8.7ms\n",
      "Speed: 3.5ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1802_png.rf.ada9b0ad89e89af07a36ed5590773b7e.jpg: 1024x832 None8.3ms\n",
      "Speed: 3.4ms preprocess, 8.3ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1560_png.rf.22e6f99275f437d9906a7f4a608a3985.jpg: 1024x672 None8.9ms\n",
      "Speed: 2.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_3994_png.rf.5f4d9a9a84fa26b7ba96ae6e2e40a259.jpg: 1024x416 (no detections), 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1680_png.rf.cddfca6e707beecf1ca52e4946adeeee.jpg: 640x1024 (no detections), 33.5ms\n",
      "Speed: 3.1ms preprocess, 33.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_392_png.rf.666304237d915a705d6830016a7c22c1.jpg: 1024x864 (no detections), 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_504_png.rf.a70dbb22c8ed59e8fa9535a59973eac5.jpg: 1024x896 (no detections), 10.7ms\n",
      "Speed: 3.5ms preprocess, 10.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_436_png.rf.163f5793186cc5a322fad8a193d892e1.jpg: 1024x704 (no detections), 9.1ms\n",
      "Speed: 2.4ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_316_png.rf.61dbf14487cee0fdf8a82602742726a0.jpg: 1024x832 (no detections), 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2929_png.rf.5281aae6cdac82080777a2ba5270e050.jpg: 1024x672 None9.2ms\n",
      "Speed: 2.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1806_png.rf.8a13aca157648bc2ca883135c439304a.jpg: 864x1024 (no detections), 9.0ms\n",
      "Speed: 3.8ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1031_png.rf.0f84f2c23a4cd720a80e74e445be6466.jpg: 1024x448 (no detections), 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_787_png.rf.bf6694681dafe401cf0123e5b2733ae0.jpg: 1024x704 (no detections), 9.2ms\n",
      "Speed: 2.7ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1107_png.rf.f261d35066d972aeae64edc4b34a5d7e.jpg: 544x1024 (no detections), 8.5ms\n",
      "Speed: 1.9ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 544, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_548_png.rf.042f9ef1d41fe9e8cfc84c43a6d33bed.jpg: 1024x832 (no detections), 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1098_png.rf.89eea31a3d88c2de0f0e605a12968a91.jpg: 992x1024 (no detections), 10.7ms\n",
      "Speed: 4.2ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_98_png.rf.760919589e2de7e93ced78b7dfa3c62b.jpg: 1024x864 None9.3ms\n",
      "Speed: 3.5ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_304_png.rf.02b33477f70bcaae759cf80b1c7d3730.jpg: 1024x576 (no detections), 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_472_png.rf.75e038dd70d155dd6355dc7906aeec02.jpg: 1024x832 (no detections), 9.1ms\n",
      "Speed: 3.0ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_142_png.rf.05bdcca221eee8efc0651e3fb54f932f.jpg: 832x1024 (no detections), 8.9ms\n",
      "Speed: 2.9ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_615_png.rf.cef477ebb9daca0f6f69f1eb39a7b53d.jpg: 1024x640 (no detections), 8.7ms\n",
      "Speed: 2.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 640)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_155_png.rf.80393d981ea40b6c1b8b9dc753eb308c.jpg: 1024x704 None7.8ms\n",
      "Speed: 2.6ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1149_png.rf.235191fb233abff0b4926a7e39a9eea4.jpg: 864x1024 None9.3ms\n",
      "Speed: 3.7ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_290_png.rf.9635aba99a64bd1ea314ae43241ac044.jpg: 1024x576 (no detections), 8.4ms\n",
      "Speed: 2.1ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_306_png.rf.61caa0eea2f392fcfed6a6808aa4174d.jpg: 832x1024 (no detections), 8.5ms\n",
      "Speed: 3.2ms preprocess, 8.5ms inference, 0.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_864_png.rf.a5f519ce8af0f1f08b0439f97599d471.jpg: 1024x800 None7.6ms\n",
      "Speed: 3.0ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2152_png.rf.5c2e8ea5ec087257e61a7026e9994011.jpg: 1024x544 None7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1353_png.rf.b843ae50b5e163e10c908171716e5a39.jpg: 1024x1024 (no detections), 8.2ms\n",
      "Speed: 4.2ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_630_png.rf.cdb97ca5544b97e536d241a63bdbd547.jpg: 1024x384 (no detections), 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_21_png.rf.abe115abaadda1c0fdd552fcb1c32032.jpg: 608x1024 (no detections), 34.3ms\n",
      "Speed: 2.1ms preprocess, 34.3ms inference, 0.9ms postprocess per image at shape (1, 3, 608, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_225_png.rf.2bfd04df55787346cd770f059fc1e7ad.jpg: 1024x1024 None8.2ms\n",
      "Speed: 3.9ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_331_png.rf.a0851e40fddcf6211958fca348bfeb78.jpg: 1024x832 (no detections), 8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_356_png.rf.325517fed11d2b059bbae6715a7cb21c.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 3.1ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_68_png.rf.e9c730368efcd367b5e1430616ef2ed6.jpg: 1024x384 (no detections), 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1310_png.rf.daf759fe071a5733142e9847fb388e75.jpg: 1024x608 (no detections), 7.7ms\n",
      "Speed: 2.3ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_2337_png.rf.4f2fc3029cc730ee37e46652fea46036.jpg: 832x1024 None7.8ms\n",
      "Speed: 3.6ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_438_png.rf.dbe2dfbad9f739757ead72d520d2e633.jpg: 768x1024 (no detections), 7.7ms\n",
      "Speed: 2.8ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_206_png.rf.9af7b509cfc87217908dfda627136bf8.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 3.8ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_200_png.rf.5c5667178404f14d0124544574c16083.jpg: 1024x352 (no detections), 7.9ms\n",
      "Speed: 1.2ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_571_png.rf.60239651dc5d9031c3e902d0a16b200d.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 2.9ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2149_png.rf.2d391a8be0d79857aeb9992f52779eca.jpg: 1024x800 None9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_1259_png.rf.ebfab9ae92058e7cca0b9e0fbb64c948.jpg: 1024x864 None8.6ms\n",
      "Speed: 3.6ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_697_png.rf.4655bfbfaecb4bb4ecf7fa9478b76ad8.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 3.0ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_610_png.rf.c0995510828ea9894c4ffdea39630aca.jpg: 1024x864 None8.2ms\n",
      "Speed: 3.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_75_png.rf.9fdc9f8a903295c283ebab365a1888e0.jpg: 1024x672 None8.3ms\n",
      "Speed: 2.6ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_278_png.rf.aed420df47119889bd8af834c3e1c7b8.jpg: 1024x768 (no detections), 8.1ms\n",
      "Speed: 3.2ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_513_png.rf.9c41966c467d0bbd6cfa7cd9a8a2953e.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_537_png.rf.0af2211302c463dd9e59caf6ed321ecf.jpg: 1024x832 (no detections), 9.0ms\n",
      "Speed: 2.9ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_78_png.rf.d27b079cf4d9404f9590dc2641f37dc9.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1029_png.rf.8f1dfb1982511a9b38867fa9444965f0.jpg: 832x1024 (no detections), 7.9ms\n",
      "Speed: 3.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_256_png.rf.4706c2f841f94188ed9f48b4ad4dba26.jpg: 1024x384 (no detections), 7.8ms\n",
      "Speed: 2.0ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_340_png.rf.38e0fc7764336e7a7e3c440aea0e2daa.jpg: 1024x864 (no detections), 8.3ms\n",
      "Speed: 3.9ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1669_png.rf.66de9f8a4d5a71ec06d4c5c4c475ff6c.jpg: 1024x768 (no detections), 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1244_png.rf.10768651f2631bbbf28837704e2c9916.jpg: 768x1024 (no detections), 8.2ms\n",
      "Speed: 2.9ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1264_png.rf.3d9e9ec178bffa0af8674e9f9e69730f.jpg: 1024x864 (no detections), 9.0ms\n",
      "Speed: 3.7ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_120_png.rf.a013ab648c9c688362f65937d25c190b.jpg: 832x1024 (no detections), 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_894_png.rf.d87567f8b64137ef40bc1cf5852d4d03.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 3.3ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2145_png.rf.a47b00248c5acbae164fa4f06f39861b.jpg: 1024x576 None8.0ms\n",
      "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_158_png.rf.50714cb0fd36bf8ad441d03d4e5c58d3.jpg: 768x1024 (no detections), 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_764_png.rf.ab8fbe451b41e67b0fac185b0f9a4f86.jpg: 768x1024 (no detections), 7.5ms\n",
      "Speed: 3.3ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_60_png.rf.8d4f7dce9cd64f581cab952df132669a.jpg: 1024x864 (no detections), 8.3ms\n",
      "Speed: 3.7ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_6_png.rf.c1d09879417997e2d668378db7be1a55.jpg: 1024x832 (no detections), 7.9ms\n",
      "Speed: 3.3ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_499_png.rf.588eaa8ccf68add93a6a4280de716db4.jpg: 832x1024 (no detections), 7.9ms\n",
      "Speed: 3.4ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/coronoid-process-fracture_jpg.rf.71650459c69a9734ecd545067cf18bf4.jpg: 992x1024 (no detections), 8.1ms\n",
      "Speed: 5.5ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 992, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_891_png.rf.14e1ce98932091652500c98541ec8455.jpg: 1024x512 None8.2ms\n",
      "Speed: 2.2ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_162_png.rf.0132591669e00deaf033b6d409e4d24f.jpg: 1024x864 (no detections), 8.2ms\n",
      "Speed: 3.3ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_481_png.rf.d04c20719ce7d46794b21c816dcee200.jpg: 1024x864 (no detections), 7.4ms\n",
      "Speed: 3.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_642_png.rf.da3a47f0d75768392b53c76d73227bbc.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 3.7ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_4311_png.rf.94bdbf6b601e08d736b5fca3590c95c1.jpg: 1024x768 None8.1ms\n",
      "Speed: 2.8ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_2552_png.rf.7a87da3fa8c3d03f97c51bcec0ead7e7.jpg: 1024x864 (no detections), 8.1ms\n",
      "Speed: 4.3ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_342_png.rf.c1998dcfe68bc1bab84ea57af9694c51.jpg: 1024x832 None7.9ms\n",
      "Speed: 3.0ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_786_png.rf.8799fbcb9ae8f82f1f9eadcf993428bf.jpg: 1024x704 (no detections), 8.4ms\n",
      "Speed: 2.9ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_234_png.rf.8ff82c844e5a90593e9009ee2546dfb0.jpg: 1024x608 (no detections), 8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_644_png.rf.5e61f3b5f36f82ab41f333281faf6eca.jpg: 1024x1024 (no detections), 10.0ms\n",
      "Speed: 4.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_602_png.rf.19b335a39a1557f6b0cdf8f617e3537d.jpg: 1024x864 (no detections), 8.4ms\n",
      "Speed: 3.3ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_581_png.rf.20026bf05c575326d79e00f6772a094a.jpg: 1024x544 None8.3ms\n",
      "Speed: 2.4ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_598_png.rf.d5cdf9fdd24ff6626fd9fe2cbc02ea34.jpg: 1024x672 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_632_png.rf.65725898246d01bd76a6610f79591127.jpg: 1024x1024 None9.3ms\n",
      "Speed: 3.6ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_536_png.rf.d14e240fc070711be3f1b81d89416b17.jpg: 1024x1024 (no detections), 9.2ms\n",
      "Speed: 4.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image2_60_png.rf.d9da166ee463c69580031e0462b5c001.jpg: 1024x1024 (no detections), 9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1175_png.rf.32cf171a1800acd13701cee027eb0940.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.1ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_1577_png.rf.50a94b433475441003b8b6716e35ee7c.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 3.2ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/valid/images/image1_119_png.rf.77de12cb566fc295603927e2a5b2748a.jpg: 1024x512 (no detections), 7.7ms\n",
      "Speed: 1.9ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../project_name/data/valid/'\n",
    "images_dir = data_dir + 'images/'\n",
    "labels_dir = data_dir + 'labels/'\n",
    "\n",
    "image_paths = os.listdir(images_dir)\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image in image_paths:\n",
    "    label_filename = os.path.splitext(image)[0] + '.txt'\n",
    "    label_path = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "    results = model.predict(source= images_dir + image, save=False)\n",
    "\n",
    "    label = ''\n",
    "\n",
    "    # check and print corresponding label if it exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = f.read()\n",
    "    else:\n",
    "        print(f\"No label file found for {image}\")\n",
    "\n",
    "    predictions.append((image, results, label))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46cd41",
   "metadata": {},
   "source": [
    "First we check if it labels an image if it has a fracture and if it labels when it does not have a fracture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1117a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "correct = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "\n",
    "    true_label = 0 if label_is_empty else 1\n",
    "    predicted_label = 1 if has_prediction else 0\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084cb81",
   "metadata": {},
   "source": [
    "Let us now create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d1f793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Fracture', 'Fracture'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680057fd",
   "metadata": {},
   "source": [
    "### Testing bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c0c7e",
   "metadata": {},
   "source": [
    "Now we will see if the bounding boxes are better than if one would select the entire screen. We use shapify to find the IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff165754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def compute_iou(pred_poly, label_poly):\n",
    "\n",
    "    # convert to Polygon class\n",
    "    pred_polygon = Polygon(pred_poly)\n",
    "    label_polygon = Polygon(label_poly)\n",
    "\n",
    "    if not pred_polygon.is_valid or not label_polygon.is_valid:\n",
    "        # print(\"Polygon is not valid\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Get intersection and union\n",
    "    intersection_area = pred_polygon.intersection(label_polygon).area\n",
    "    union_area = pred_polygon.union(label_polygon).area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection_area / union_area, label_polygon.area\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4cbc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random guess: 20, model: 67, total: 87\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_better = 0\n",
    "random_guess_better = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    # if no label is there or the model did not predict, we are unable to calculate IoU\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "    if label_is_empty or not has_prediction:\n",
    "        continue\n",
    "\n",
    "    # split lines of label\n",
    "    label_lines = label.splitlines()\n",
    "    \n",
    "    iou = 0.0\n",
    "    for line in label_lines:\n",
    "        if not line.strip():\n",
    "            continue  # skip empty labels, sanity check\n",
    "\n",
    "        label_parts = line.strip().split()\n",
    "        label_coords = list(map(float, label_parts[1:]))  # skip class label and make it float array\n",
    "        # print(label_coords)\n",
    "\n",
    "        # Go from a line to x y tuples\n",
    "        label_polygon = [(label_coords[i], label_coords[i + 1]) for i in range(0, len(label_coords), 2)]\n",
    " \n",
    "        label_area = 0.0\n",
    "        for r in result:\n",
    "            # print(r.obb.xyxyxyxyn)\n",
    "            pred_coords = r.obb.xyxyxyxyn.cpu().numpy().reshape(-1, 2)\n",
    "            # print(pred_coords)\n",
    "            pred_polygon = [tuple(point) for point in pred_coords]\n",
    "\n",
    "            iou_temp, label_area = compute_iou(pred_polygon, label_polygon)\n",
    "            iou = iou + iou_temp\n",
    "\n",
    "            #print(f\"IoU: {iou:.4f}\")\n",
    "            # print(f\"Label Area: {label_area:.4f}\")\n",
    "    \n",
    "    # Since coordinates of polygon are in normal coordinates, we only have t o check wether IoU is larger than label area. \n",
    "    # Since IoU of a an entire picture with another area has an union area of 1, and a intersection area of the label area.   \n",
    "    if iou > label_area:\n",
    "        model_better = model_better + 1\n",
    "    else:\n",
    "        random_guess_better = random_guess_better + 1\n",
    "\n",
    "print(f\"Random guess: {random_guess_better}, model: {model_better}, total: {random_guess_better + model_better}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
