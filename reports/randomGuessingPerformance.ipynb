{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057aba3f",
   "metadata": {},
   "source": [
    "### How to prove we are better than random guessing\n",
    "\n",
    "We have an interesting situation where we work with bounding boxes, resulting in a more difficult way to prove that we are better than random guessing. We will show multiple ways to prove that we are better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af98239",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c11277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from project_name.models.yoloModel import YOLOModel\n",
    "model = YOLOModel()\n",
    "model.load_model(\"../runs/obb/train6/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34474148",
   "metadata": {},
   "source": [
    "Let us now predict for every model and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766831e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_637_png.rf.750d1e44edbbb461c9505f1d9c0e4a02.jpg: 1024x992 (no detections), 37.4ms\n",
      "Speed: 4.2ms preprocess, 37.4ms inference, 97.4ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_300_png.rf.68c69212cc50665b9c1ffa7dd4eb25a4.jpg: 1024x992 (no detections), 10.8ms\n",
      "Speed: 6.2ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_6973_png.rf.6a71f376e7ce54b8e8d484d17e699596.jpg: 1024x800 (no detections), 34.6ms\n",
      "Speed: 3.6ms preprocess, 34.6ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_125_png.rf.0025d3a37097e5e1e913d6b36f38df9a.jpg: 1024x1024 (no detections), 13.6ms\n",
      "Speed: 3.8ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1101_png.rf.76b621303ad7da308e79a2e39d860675.jpg: 1024x768 None37.4ms\n",
      "Speed: 2.8ms preprocess, 37.4ms inference, 87.6ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1233_png.rf.4e2b7dc04a17f7f3a33a343e8f7ee67e.jpg: 832x1024 (no detections), 34.0ms\n",
      "Speed: 3.1ms preprocess, 34.0ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1284_png.rf.45c8239cf68c001ba91d7d002729eec7.jpg: 1024x832 (no detections), 33.4ms\n",
      "Speed: 3.2ms preprocess, 33.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3054_png.rf.4be16ac99458914b4a34d0892e5f7ff0.jpg: 1024x832 None9.0ms\n",
      "Speed: 3.4ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_40_png.rf.3404b7671f39e7295097dd6dabb28a97.jpg: 1024x992 (no detections), 13.1ms\n",
      "Speed: 4.7ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_1540_png.rf.46ec2cd9f9775a6e815e5062658d9fb0.jpg: 1024x864 None34.9ms\n",
      "Speed: 3.0ms preprocess, 34.9ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_448_png.rf.70f487675effb06da9c6c334b5fe29cc.jpg: 1024x768 (no detections), 8.0ms\n",
      "Speed: 3.6ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_663_png.rf.460908c550b08162d5553b1073c8495c.jpg: 1024x864 (no detections), 9.2ms\n",
      "Speed: 3.9ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1392_png.rf.692d8594c2ce39483af8c3c4fee91646.jpg: 1024x352 (no detections), 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 352)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1000_png.rf.a53c5e186c03961bf88075c6e3e94cf6.jpg: 864x1024 None39.1ms\n",
      "Speed: 4.9ms preprocess, 39.1ms inference, 2.6ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4097_png.rf.5579812fd38a497fbfeabe584564ffaf.jpg: 1024x832 None9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1084_png.rf.d9da08b77872f6b4282f2700d216b9b3.jpg: 1024x1024 None11.9ms\n",
      "Speed: 4.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2600_png.rf.01b17c4166e1ea6a863191eebfff35ae.jpg: 1024x832 (no detections), 8.9ms\n",
      "Speed: 3.4ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/distal-humerus-fracture-1_jpg.rf.831cb137cfcbde1079f86abd5f5f2867.jpg: 1024x416 (no detections), 34.0ms\n",
      "Speed: 2.7ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1175_png.rf.aad108f3739e48313c773ad1392a8966.jpg: 1024x896 None35.4ms\n",
      "Speed: 3.8ms preprocess, 35.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 896)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_145_png.rf.a69d928d011a93d25a95b7b8380ea25d.jpg: 1024x544 None34.9ms\n",
      "Speed: 3.3ms preprocess, 34.9ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_344_png.rf.d52b5bab514fb7cfb568da05594a6404.jpg: 1024x416 (no detections), 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_252_png.rf.81a8e63687d8630d28257570bd5fcd80.jpg: 1024x832 None9.5ms\n",
      "Speed: 4.5ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_674_png.rf.9c85436fb6b27fc193107ee487555959.jpg: 1024x832 (no detections), 8.0ms\n",
      "Speed: 3.5ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1044_png.rf.1e17d3a8637036ef4b3e1c5d0b88011f.jpg: 1024x672 None35.4ms\n",
      "Speed: 2.6ms preprocess, 35.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_726_png.rf.d196dd48429681a19051d39b968f3fb0.jpg: 1024x1024 (no detections), 10.3ms\n",
      "Speed: 5.2ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_670_png.rf.da8ddaaa5ef3e99f8da51b6664740aa4.jpg: 1024x832 None8.7ms\n",
      "Speed: 3.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_849_png.rf.761ec251e358a15e08cdad95fd41492a.jpg: 320x1024 None34.5ms\n",
      "Speed: 1.6ms preprocess, 34.5ms inference, 2.5ms postprocess per image at shape (1, 3, 320, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_176_png.rf.87231f93e98596a5a1b52ef2fd5a7871.jpg: 1024x864 (no detections), 9.0ms\n",
      "Speed: 3.7ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4966_png.rf.27ae131adff1063f606ceecb0fddc7c2.jpg: 1024x832 None7.7ms\n",
      "Speed: 3.4ms preprocess, 7.7ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_1718_png.rf.3320525501293fd17921dbca2ec70ebf.jpg: 864x1024 (no detections), 7.7ms\n",
      "Speed: 3.8ms preprocess, 7.7ms inference, 0.9ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_268_png.rf.00406f976b1bd6c978e828d2c5085683.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 3.6ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_860_png.rf.37fd7f57d0b9ec38eafafceacdbd4f4c.jpg: 1024x576 (no detections), 35.3ms\n",
      "Speed: 2.4ms preprocess, 35.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_258_png.rf.7d64b6239897f6838c97b4d18d6ed0c9.jpg: 1024x544 (no detections), 8.3ms\n",
      "Speed: 2.3ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_641_png.rf.ca0bfddb8b5ac5e97fa841e32c94ad9a.jpg: 704x1024 (no detections), 35.3ms\n",
      "Speed: 3.2ms preprocess, 35.3ms inference, 0.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_350_png.rf.32b20b275bdbf30afb13d8d585da2743.jpg: 1024x864 (no detections), 9.6ms\n",
      "Speed: 4.1ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_375_png.rf.309ea11b65edee9329ae91a338bcefe9.jpg: 1024x416 (no detections), 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_68_png.rf.9e3dfa26e497af0a8f676a9686fd0e20.jpg: 1024x832 (no detections), 8.9ms\n",
      "Speed: 3.4ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_137_png.rf.996f3c880689913494b8c7baae7a6f0d.jpg: 960x1024 (no detections), 34.5ms\n",
      "Speed: 3.6ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 960, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_152_png.rf.f6e7109e7499a7a20e4fc8c0940603d3.jpg: 1024x736 (no detections), 36.4ms\n",
      "Speed: 3.2ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_0_png.rf.99862308d714bff3f9c410adf5ca93ac.jpg: 768x1024 (no detections), 34.0ms\n",
      "Speed: 3.6ms preprocess, 34.0ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_279_png.rf.b40ab0fc72a8fff98daa57979d24b206.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 4.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_182_png.rf.c9539857a1608ea4850d37195ff767ce.jpg: 1024x1024 (no detections), 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1563_png.rf.4d5bc124b48e7d4d2636d2d6691e36f2.jpg: 768x1024 (no detections), 8.4ms\n",
      "Speed: 3.0ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_241_png.rf.9429a19b000ff9abd6339900245fb1ba.jpg: 1024x288 (no detections), 34.5ms\n",
      "Speed: 1.2ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3726_png.rf.2876d2f0108b5a9fb5c23e8fb95f4625.jpg: 1024x416 (no detections), 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 416)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_537_png.rf.06ee5106226a244e50fa61450224633b.jpg: 1024x864 (no detections), 8.8ms\n",
      "Speed: 3.9ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4499_png.rf.8ed6bcadb4b1266886b392db6f1f1da2.jpg: 1024x320 None34.2ms\n",
      "Speed: 1.4ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 320)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1682_png.rf.8c3d0845adaa6d884f90b3a020573069.jpg: 1024x992 (no detections), 9.7ms\n",
      "Speed: 4.7ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_23_png.rf.da8bbef32848f32a8d5434e328b10428.jpg: 832x1024 (no detections), 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_639_png.rf.915590376683dad767046b536acd3b19.jpg: 1024x384 None34.7ms\n",
      "Speed: 1.6ms preprocess, 34.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1359_png.rf.7475a35f950cea14d8dcd975042229b2.jpg: 832x1024 (no detections), 7.8ms\n",
      "Speed: 3.9ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2336_png.rf.76087ca1e6263ce05700b7e1f92b9f02.jpg: 832x1024 None7.4ms\n",
      "Speed: 3.7ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4498_png.rf.36adec7c0d9bacf95faf5c87d28dfbe7.jpg: 1024x960 (no detections), 34.9ms\n",
      "Speed: 4.8ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_437_png.rf.fc6edfb87d799f751a64d540952739cc.jpg: 1024x480 (no detections), 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_416_png.rf.4aaadbb2bfef18ef419564a862caa457.jpg: 864x1024 (no detections), 8.4ms\n",
      "Speed: 3.9ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_327_png.rf.f8494f574a1ebe492bf514a9504da0a1.jpg: 1024x864 (no detections), 9.4ms\n",
      "Speed: 3.1ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_184_png.rf.e493197224b25d2fe8234345382fb4b9.jpg: 1024x928 (no detections), 36.1ms\n",
      "Speed: 3.9ms preprocess, 36.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3368_png.rf.074f5f9364ab5534a1e1285ad13e5e0b.jpg: 1024x832 None7.7ms\n",
      "Speed: 3.4ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_338_png.rf.617385aa69fa890a370a37684bae944f.jpg: 1024x768 None7.8ms\n",
      "Speed: 3.6ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3167_png.rf.e97086c7a649e081f8b3ebdd6b27fd2f.jpg: 1024x832 (no detections), 7.8ms\n",
      "Speed: 4.0ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_37_png.rf.bda84ad18e135a15c25ffd40bd55567f.jpg: 1024x1024 (no detections), 9.4ms\n",
      "Speed: 5.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_12_png.rf.5f6971023573ad4a240a4e4c4dae0e5f.jpg: 1024x1024 (no detections), 9.1ms\n",
      "Speed: 3.9ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3221_png.rf.5fb071486cc85c923cd8350b22ad6ee7.jpg: 1024x544 None8.4ms\n",
      "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_154_png.rf.bf5cc83ea60cb0fd21d1f21ab7055f9d.jpg: 1024x864 (no detections), 8.9ms\n",
      "Speed: 3.3ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_698_png.rf.66b6d614653eed2ef4e81695aca5c5a6.jpg: 832x1024 (no detections), 8.0ms\n",
      "Speed: 2.9ms preprocess, 8.0ms inference, 0.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1365_png.rf.588432cc594787268e4d4e7bdf4bb240.jpg: 1024x832 (no detections), 10.9ms\n",
      "Speed: 5.5ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_848_png.rf.029e1130bf23b22edbf687ed6b1902ed.jpg: 1024x320 None11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 320)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1070_png.rf.d01735eab2c774146e40eef6c8e7b661.jpg: 1024x768 (no detections), 11.3ms\n",
      "Speed: 5.3ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_852_png.rf.b721589a516459f110ab073a190f3f0f.jpg: 608x1024 (no detections), 42.3ms\n",
      "Speed: 5.0ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 608, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3565_png.rf.52153ba946f07810b3c16f62d202db16.jpg: 704x1024 (no detections), 8.4ms\n",
      "Speed: 2.9ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 704, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1796_png.rf.42413ce321f53b714fc52ffa1d1a2021.jpg: 1024x1024 None9.1ms\n",
      "Speed: 5.0ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_623_png.rf.056fad4c4c1c2381cdabf35f947ab1bb.jpg: 1024x864 (no detections), 8.3ms\n",
      "Speed: 3.6ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_594_png.rf.08dd02caad7756ae235e1ff58a0205b6.jpg: 1024x672 None7.4ms\n",
      "Speed: 2.6ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_508_png.rf.63f80ba9eca75737d7435b9122d70288.jpg: 1024x864 None7.5ms\n",
      "Speed: 4.1ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_230_png.rf.f2a3605e418617cb313976daaec78e18.jpg: 1024x864 (no detections), 7.5ms\n",
      "Speed: 4.1ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_450_png.rf.c1640af9f113b3690185c7b22e1d76ec.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.3ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2157_png.rf.37cf76e910103b2aa83a2c925849f300.jpg: 1024x832 None7.6ms\n",
      "Speed: 3.1ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_645_png.rf.402f6afd337e508ac75cc56d0ecf912c.jpg: 1024x864 (no detections), 8.6ms\n",
      "Speed: 3.4ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_199_png.rf.111ecddb2bdc3542d7f953385d1bb03b.jpg: 1024x768 (no detections), 8.1ms\n",
      "Speed: 2.7ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_291_png.rf.c5a2f62a6316d1ebd9f91cb85ed65891.jpg: 864x1024 (no detections), 8.1ms\n",
      "Speed: 3.7ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_454_png.rf.3dd6c4b175031818178433bd945d2af9.jpg: 1024x864 (no detections), 7.6ms\n",
      "Speed: 3.3ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_511_png.rf.9e17ffe27582ff4724db0edbc22118ba.jpg: 832x1024 (no detections), 7.6ms\n",
      "Speed: 3.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_635_png.rf.87aa3f97aeaffa79004761ae1f895cac.jpg: 1024x800 (no detections), 7.8ms\n",
      "Speed: 4.0ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 800)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_148_png.rf.b9799a5fddd2b4b2b747dc5c49f1643f.jpg: 1024x768 (no detections), 7.9ms\n",
      "Speed: 3.0ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_22_png.rf.bb53a5b5275a858894f501512908f07a.jpg: 1024x544 (no detections), 9.1ms\n",
      "Speed: 2.0ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_1758_png.rf.be01737bb3e65525d2fcac4a9814624f.jpg: 864x1024 (no detections), 8.1ms\n",
      "Speed: 3.8ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_62_png.rf.49b4ef3c363843b800174d2fdfc56ee8.jpg: 1024x832 (no detections), 8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_211_png.rf.e1fd0ca40a197d13f9ecae59c4074d43.jpg: 1024x832 (no detections), 8.1ms\n",
      "Speed: 3.5ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1015_png.rf.9181f8eb07451331e22381bacb3a5bd2.jpg: 1024x1024 (no detections), 9.7ms\n",
      "Speed: 5.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1545_png.rf.cd2ce2cc69004944f0d920c4bda34592.jpg: 1024x704 (no detections), 37.4ms\n",
      "Speed: 2.9ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_314_png.rf.870abcb0b0922e63bd5ba9389a1efd74.jpg: 1024x832 (no detections), 8.2ms\n",
      "Speed: 3.8ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_953_png.rf.97a41890b4badde45bfc390f9f5c9d12.jpg: 1024x864 None8.8ms\n",
      "Speed: 3.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1741_png.rf.abfab4411413ca60310f9787db4d8d83.jpg: 832x1024 None8.8ms\n",
      "Speed: 3.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_6478_png.rf.eee144dfa7e8712592f7d8b10523e2fa.jpg: 1024x832 (no detections), 9.2ms\n",
      "Speed: 3.8ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1033_png.rf.4bbf6560a26646b1d3a1ab600aa19251.jpg: 832x1024 None8.6ms\n",
      "Speed: 3.9ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_51_png.rf.56172f90bd654dcc6cc4ac47f79988a2.jpg: 832x1024 (no detections), 8.3ms\n",
      "Speed: 3.3ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3073_png.rf.241285b7d595353800440e6d2b9b91f0.jpg: 1024x672 (no detections), 8.8ms\n",
      "Speed: 2.4ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_336_png.rf.f758673053df7ac6e05b8671c2563062.jpg: 832x1024 (no detections), 8.3ms\n",
      "Speed: 3.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_432_png.rf.f040d366cb944d4ab64b58825db1fedc.jpg: 960x1024 (no detections), 11.0ms\n",
      "Speed: 5.0ms preprocess, 11.0ms inference, 0.4ms postprocess per image at shape (1, 3, 960, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3413_png.rf.d18ceb5ede7d864fef838167eae65120.jpg: 832x1024 None8.3ms\n",
      "Speed: 3.3ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_633_png.rf.9bd74183541bd851e79f94d3f07c50d6.jpg: 832x1024 (no detections), 7.5ms\n",
      "Speed: 3.2ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_1421_png.rf.b623cea6c9617fcf2f09843434e25218.jpg: 640x1024 None35.3ms\n",
      "Speed: 2.4ms preprocess, 35.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_358_png.rf.ae461871b8aa93ee2b62c42d61ada754.jpg: 1024x736 (no detections), 8.7ms\n",
      "Speed: 3.0ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3739_png.rf.378cc67dc76f5d423a65e397d699fa37.jpg: 1024x288 (no detections), 8.0ms\n",
      "Speed: 1.1ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 288)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_164_png.rf.ed315410a29883c298454af69f3ae895.jpg: 832x1024 None8.0ms\n",
      "Speed: 3.6ms preprocess, 8.0ms inference, 2.8ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1311_png.rf.27646e931562cc3823c79f79472b8749.jpg: 832x1024 (no detections), 7.5ms\n",
      "Speed: 3.4ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_5740_png.rf.9e24e104e841b740e0389637d5e6d2d7.jpg: 864x1024 None8.4ms\n",
      "Speed: 3.8ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1553_png.rf.ec209f9a8e0e7a41b30a1683a4574f00.jpg: 1024x832 (no detections), 8.9ms\n",
      "Speed: 3.2ms preprocess, 8.9ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_636_png.rf.3a27fb8f5d5892ce33733630521b1e3d.jpg: 864x1024 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_509_png.rf.4b918f154cece667f6fe4ec2e676eaf1.jpg: 832x1024 (no detections), 7.7ms\n",
      "Speed: 3.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1588_png.rf.aba29f401dee4db13fc5434f3c0186b4.jpg: 1024x832 None7.7ms\n",
      "Speed: 4.2ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1813_png.rf.36e36804ccd3bc72b0fc02d36029d08f.jpg: 1024x704 (no detections), 8.0ms\n",
      "Speed: 3.5ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 704)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_8002_png.rf.3b1d55e198fdcd09f808da01429ee7c7.jpg: 1024x832 None8.5ms\n",
      "Speed: 3.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1134_png.rf.642f46a1f0f794f24f5aa3edcf58bdcf.jpg: 1024x480 (no detections), 8.9ms\n",
      "Speed: 2.0ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 480)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_340_png.rf.82476241970da952e6e27b1a9c43bef8.jpg: 1024x768 (no detections), 8.8ms\n",
      "Speed: 2.7ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1057_png.rf.dbd0e857728d8b149e5732cb2824d819.jpg: 1024x864 None8.9ms\n",
      "Speed: 3.7ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_745_png.rf.4e5bc3fc5e483e6cc01963dd3d591550.jpg: 1024x736 (no detections), 9.0ms\n",
      "Speed: 2.7ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 736)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_536_png.rf.20bf7f571e4badd6d76c3a8894575eb7.jpg: 1024x864 None8.3ms\n",
      "Speed: 3.5ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_33_png.rf.c1c24340e753b63b6f4e5079b8ef474d.jpg: 1024x768 None8.0ms\n",
      "Speed: 2.8ms preprocess, 8.0ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_186_png.rf.e7ef27f31171ef062f867a9043ecb879.jpg: 1024x544 (no detections), 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 544)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2128_png.rf.9cdb5d69b7f964d77ef2cd8ddaa64b3d.jpg: 768x1024 (no detections), 7.8ms\n",
      "Speed: 3.0ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_388_png.rf.b1fe6ed17e0c06f51058539841f1a51c.jpg: 1024x832 (no detections), 7.7ms\n",
      "Speed: 3.9ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_6234_png.rf.564f9903c116204416868f0a2273e6ba.jpg: 1024x928 None8.7ms\n",
      "Speed: 4.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 928)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_92_png.rf.108b5397d94ff8c3c87cc885247ef603.jpg: 1024x448 (no detections), 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 448)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3374_png.rf.c13f2204d119c696615bdfeb960e7748.jpg: 1024x512 None35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2818_png.rf.3ef0c89fed24793069ef7828f4978ab4.jpg: 1024x832 (no detections), 8.3ms\n",
      "Speed: 3.8ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2207_png.rf.826e33db891514f1a14c23ece2273e7e.jpg: 1024x832 None7.7ms\n",
      "Speed: 3.1ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1126_png.rf.66c21ce21ee255ed4bdc66164bac87c5.jpg: 864x1024 None8.1ms\n",
      "Speed: 3.6ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1981_png.rf.05106dc3354a8d2c4292cacd2813aae1.jpg: 1024x832 (no detections), 8.2ms\n",
      "Speed: 3.1ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_673_png.rf.fbe0dea2deaf75d49f079ca7d33abe14.jpg: 1024x608 (no detections), 34.7ms\n",
      "Speed: 2.4ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 608)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_496_png.rf.be69c35487b2531b272b242febfdebb1.jpg: 1024x992 (no detections), 9.4ms\n",
      "Speed: 4.6ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 992)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2959_png.rf.87b65aa9e9d80f284ae39c06d2892e6e.jpg: 1024x576 (no detections), 8.5ms\n",
      "Speed: 2.2ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2263_png.rf.43688af1368a72ad0bc6719a5dcab20b.jpg: 1024x960 (no detections), 10.1ms\n",
      "Speed: 3.8ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4300_png.rf.d4626ae6c3183d2419faae148cd72283.jpg: 1024x672 None9.0ms\n",
      "Speed: 2.6ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_486_png.rf.57d8fa147cc2e2f6e7fb6067b94fdd17.jpg: 1024x768 (no detections), 8.7ms\n",
      "Speed: 2.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 768)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_273_png.rf.b2d75c97ef473f97c7077eb114856b2a.jpg: 1024x832 (no detections), 11.6ms\n",
      "Speed: 5.9ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_9_png.rf.063293a5d91155202c1ec5f03dd1170b.jpg: 1024x864 (no detections), 9.1ms\n",
      "Speed: 5.9ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_26_png.rf.ea3697c11878702d0b7728d240e2eb75.jpg: 512x1024 None40.1ms\n",
      "Speed: 2.4ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_704_png.rf.e3668d404753b933e1fd9500e697ca8c.jpg: 832x1024 (no detections), 8.6ms\n",
      "Speed: 3.7ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_812_png.rf.cfcd3189eb853066fc4819ad746775a6.jpg: 448x1024 (no detections), 40.4ms\n",
      "Speed: 1.6ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3620_png.rf.484267b719f5e17f04fecfe359aff37d.jpg: 1024x512 (no detections), 14.5ms\n",
      "Speed: 3.3ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 512)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_117_png.rf.e200e6b84f70bd27ba1e1123d052755e.jpg: 768x1024 (no detections), 12.6ms\n",
      "Speed: 4.9ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 768, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_540_png.rf.0e3e26d67bb471fb263c983cdf758c46.jpg: 832x1024 (no detections), 13.6ms\n",
      "Speed: 6.0ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_283_png.rf.f41cf5bd6aa70a2216bb701856df9e03.jpg: 864x1024 (no detections), 8.4ms\n",
      "Speed: 3.6ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2794_png.rf.6b3aeafbe8917839f42840a597349a32.jpg: 1024x832 (no detections), 8.6ms\n",
      "Speed: 3.3ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_355_png.rf.ae0f59ff3c26334cf587c5e76cc18b67.jpg: 1024x864 (no detections), 7.8ms\n",
      "Speed: 4.3ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1326_png.rf.6019c7e15df84d9d6286932d03e687b6.jpg: 512x1024 (no detections), 8.2ms\n",
      "Speed: 2.5ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_462_png.rf.1af786d0d41cd4ddc775694d50a5189d.jpg: 1024x384 None8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 384)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1015_png.rf.3b7320c3c40771fa5532bf713a728b83.jpg: 864x1024 (no detections), 8.5ms\n",
      "Speed: 3.7ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_354_png.rf.4fafa55e4596998cceb97af05c87b38d.jpg: 1024x864 (no detections), 9.0ms\n",
      "Speed: 3.5ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_2694_png.rf.6390e595cb681c436da1dfa7b2c78dfd.jpg: 1024x832 None9.3ms\n",
      "Speed: 3.1ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1471_png.rf.3ba297237985853fdf9e2c9f79f07f1d.jpg: 1024x960 (no detections), 10.3ms\n",
      "Speed: 4.3ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 960)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_52_png.rf.b194877235d291ca9e2e8824392bf776.jpg: 1024x864 None9.3ms\n",
      "Speed: 3.4ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1137_png.rf.fd851f5a4b2be36de41c54ec6a53c989.jpg: 832x1024 (no detections), 8.4ms\n",
      "Speed: 3.4ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_467_png.rf.b1cc6164190c9fbf10f622b0f06fc115.jpg: 1024x864 (no detections), 9.5ms\n",
      "Speed: 4.0ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1_png.rf.ff3f4a12a8e46a9a9aecace2ebf3869a.jpg: 1024x864 (no detections), 8.5ms\n",
      "Speed: 3.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_1035_png.rf.d7493a5653bc3628f7a1b1ec0eb5de85.jpg: 1024x864 (no detections), 8.0ms\n",
      "Speed: 3.5ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_212_png.rf.2ffb29b8c57630c49b7ee34bce2c46f3.jpg: 1024x1024 (no detections), 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image2_232_png.rf.66b26e2592f806b3b659538ae42a2e74.jpg: 1024x1024 (no detections), 9.3ms\n",
      "Speed: 4.1ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_43_png.rf.9757e6d0c648b4544e9043ccc8fb31ca.jpg: 1024x832 (no detections), 8.6ms\n",
      "Speed: 3.6ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_240_png.rf.c8b0cfb57aef2e4bc78d5a716909fd94.jpg: 1024x832 (no detections), 8.5ms\n",
      "Speed: 3.6ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 832)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4521_png.rf.9d460c80d2b830fc35b17c628a6d6290.jpg: 1024x256 (no detections), 37.7ms\n",
      "Speed: 1.3ms preprocess, 37.7ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 256)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_651_png.rf.c3391a5ae823bf5de28ed36b3f23f93a.jpg: 1024x672 (no detections), 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 672)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_497_png.rf.d6769296bd5c7ac8218ae363a5dc3968.jpg: 1024x576 (no detections), 9.1ms\n",
      "Speed: 2.6ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 576)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_302_png.rf.dc3856686e28e1ff95efc721c7cda455.jpg: 832x1024 (no detections), 11.8ms\n",
      "Speed: 6.5ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 832, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_189_png.rf.9fe16c915039954baf6675c96b2bacc6.jpg: 1024x864 (no detections), 8.6ms\n",
      "Speed: 4.8ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 1024, 864)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_4007_png.rf.5c5b46eb5afec1aecfd8ec0119476889.jpg: 1024x256 None8.3ms\n",
      "Speed: 1.0ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 256)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_3914_png.rf.d8e6ab2b78990092b7856255dd9726b7.jpg: 864x1024 (no detections), 9.2ms\n",
      "Speed: 3.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 864, 1024)\n",
      "\n",
      "image 1/1 /home/ippe-luning/Documents/uni/AppliedML/Applied-ML-Model/reports/../project_name/data/test/images/image1_391_png.rf.0b615525b5dec73ed6871c657bfded04.jpg: 1024x640 (no detections), 35.1ms\n",
      "Speed: 2.5ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../project_name/data/test/'\n",
    "images_dir = data_dir + 'images/'\n",
    "labels_dir = data_dir + 'labels/'\n",
    "\n",
    "image_paths = os.listdir(images_dir)\n",
    "i = 0\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image in image_paths:\n",
    "    label_filename = os.path.splitext(image)[0] + '.txt'\n",
    "    label_path = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "    results = model.predict(source= images_dir + image, save=False)\n",
    "\n",
    "    label = ''\n",
    "\n",
    "    # check and print corresponding label if it exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = f.read()\n",
    "    else:\n",
    "        print(f\"No label file found for {image}\")\n",
    "\n",
    "    predictions.append((image, results, label))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46cd41",
   "metadata": {},
   "source": [
    "First we check if it labels an image if it has a fracture and if it labels when it does not have a fracture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1117a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "correct = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "\n",
    "    true_label = 0 if label_is_empty else 1\n",
    "    predicted_label = 1 if has_prediction else 0\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084cb81",
   "metadata": {},
   "source": [
    "Let us now create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1f793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Fracture', 'Fracture'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680057fd",
   "metadata": {},
   "source": [
    "### Testing bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c0c7e",
   "metadata": {},
   "source": [
    "Now we will see if the bounding boxes are better than if one would select the entire screen. We use shapify to find the IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff165754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def compute_iou(pred_poly, label_poly):\n",
    "\n",
    "    # convert to Polygon class\n",
    "    pred_polygon = Polygon(pred_poly)\n",
    "    label_polygon = Polygon(label_poly)\n",
    "\n",
    "    if not pred_polygon.is_valid or not label_polygon.is_valid:\n",
    "        # print(\"Polygon is not valid\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Get intersection and union\n",
    "    intersection_area = pred_polygon.intersection(label_polygon).area\n",
    "    union_area = pred_polygon.union(label_polygon).area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection_area / union_area, label_polygon.area\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f4cbc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random guess: 10, model: 29, total: 39\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_better = 0\n",
    "random_guess_better = 0\n",
    "\n",
    "for image, result, label in predictions:\n",
    "    # if no label is there or the model did not predict, we are unable to calculate IoU\n",
    "    has_prediction = any(r.obb.xyxy.numel() > 0 for r in result)\n",
    "    label_is_empty = len(label.strip()) == 0\n",
    "    if label_is_empty or not has_prediction:\n",
    "        continue\n",
    "\n",
    "    # split lines of label\n",
    "    label_lines = label.splitlines()\n",
    "    \n",
    "    iou = 0.0\n",
    "    for line in label_lines:\n",
    "        if not line.strip():\n",
    "            continue  # skip empty labels, sanity check\n",
    "\n",
    "        label_parts = line.strip().split()\n",
    "        label_coords = list(map(float, label_parts[1:]))  # skip class label and make it float array\n",
    "        # print(label_coords)\n",
    "\n",
    "        # Go from a line to x y tuples\n",
    "        label_polygon = [(label_coords[i], label_coords[i + 1]) for i in range(0, len(label_coords), 2)]\n",
    " \n",
    "        label_area = 0.0\n",
    "        for r in result:\n",
    "            # print(r.obb.xyxyxyxyn)\n",
    "            pred_coords = r.obb.xyxyxyxyn.cpu().numpy().reshape(-1, 2)\n",
    "            # print(pred_coords)\n",
    "            pred_polygon = [tuple(point) for point in pred_coords]\n",
    "\n",
    "            iou_temp, label_area = compute_iou(pred_polygon, label_polygon)\n",
    "            iou = iou + iou_temp\n",
    "\n",
    "            #print(f\"IoU: {iou:.4f}\")\n",
    "            # print(f\"Label Area: {label_area:.4f}\")\n",
    "    \n",
    "    # Since coordinates of polygon are in normal coordinates, we only have t o check wether IoU is larger than label area. \n",
    "    # Since IoU of a an entire picture with another area has an union area of 1, and a intersection area of the label area.   \n",
    "    if iou > label_area:\n",
    "        model_better = model_better + 1\n",
    "    else:\n",
    "        random_guess_better = random_guess_better + 1\n",
    "\n",
    "print(f\"Random guess: {random_guess_better}, model: {model_better}, total: {random_guess_better + model_better}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
